<link href="../styles.css" rel="stylesheet" />

## 02. Введение в большие данные

- [02. Введение в большие данные](#02-введение-в-большие-данные)
  - [Большие данные](#большие-данные)
    - [Данные и информация](#данные-и-информация)
    - [Что такое большие данные?](#что-такое-большие-данные)
    - [Особенности больших данных](#особенности-больших-данных)
  - [Работа с Big Data](#работа-с-big-data)
  - [Хранение и обработка больших данных](#хранение-и-обработка-больших-данных)
    - [Хранилище данных](#хранилище-данных)
    - [Озеро данных](#озеро-данных)
      - [Применение Data Lake](#применение-data-lake)
      - [Примеры использования Data Lake](#примеры-использования-data-lake)
      - [Как устроено озеро данных](#как-устроено-озеро-данных)
      - [Отличия Data Lake от хранилища данных](#отличия-data-lake-от-хранилища-данных)
      - [Преимущества Data Lake](#преимущества-data-lake)
      - [Недостатки Data Lake](#недостатки-data-lake)
      - [Советы по использованию Data Lake](#советы-по-использованию-data-lake)
    - [Витрина данных](#витрина-данных)
  - [Аналитика больших данных](#аналитика-больших-данных)
    - [Основная терминология](#основная-терминология)
    - [Бизнес-аналитика](#бизнес-аналитика)
      - [Преимущества внедрения бизнес-аналитики BI](#преимущества-внедрения-бизнес-аналитики-bi)
      - [Какие задачи решают BI-системы для руководителей и аналитиков](#какие-задачи-решают-bi-системы-для-руководителей-и-аналитиков)
      - [Примеры задач, решаемых с помощью BI](#примеры-задач-решаемых-с-помощью-bi)
      - [BI и сквозная аналитика: в чем различие?](#bi-и-сквозная-аналитика-в-чем-различие)
      - [Ключевые этапы внедрения BI](#ключевые-этапы-внедрения-bi)
      - [Примеры используемых систем](#примеры-используемых-систем)
  - [Разработка систем Big Data](#разработка-систем-big-data)
    - [Специалисты для работы с Big Data](#специалисты-для-работы-с-big-data)
    - [Этапы разработки систем Big Data](#этапы-разработки-систем-big-data)
  - [Направления работы в области Big Data](#направления-работы-в-области-big-data)
  - [Применение Big Data](#применение-big-data)
  - [Преимущества и недостатки Big Data](#преимущества-и-недостатки-big-data)
  - [Наука о данных](#наука-о-данных)
    - [Направления и специальности](#направления-и-специальности)
    - [Уровни компетенций](#уровни-компетенций)
  - [Связь между машинным обучением и большими данными](#связь-между-машинным-обучением-и-большими-данными)
  - [Машинное обучение и большие данные: взаимосвязь и применение](#машинное-обучение-и-большие-данные-взаимосвязь-и-применение)
  - [Представление данных для машинного обучения. Признаки объектов](#представление-данных-для-машинного-обучения-признаки-объектов)
      - [Типы признаков](#типы-признаков)
      - [Ограничения табличного представления объектов](#ограничения-табличного-представления-объектов)
  - [Заключение](#заключение)
      - [Выводы](#выводы)
  - [Практическая работа. Представление признаков в табличной форме](#практическая-работа-представление-признаков-в-табличной-форме)
    - [Задание](#задание)
  - [Глоссарий](#глоссарий)
  - [Источники информации](#источники-информации)

### Большие данные
В мире, где цифровизация стала основой нашего образа жизни, мы столкнулись с новым явлением, получившим название «большие данные». Но что стоит за этим термином, и каковы его реальные масштабы?

> Большие данные, или Big Data, – это не просто объемная информация. Это данные такого масштаба, скорости и разнообразия, что традиционные методы их обработки становятся неэффективными. Мы говорим о терабайтах и петабайтах данных, поступающих из самых разных источников: от социальных сетей до космических телескопов.

Однако, объем – это лишь верхушка айсберга. Большие данные представляют собой не только квантовое увеличение информации, но и качественное изменение. Они включают в себя структурированную, полуструктурированную и неструктурированную информацию, требующую специализированных подходов к хранению, обработке и анализу.

Работа с большими данными выдвигает перед IT-специалистами целый ряд вызовов. С одной стороны, это вопросы хранения и доступа к данным. С другой – необходимость преобразования этих массивов информации в понятные и полезные знания, способные повлиять на принятие решений в бизнесе, науке и других сферах.

Для начала стоит разобраться, чем отличаются данные от информации.

#### Данные и информация
<dfn title="данные">Данные</dfn> — это необработанные, сырые факты и цифры, не имеющие самостоятельного смысла, в то время как <dfn title="информация">информация</dfn> — это обработанные, структурированные и контекстуализированные данные, которые приобретают значение и цель для пользователя. Информация помогает понять закономерности, принимает форму отчета или сводки, тогда как данные — это отдельные фрагменты пазла, которые становятся цельной картиной только после их сборки.

**Ключевые отличия**
- **Структура**: данные — это неорганизованная совокупность фактов (числа, текст, изображения), а информация — это данные, которые были упорядочены и связаны в логическую последовательность. 
- **Смысл и контекст**: данные не несут конкретного смысла или назначения сами по себе, в отличие от информации, которая имеет значение и цель, добавляемую при её обработке. 
- **Цель использования**: Данные служат основой для анализа и принятия решений, а информация помогает осмысливать эти данные и формировать суждения. 
- **Превращение**: данные превращаются в информацию в результате обработки, интерпретации, анализа и добавления контекста. 

**Пример**
- **Данные**: Список цифр в электронной таблице, например: "150 (Январь), 300 (Февраль)".
- **Информация**: Отчет, который анализирует эти цифры и показывает, что "В начале года (январь-февраль) наблюдался рост расходов на транспорт, что требует дальнейшего изучения". 

Отличие информации от данных состоит в том, что:
1) **Данные** — это фиксированные сведения о событиях и явлениях, которые хранятся на определенных носителях, а **информация** появляется в результате обработки данных при решении конкретных задач.

    Например, в базах данных хранятся различные данные, а по определенному запросу система управления базой данных выдает требуемую информацию.

2) Данные — это носители информации, а не сама информация.

3) Данные превращаются в информацию только тогда, когда ими заинтересуется человек. Человек извлекает информацию из данных, оценивает, анализирует ее и по результатам анализа принимает то или иное решение.

    Данные превращаются в информацию несколькими путями:

   - контекстуализация: мы знаем, для чего эти данные нужны;
   - категоризация: мы разбиваем данные на типы и компоненты;
   - подсчет: мы обрабатываем данные математически;
   - коррекция: мы исправляем ошибки и ликвидируем пропуски;
   - сжатие: мы сжимаем, концентрируем, агрегируем данные.

   Таким образом, если существует возможность использовать данные для уменьшения неопределенности знаний о каком-либо предмете, то данные превращаются в информацию. Поэтому можно утверждать, что информацией являются используемые данные.

4) Информацию можно измерять. Мера измерения содержательности информации связана с изменением степени неосведомленности получателя и основана на методах теории информации.[^38087337]

#### Что такое большие данные?
<dfn title="big data">Big Data</dfn> — это крупные массивы разнообразной информации и стек специальных технологий для работы с ней. Термин применяется к таким объемам данных, с которыми пользовательский компьютер и офисные программы не справятся. С помощью анализа больших данных бизнес может получить возможность принимать решения по развитию продукта и завоевывать конкурентное преимущество.

Термин Big Data появился еще в прошлом веке, но начал набирать популярность, когда появились первые крупные интернет-сервисы. Компании столкнулись с тем, что пользователи загружают на сайты колоссальные объемы неструктурированного контента.

Это заставило разработчиков придумывать новые типы хранилищ данных, поскольку стандартных уже не хватало. Первой платформой, которая взяла на себя работу с такими объемами данных, стала [Hadoop](https://ru.wikipedia.org/wiki/Hadoop). К настоящему времени она обладает мощным стеком инструментов.[^bigdata]

#### Особенности больших данных
<dfn title="большие данные">Большие данные</dfn> — это наборы данных настолько объёмные или сложные, что традиционные методы обработки не справляются с ними эффективно. Они характеризуются "3V":

1. **Volume** (*объём*) — очень большой объём информации (терабайты и петабайты). Как правило, информации должно поступать более 150 Гб в сутки.

2. **Velocity** (*скорость*) — данные поступают очень быстро (поток данных в реальном времени). Для работы с массивами информации в режиме реального времени требуются повышенные вычислительные мощности.

3. **Variety** (*разнообразие*) — данные бывают разных типов и форматов. Поступающая информация имеет разные форматы или степень структурированности. Например, контент социальных сетей может сильно различаться даже в пределах одной страницы.

Иногда добавляют еще три дополнительных признака больших данных, которые точно помогают определить, что речь идет именно о Big Data:

3. **Veracity** (*достоверность*) — источникам данных можно доверять, а результат их обработки обладает достоверностью, достаточной для принятия решений.

4. **Variability** (*вариативность*) — поток данных изменчив, на него может влиять даже время суток или погода. Например, в час пик приходит больше данных от таксистов.

5. **Value** (*ценность*) — данные могут иметь разное значение для компании. Например, сделки с крупными покупателями имеют большее значение, чем с мелкими.

*Примеры типов данных*

Большие данные |	Обычные данные
-- | --
Записи всех звонков сотрудников крупного колл-центра |	Бухгалтерские отчеты компании в Excel
Поисковые запросы, переходы по ссылкам, движения и нажатия мыши всех пользователей поисковой системы |	ФИО и возраст всех пользователей отдельного сервиса
Сведения о перемещениях таксистов, трафик и спрос на поездки |	Расписание маршрутов всего общественного транспорта области
Информация о покупках клиентов банка и снятии ими наличных в терминалах и отделениях |	Список клиентов с просроченными задолженностями

Еще одна особенность больших данных заключается в их распределенной структуре — для сбора и анализа информации одновременно используется множество инструментов. Получается что-то наподобие воронок, которые пропускают информацию из разных источников, попутно обрабатывая ее. В умелых руках это дает ряд преимуществ:

- **Расширяемость** — платформы для работы с Big Data можно горизонтально масштабировать до тех пор, пока хватает вычислительных мощностей.
- **Отказоустойчивость** — сбой в одном потоке не нарушает работу других.
- **Локализация** — информация обрабатывается на тех же серверах, где она находится, что минимизирует затраты на транспортировку.[^bigdata]

Источники больших данных:

- социальные сети;
- сенсоры и IoT-устройства;
- транзакционные системы (банки, интернет-магазины);
- логи серверов и системных устройств.

### Работа с Big Data
*[DAS]: Direct-attached storage
*[NAS]: Network Attached Storage
*[SAN]: Storage Area Network

До начала создания базы данных нужно определить, какие технологии планируется использовать для сбора, хранения, обработки и анализа информации. Чтобы лучше понимать эти процессы, рассмотрим этапы работы (**пайплайн**) с Big Data:

1. <dfn title="сбор данных">Сбор данных</dfn> (*data collection*) — процессы получения информации из различных источников для последующего анализа и использования.

    Все начинается с интеграции технологий сбора информации, определения ее источников и необходимой обработки. Это могут быть действия пользователей сайта, отчеты о продажах, статистические, медицинские и любые другие данные, которые ценны для компании. К процессу также подключаются специалисты по Data Cleaning, которые настраивают фильтры для будущего анализа.

    **Основные этапы**: сбор данных охватывает извлечение сырых данных из источников, таких как датчики, базы данных, веб-формы или документы. Ключевые шаги: идентификация источников, захват данных (сканирование, импорт, опросы) и начальная проверка целостности. Это обеспечивает готовность данных для обработки в ML или аналитике.

    **Методы сбора**
      - **Автоматизированный**: через API, IoT-устройства, логи систем или веб-скрейпинг.

      - **Ручной**: опросы, интервью, анкетирование или ввод из документов.

      - **Гибридный**: комбинация, например, сканирование бумажных форм с OCR для цифровизации.

    Эти компоненты формируют фундамент пайплайна данных в Big Data и машинном обучении.

2. <dfn title="хранение данных">Хранение данных</dfn> (*data retention*, *data storage*) — процессы сохранения, организации и обеспечения доступа к информации на цифровых носителях.

    **Основные компоненты**: хранение охватывает выбор носителей (диски, облака, СХД), структуру данных (реляционные БД, NoSQL, озера данных) и управление жизненным циклом: от загрузки до архивирования. Ключевые задачи — обеспечение целостности, масштабируемости и безопасности через резервное копирование и репликацию. На данном этапе используются такие инструменты, как NoSQL базы данных (MongoDB, Cassandra), распределённые файловые системы (например, HDFS).

    **Типы систем хранения**
    - **Блоковое**: данные как блоки (DAS, SAN) для высокопроизводительных приложений.

    - **Файловое**: иерархическая структура (NAS) для общего доступа.

    - **Объектное**: для неструктурированных данных в Big Data (S3, MinIO).

    <details>
    <summary>Про DAS, NAS, SAN</summary>

    <dfn title="NAS">NAS</dfn> (англ. *Network Attached Storage*, сетевое хранилище) — сервер для хранения данных на файловом уровне. По сути представляет собой компьютер с некоторым дисковым массивом, подключённый к сети (обычно локальной) и поддерживающий работу по принятым в ней протоколам. Несколько таких компьютеров могут быть объединены в одну систему.[^NAS]

    <dfn title="SAN">SAN</dfn> (англ. *Storage Area Network*, сеть хранения данных) — архитектурное решение для подключения внешних устройств хранения данных, таких как дисковые массивы, ленточные библиотеки, оптические приводы к серверам таким образом, чтобы операционная система распознала подключённые ресурсы как локальные. SAN характеризуются предоставлением так называемых сетевых блочных устройств (обычно посредством протоколов Fibre Channel, iSCSI или AoE), в то время как сетевые хранилища данных (англ. Network Attached Storage, NAS) нацелены на предоставление доступа к хранящимся на их файловой системе данным при помощи сетевой файловой системы (такой как NFS, SMB/CIFS, или Apple Filing Protocol). При этом категоричное разделение SAN и NAS является искусственным: с появлением iSCSI началось взаимное проникновение технологий с целью повышения гибкости и удобства их применения.[^SAN]

    <dfn title="DAS">DAS</dfn> (англ. *Direct-attached storage* — система хранения данных с прямым подключением, дисковое хранилище) — запоминающее устройство, непосредственно подключённое к серверу или рабочей станции, без помощи сети хранения данных. Это ретроним, используемый в основном для отличия несетевых устройств хранения от SAN и NAS. Де-факто DAS — это быстрое (если интерфейс быстрый) локальное хранилище, доступное только тому устройству, к которому оно подключено. Жёсткий диск внутри ПК тоже своего рода DAS. DAS часто называют «островами информации»[^DAS].

    </details>

    Эти элементы формируют базу для последующего анализа и ML.

    Для больших объемов информации недостаточно будет даже нескольких компьютеров, поэтому компании прибегают к услугам облачных провайдеров и задействуют распределенные вычислительные мощности. Примеры технологий, которые используются для хранения:

   - <dfn title="data warehouse">Data Warehouse</dfn> (*хранилище данных*) — единое корпоративное хранилище с обработанной и структурированной информацией. Хранилище упрощает анализ полученных данных, но требует структурированности.
   - <dfn title="data vault">Data Vault</dfn> (*свод данных*) — одна из моделей хранилища Data Warehouse с временными отметками размещения данных, которые позволяют проследить изменение хранимой информации во времени.
   - <dfn title="data lake">Data Lake</dfn> (*озеро данных*) — данные в хранилище поступают непрерывно в неструктурированном или, наоборот, структурированном или слабоструктурированном виде. Используется для сбора данных из разных источников в режиме реального времени.
   - <dfn title="data mart">Data Mart</dfn> (*витрина данных*) — хранилище данных, предназначенных для повседневного использования. Поступающую информацию необходимо тщательно обрабатывать, но после этого к ней проще регулярно обращаться.

3. <dfn title="обработка данных">Обработка данных</dfn> (*data processing*) — преобразование сырых данных в пригодный для анализа формат.

    **Основные этапы**
    - <dfn title="очистка данных">Очистка данных</dfn> (*data cleaning*) — процесс выявления и устранения ошибок, несоответствий и "грязи" в датасетах для повышения их качества. Очистка обеспечивает точность ML-моделей, снижая шум и предвзятость. Включает следующие методы: удаление дублей, пропусков, выбросов и исправление ошибок.

    - <dfn title="трансформация данных">Трансформация данных</dfn> (*data transformation*) — это процесс преобразования сырых данных в удобный для анализа или хранения формат. Включает следующие методы: нормализация, кодирование категориальных переменных, масштабирование признаков.

    - <dfn title="интеграция данных">Интеграция даных</dfn> (*data integration*) — объединение данных из разных источников в единый набор данных (*dataset*).

    - <dfn title="агрегация данных">Агрегация данных</dfn> (*data aggregation*) — процесс обобщения информации в сводную форму для анализа. Агрегация в пайплайне следует после интеграции: сначала сливаются источники, затем данные суммируются. Уменьшает объём данных, ускоряя обработку без потери ключевых инсайтов. Агрегация снижает нагрузку на хранение, интеграция обеспечивает полноту. Результат — компактный датасет с метриками, удобный для отчётов и визуализации.

    - <dfn title="обогащение данных">Обогащение данных</dfn> (*data enrichment*) — добавления дополнительной ценной информации к существующим наборам (например, дополняет записи новыми атрибутами из внешних источников). Отличается от агрегации расширением (добавление), а не сжатием данных.

    Обработка обеспечивает качество данных для ML-моделей: снижает шум, повышает точность прогнозов и ускоряет вычисления.

    Для обработки крупных объемов информации используется технология [MapReduce](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html). Массивы распределяется на разных узлах, которые могут параллельно их обрабатывать, даже если на одном узле случилась ошибка. На MapReduce, например, работают кластеры Apache Spark™, Apache Hadoop®.

4. <dfn title="анализ данных">Анализ данных</dfn> — это процесс исследования, фильтрации и моделирования информации для извлечения полезных знаний и поддержки решений.

    Заключительным этапом работы является анализ — получение самого ценного из всего хранилища данных. С помощью СУБД, нейросетей и других инструментов массивы информации преобразуются в таблицы, диаграммы, графики и другое (**визуализация данных**). Анализ начинается с **описательного** (что произошло?), переходит к **диагностическому** (почему?), **предиктивному** (что будет?) и **пресскриптивному** (что делать?). Включает статистику, визуализацию и ML для выявления паттернов (интеллектуальную аналитику). На данном этапе используются такие инструменты, как MapReduce, Apache Hadoop, Apache Spark.

    **Визуализация** используется на финальных шагах анализа для представления результатов: графики, дашборды, тепловые карты помогают выявить паттерны и тренды. **Вывод инсайтов** следует сразу после — интерпретация визуализаций для бизнес-решений или гипотез. <dfn title="инсайт">Инсайт</dfn> (*insight* — с англ. "прозрение", "озарение") в анализе данных — это глубокое, неожиданное понимание или ценное открытие, полученное из данных, которое приводит к практическим рекомендациям. Инсайт отличается от обычных фактов тем, что объясняет "почему" и "как использовать": например, не просто "продажи упали на 20%", а "отток вырос из-за задержек доставки в регионы X и Y". Он рождается на стыке данных, гипотез и контекста. Вывод инсайтов завершает анализ данных: после визуализации и моделирования аналитик интерпретирует результаты для бизнеса.

    **Примеры назначения анализа**

    - <dfn title="сравнительная аналитика">Сравнительная аналитика</dfn> (*competitive analytics*) — изучение поведения потребителей и их вовлеченность в режиме реального времени, чтобы сравнить продукт компании с продуктами конкурентов.
    - <dfn title="аналитика настроений">Аналитика настроений</dfn> (*sentiment analysis*) — изучение отзывов клиентов и обсуждений продукта в соцсетях, чтобы выявить слабые стороны продукта и уровень удовлетворенности потребителей.
    - <dfn title="маркетинговая аналитика">Маркетинговая аналитика</dfn> (*marketing analytics*) — изучение данных о клиентах, чтобы улучшить маркетинговые компании и разработать бизнес-инициативы.
    - <dfn title="интеллектуальный анализ данных">Интеллектуальный анализ данных</dfn> (*data mining*) — подмножество анализа для поиска скрытых зависимостей, процесс «просеивания» больших массивов данных с целью извлечь из них ценную информацию для конкретного применения. Он является неотъемлемой частью науки о данных и бизнес-аналитики и направлен в первую очередь на поиск закономерностей.

_Пример_: Анализ кликов пользователей на сайте для персонализации рекламы в реальном времени.

*Пример MapReduce (подсчёт слов) (псевдокод)*:
```py
Map(key, value):
  for word in value:
    Emit(word, 1)

Reduce(key, values):
  sum = 0
  for v in values:
    sum += v
  Emit(key, sum)
```

### Хранение и обработка больших данных
*[DWH]: Data Wharehouse
*[CRM]: Customer Relationship Management
*[ERP]: Enterprise Resource Planning

#### Хранилище данных
<dfn title="хранилище данных">Хранилище данных</dfn> (*Data Warehouse*, DWH) — централизованная система, где собираются данные из разных источников: например из CRM, с сайта, из мобильного приложения и ERP. В отличие от обычной базы, которая нужна для оперативной работы приложений, например чтобы быстро оформлять заказы или собирать данные пользователей, хранилище создаётся именно для аналитики. В нём данные очищаются, приводятся к единому формату и структурируются так, чтобы их было удобно анализировать.

<details>
<summary>Что такое ERP</summary>

ERP (enterprise resource planning) — это планирование ресурсов предприятия. В наиболее общем виде ERP можно определить как совокупность всех базовых бизнес-процессов, необходимых для управления компанией: финансы, управление персоналом, производство, цепочка поставок, услуги, закупки и многое другое. На самом базовом уровне ERP помогает эффективно управлять всеми этими процессами в интегрированной системе. 

ERP — организационная стратегия интеграции производства и операций, управления трудовыми ресурсами, финансового менеджмента и управления активами, ориентированная на непрерывную балансировку и оптимизацию ресурсов предприятия посредством специализированного интегрированного пакета прикладного программного обеспечения, обеспечивающего общую модель данных и процессов для всех сфер деятельности.[^erp]

ERP-система — конкретный программный пакет, реализующий стратегию ERP. По сути это центральная нервная система предприятия, которая обеспечивает автоматизацию, интеграцию и интеллектуальность, необходимые для эффективного выполнения всех повседневных бизнес-операций. Большинство или все данные организации должны храниться в системе ERP, чтобы обеспечить единый источник достоверной информации в масштабе всей компании.

Современные ERP-системы — это не что иное, как базовые, и они мало похожи на ERP-системы десятилетий назад. Теперь они поставляются в облаке и используют новейшие технологии, такие как искусственный интеллект (ИИ) и машинное обучение, для интеллектуальной автоматизации, повышения эффективности и мгновенного анализа в масштабе всей компании. [^810741]

</details>

#### Озеро данных
<dfn title="озеро данных">Озеро данных</dfn> (*Data Lake*) — это логическая совокупность репозиториев данных, предназначенных для хранения и анализа больших данных в их исходном формате. В отличие от традиционного понимания централизованного хранилища, Data Lake может быть распределенным по множеству физических местоположений, включая облачные платформы, on-premises инфраструктуру или гибридные среды. Концепция озера данных представляет собой эволюционный подход к управлению корпоративными данными, обеспечивающий гибкость, масштабируемость и экономическую эффективность в условиях постоянно растущих объемов информации.[^data-lake]

<details>
<summary>Об on-premise и on-cloud решениях</summary>

**On-premise** – это метод развертывания программного обеспечения или приложений, которые устанавливаются и функционируют на собственных серверах и инфраструктуре компании-заказчика. **On-cloud** (облачные) решения предполагают, что доступ к программному обеспечению осуществляется через серверы стороннего поставщика.[^on-premise-i-on-cloud-v-chem-raznitsa-i-chto-vybrat]

<dfn title="on-premise">On-premise</dfn> (также “on-premises” и “on-prem”, в переводе с англ. — локальный) в контексте компаний означает модель развертывания программного обеспечения и инфраструктуры, когда все ресурсы, включая оборудование и данные, находятся внутри компании, на её собственных серверах, а не в облаке. Локальное решение относится к программной или технологической инфраструктуре, которая устанавливается и обслуживается на собственных серверах или оборудовании компании. Локальные решения считаются более безопасными, поскольку компания имеет полный контроль над инфраструктурой, но они также могут быть более дорогостоящими и трудоемкими в управлении по сравнению с облачными или веб-решениями.[^on-premise-i-on-cloud-v-chem-raznitsa-i-chto-vybrat] В отличие от облачных решений, где компания арендует ресурсы у стороннего провайдера, on-premise модель предполагает полный контроль и ответственность за инфраструктуру со стороны компании.[^chto-znachit-on-premise]

<dfn title="облачное решение">Облачное решение</dfn> (англ. *on-cloud*) представляет собой программное обеспечение или услугу, предоставляемую через интернет или сеть удаленных серверов. Подобное решение позволяет компаниям получать доступ и использовать программное обеспечение или сервис из любого места, где есть подключение к интернету, поскольку данные и приложения размещаются на удаленных серверах, а не на собственном компьютере пользователя или на локальных серверах. Облачные решения часто обеспечивают такие преимущества, как масштабируемость, доступность и экономичность, поскольку они не требуют поддержки аппаратной или программной инфраструктуры. В качестве примеров можно вспомнить такие популярные облачные решения, как 1С Облако, Trello, Figma, «Битрикс24» и пр.[^on-premise-i-on-cloud-v-chem-raznitsa-i-chto-vybrat]

</details>

<dfn title="data lake">Data Lake</dfn> или Озеро данных — технология для получения и управления данными в разных форматах: в необработанном, неупорядоченном или, наоборот, структурированном или слабоструктурированном виде, в едином репозитории. Данные, которые можно хранить в озере:[^datalake]

Тип данных |	Примеры
-- | --
Неструктурированные |	Текстовые документы, медицинские данные, изображения и видео
Слабоструктурированные |	Файлы в формате xml, edi, json и лог-файлы
Структурированные |	Строки и столбцы реляционных БД, таблицы Excel

##### Применение Data Lake
Термин придуман в 2010-м году основателем компании Pentaho Джеймсом Диксоном. Описывая концепцию, он сравнил Data Lake и Data Mart. Витрины данных похожи на бутилированную воду — очищенную и упакованную. Озера данных — это открытые водоемы, в которые вода стекается из различных источников. В водоемы можно погружаться, а можно брать образцы с поверхности.

Так, озера данных удобны для сбора, хранения и обработки больших потоков информации, которая поступает непрерывно. Если грамотно их использовать, они станут надежным инструментом для следующих отраслей:

- **Телекоммуникации**. Озера данных часто применяются для хранения и анализа данных о клиентах, трафике, сетевых устройствах и других факторах, которые влияют на бизнес телекоммуникационных компаний.
- **Нефтегазовая промышленность**. Data Lake собирают терабайты данных и используют их в прогнозных моделях для разведки месторождений, управления цепочками поставок и техническим обслуживанием.
- **Медицина**. База данных о пациентах, их диагнозах и способах лечения может быть использована для автоматизации диагностики.
- **Розничная торговля**. Data lake позволяет хранить и анализировать данные о продажах, клиентах, инвентаре и других факторах, которые важны для розничных компаний.
- **Организации, занимающиеся финансами, страхованием, логистикой, закупками** — любой бизнес, который обрабатывает огромные объемы данных, может извлечь выгоду из использования Data Lake.

##### Примеры использования Data Lake
- **Омниканальный маркетинг**.

    Приложения для смартфонов нередко собирают информацию о действиях пользователя, а озера данных позволяют оперативно ее получать. На основе этой информации маркетологи могут делать специальные предложения или персонализированные скидки. Так, стриминговый сервис Netflix, Inc. с помощью Data Lake [получает](https://www.protocol.com/enterprise/how-netflix-and-uber-helped-create-the-data-lakehouse-by-preserving-an-open-source-tradition) данные о просмотренных пользователями фильмах и сериалах.

- **Цифровая цепочка поставок**.

    В цифровой цепочке поставок часто необходимо собирать большие объемы данных разного формата. Например, информация из цеха, отчеты о доставке и оплате. Благодаря Data Lake производитель может объединить их. Одним из первых пользователей Data Lake в промышленности [стал](https://www.ge.com/news/press-releases/ge-announces-first-data-lake-approach-industrial-internet-better-access-analyze-and) международный производитель техники General Electric.

- **Интернет вещей**.

    [Интернет вещей](https://ru.wikipedia.org/wiki/%D0%98%D0%BD%D1%82%D0%B5%D1%80%D0%BD%D0%B5%D1%82_%D0%B2%D0%B5%D1%89%D0%B5%D0%B9) непрерывно расширяется за счет многочисленных датчиков, которые устанавливаются на транспортные средства. С помощью них отслеживается передвижение транспорта, безопасность его эксплуатации, расход топлива и другое. Озера данных популярны для сбора такой информации, поскольку не требуют ее структурирования. Например, сервис доставки и такси Uber с помощью Data Lake [следит](https://www.protocol.com/enterprise/how-netflix-and-uber-helped-create-the-data-lakehouse-by-preserving-an-open-source-tradition) за своими автомобилями.

##### Как устроено озеро данных
Озеро данных можно рассматривать как шаблон проектирования — формализованные рекомендации, которые можно использовать для решения распространенных проблем при разработке инфраструктуры. Четыре основные особенности устройства Data Lake:

- Данные необработаны либо слабообработаны.
- Большой срок хранения данных.
- Есть возможность преобразования данных.
- Поддерживаются разные схемы чтения данных.

Файлы в Data Lake хранятся на нескольких серверах, куда поступают из таких источников, как CRM-системы, социальные сети, интернет-магазины, датчики на производстве и прочих. Поступающей в озеро информации присваиваются метаданные: время поступления, источник, формат, структура и другое.

Все это может использоваться для извлечения данных в будущем, чтобы провести аналитику или обучить чему-то искусственный интеллект. Способы организации Data Lake могут включать HDFS, S3, Data Vault и распределенные файловые системы. Для размещения озера данных можно использовать как локальное хранилище, так и облачное.

##### Отличия Data Lake от хранилища данных
У озера данных и хранилища данных есть существенные различия, которые надо учитывать при выборе способа хранения информации:

| Область сравнения     | Data Lake                                    | Хранилище данных                |
| --------------------- | -------------------------------------------- | ------------------------------- |
| Сбор данных           | Данные любой структуры и из любых источников | Данные приведены к единому виду |
| Обработка данных      | Осуществляется после сбора                   | Осуществляется перед сбором     |
| Основные пользователи | Специалисты по глубокому анализу данных      | Оперативные пользователи        |
| Стоимость хранения    | Ниже                                         | Выше                            |
| Получение данных      | Высокая скорость получения                   | Низкая скорость получения       |

##### Преимущества Data Lake
- **Гибкие варианты использования**.

    При использовании озер данных не нужно заранее знать, как их необходимо будет анализировать. Например, данные из одного и того же озера можно использовать для поиска совпадающих записей или удаления дублирующихся, преобразования данных для внешней интеграции, классификации и кластеризации или машинного обучения.

- **Снижение эксплуатационных расходов**.

    Традиционные хранилища данных для аналитики и систем поддержки принятия решений используются уже более 30 лет. Озера данных совмещают в себе лучшие открытые и бесплатные технологии, что позволяет сэкономить на сборе и обработке информации.

- **Быстрый доступ к данным**.

    Информация — это стратегический актив, на основе которого можно разрабатывать инновации. Data Lake позволяет быстрее получить данные и принять необходимые решения. Искусственный интеллект также зависит от больших объемов разнообразной информации, быстрый доступ к которой можно организовать с помощью озер данных.

- **Совместное использование**.

    Крупные организации традиционно работают в разрозненных группах, каждая из которых может использовать разные типы данных. Объединенное хранилище для них — отличное решение, чтобы наладить совместную работу между командами.

- **Масштабируется бесконечно**.

    Благодаря низкой стоимости Data Lake не имеют ограничений по размеру. Также озера данных способны масштабироваться горизонтально и вертикально, что позволяет обрабатывать вплоть до нескольких петабайт данных.

##### Недостатки Data Lake
Озера данных оптимизированы для высокой пропускной способности, но ради этого приходится жертвовать качеством данных:

- В Data Lake не требуется структурировать данные, поэтому их сложнее анализировать.
- Data Lake не имеет инструментов для интегрированного или целостного получения всех данных.
- Без квалифицированного контроля за озерами данных трудно гарантировать конфиденциальность и безопасность хранилища.
- Для сбора реляционных данных есть гораздо более удобные решения, чем Data Lake.
- Если управление озером организовано плохо, в нем быстро накапливаются большие объемы неконтролируемых, и, возможно, бесполезных данных. Для эффективной фильтрации данных и отсечения недостоверных источников требуется высокая квалификация.

##### Советы по использованию Data Lake
Для извлечения максимальной выгоды из озер данных нужно с умом подойти к их использованию. К счастью, технология уже обкатана многими компаниями, которые сформулировали основные правила работы с озерами. Можно выделить три основных момента, которые помогут развернуть озеро данных, избежав возможных проблем в будущем:

1. **Главное — сбор данных**.

    Прежде всего необходимо максимально конкретизировать, что именно собирать, потому что озеро может поместить в себя что угодно и превратиться в болото. Грамотная настройка источников информации и фильтров в дальнейшем сильно упростит анализ и поможет сэкономить.

2. **Максимальная детализация метаданных**.

    Данные в озерах часто неструктурированные или слабоструктурированные, но навести порядок в хранилище можно с помощью каталогизации и метаданных. Затраченные усилия непременно окупятся, когда придет время анализировать результаты.

3. **План уничтожения данных**.

    Распространенная ошибка при работе с большими объемами информации — отсутствие плана по избавлению от ненужной информации. Если до сбора данных в озеро их удастся правильно разметить, то это поможет не удалить что-то нужное вместе с мусором, а также избавит от проблем с различными регуляторами и соответствием [регламентам](https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%89%D0%B8%D0%B9_%D1%80%D0%B5%D0%B3%D0%BB%D0%B0%D0%BC%D0%B5%D0%BD%D1%82_%D0%BF%D0%BE_%D0%B7%D0%B0%D1%89%D0%B8%D1%82%D0%B5_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85).

#### Витрина данных
<dfn title="витрина данных">Витрина данных</dfn> (*data mart*) — база данных, предназначенная для решения специализированной задачи или набора задач из одной предметной области, например по поиску наименьшей цены товара, расчету загрузки производственных мощностей предприятия, организации тематических рассылок и т.п.

Альтернативная технология хранения данных — Data Lake или Озеро данных. Витрины данных похожи на бутилированную воду — очищенную и упакованную. Озера данных — это открытые водоемы, в которые вода стекается из различных источников.[^datamart]

*Реализация хранилища Big Data с помощью популярных сервисов*

Назначение |	Сервис (инструмент)
-- | --
Обработка транзакций |	Apache HBase, Amazon DynamoDB, Google Cloud Spanner, Microsoft SQL Server (In-Memory/OLTP), PostgreSQL with WAL-based replication
Запросы и отчеты |	Apache Hive, Apache Impala, Amazon Athena, Google BigQuery, Amazon Redshift
New SQL |	Apache Cassandra, Google Cloud Spanner, CockroachDB, VoltDB, TiDB
Документоориентированная СУБД |	MongoDB, Couchbase, Amazon DocumentDB, Firebase Firestore, RavenDB
Резидентная СУБД |	Redis, SQLite, Derby (Embedded DB), H2, LevelDB
БД «ключ — значение» |	Redis, DynamoDB, Riak, RocksDB, Memcached
БД временных рядов |	InfluxDB, TimescaleDB, OpenTSDB, Prometheus, Druid
Потоковая обработка |	Apache Kafka, Apache Flink, Spark Streaming, Apache Storm, Google Cloud Dataflow
Полнотекстовый поиск |	Apache Solr, Elasticsearch, Algolia, OpenSearch, Sphinx
Очередь сообщений	| Apache Kafka, RabbitMQ, AWS SQS, Google Cloud Pub/Sub, NATS

### Аналитика больших данных
*[BI]: Business Intelligence
*[OLAP]: On-Line Analytical Processing

Современные Big Data решения охватывают широкий спектр вопросов, связанных с корпоративными информационными ресурсами. Иногда разрабатываются комплексные системы, которые позволяют компаниям эффективно управлять данными и использовать их в интересах бизнеса.

#### Основная терминология
<dfn title="Business Intelligence">Business Intelligence</dfn> (BI) — технология аналитики, которая призвана предоставлять компании доступ к целостной картине деятельности в режиме реального времени. BI-системы отображают ключевые метрики, формируют детализированные отчёты и помогают ориентироваться в изменениях, оказывая поддержку при принятии стратегических решений.

<dfn title="OLAP">OLAP</dfn> (англ. *online analytical processing*, интерактивная аналитическая обработка) — подход к обработке данных, позволяющий оперативно получать в структурированном виде определённый срез из большого массива данных для их последующего анализа. Как правило основывается на подготовке агрегированной информации из больших массивов данных, структурированной по многомерному принципу. Реализации технологии OLAP являются компонентами программных решений класса Business Intelligence[^OLAP].

<dfn title="OLAP-кубы">OLAP-кубы</dfn> — структурированный инструмент, необходимый для многомерного анализа показателей. Благодаря ему специалисты выявляют скрытые закономерности, проводят глубокую обработку информации и прогнозируют динамику развития.

<dfn title="хранилище данных">Хранилище данных</dfn> (DataWarehouse, DWH) — единая среда хранения, рассчитанная на большой объем корпоративной информации. Грамотная архитектура DWH обеспечивает стабильную работу основных сервисов, а также сбор и консолидацию всех данных для дальнейших аналитических вычислений.

<dfn title="dashboarding">Dashboarding</dfn> — визуальное представление показателей, помогающее отслеживать изменения в режиме реального времени. Гибкие дашборды упрощают работа с ключевыми метриками и улучшают процессы управления, за счет чего повышается понимание текущих тенденций и возможностей компании.

<dfn title="data science">Data Science</dfn> (наука о данных) — методология, в рамках которой применяются машинное обучение и нейронные сети. Такой подход помогает создавать модели для прогнозирования спроса, удержания аудитории или оптимизации маркетинговых кампаний, задействуя весь доступный объем данных.[^resheniya-bi-big-data]

#### Бизнес-аналитика
Разработка и внедрение BI систем (Business Intelligence) – это не просто цифровизация отчетности, а стратегический инструмент для повышения прозрачности, управляемости и эффективности бизнеса. BI позволяет принимать решения, основанные на фактах, а не на интуиции.[^business-intelligence]

##### Преимущества внедрения бизнес-аналитики BI
Сегодня компании генерируют огромные объемы информации: продажи, финансы, маркетинг, логистика, клиентское поведение. Но без систематизированного подхода эти данные остаются неиспользованным активом. BI-системы позволяют трансформировать разрозненные данные в целостную картину бизнеса, выявлять тренды и отклонения, прогнозировать сценарии развития.

Business Intelligence – это не просто набор дашбордов. Это платформа, интегрирующая данные из внутренних и внешних источников (CRM, ERP, базы данных, облачные сервисы), очищающая их, структурирующая и визуализирующая в формате, понятном как для руководства, так и для аналитиков.

![Устройство современной BI-системы](../img/snimok-ekrana-2025-05-23-052705-1024x711.png.webp)

##### Какие задачи решают BI-системы для руководителей и аналитиков
- **Принятие обоснованных решений**. BI предоставляет полную картину происходящего в реальном времени, позволяя оперативно реагировать на изменения.

- **Финансовый контроль, оптимизация затрат и автоматизация отчетности**. Анализ прибыльности проектов, выявление точек потерь и неэффективных процессов.

- **Повышение прозрачности процессов и визуализация данных**. Вы видите, как работают отделы, где есть узкие места, и какие действия приносят результат.

- **Планирование и прогнозирование**. BI для бизнеса помогает строить сценарии развития, моделировать спрос и управлять рисками.

- **Улучшение клиентского сервиса**. Аналитика клиентского поведеня позволяет выстраивать персонализированные предложения и повышать лояльность.

![BI](../img/frame-2-1024x331.png.webp)

##### Примеры задач, решаемых с помощью BI
BI-системы эффективны в компаниях, где важна скорость принятия решений и управление на основе данных:

- **Ритейл**: анализ продаж, управление цепочками поставок, оценка эффективности рекламных кампаний.

- **Производственные предприятия**: контроль загрузки оборудования, минимизация простоев, управление себестоимостью.

- **Финансовый сектор**: детальный анализ доходов, расходов, рисков и рентабельности.

- **IT и цифровые сервисы**: поведенческая аналитика пользователей, мониторинг эффективности релизов, развитие продуктов.

- **Логистика и транспорт**: оптимизация маршрутов, мониторинг SLA, управление запасами.

##### BI и сквозная аналитика: в чем различие?

![BI](../img/decosystems.vzlet_.media_uslugi_resheniya-bi-big-data_-1-photoroom.png.webp)

**Business Intelligence** фокусируется на внутренней эффективности: анализ операционных показателей, производственных процессов, финансовой отчетности.

![Analytics](../img/decosystems.vzlet_.media_uslugi_resheniya-bi-big-data_-e1729072553552-photoroom.png.webp)

**Сквозная аналитика** ориентирована на внешние каналы привлечения и поведение клиентов: анализ маркетинговой воронки, атрибуция рекламных расходов, ROI по каналам.

Вместе они создают единую цифровую экосистему управления бизнесом: BI обеспечивает контроль внутренних метрик, а сквозная аналитика – оптимизацию внешней коммуникации и маркетинга.

##### Ключевые этапы внедрения BI
- **Постановка целей**: определение приоритетных задач и KPI.

- **Выбор BI-платформы**: анализ функционала, масштабируемости и совместимости с текущими системами.

- **Интеграция данных**: подключение к источникам, обеспечение качества и актуальности информации.

- **Настройка дашбордов**: визуализация ключевых метрик для разных ролей: от СЕО до операционного менеджера.

- **Обучение пользователей**: адаптация команды под работу с новой системой.

- **Мониторинг и оптимизация**: регулярное обновление данных и сценариев, адаптация под изменяющиеся цели бизнеса.

##### Примеры используемых систем
Стоит обратить внимание на такие платформы как Alpha BI, Glarus BI, Luxms BI и Analytics Workspace

- **Analytics Workspace**

    ![Analytics Workspace](../img/card-1.png)

    Это мощная BI-система, разработанная для оптимизации аналитики данных и повышения эффективности бизнеса. Она предлагает интуитивно понятный интерфейс, который облегчает визуализацию данных и создание отчетов даже для пользователей без технического бэкграунда. С возможностью интеграции с различными источниками данных, Analytics Workspace обеспечивает всесторонний анализ и глубокое понимание бизнес-процессов. Автоматизация отчетности и возможность настройки информационных панелей позволяют командам сосредоточиться на стратегическом развитии, принимая обоснованные решения на основе актуальной информации.

- **Alpha BI**

    ![Alpha BI](../img/card-2.png)

    Это интуитивно понятная BI-система, которая обеспечивает мгновенный доступ к вашим данным и мощные инструменты визуализации. С Alpha BI вы сможете легко настраивать отчеты и обзорные панели, что позволяет принимать взвешенные бизнес-решения на основе актуальной информации.

- **Glarus BI**

    ![Glarus BI](../img/card-3.png)

    Предлагает надежное решение для анализа данных, фокусирующее внимание на автоматизации отчетности. С этой системой вы сможете сократить время на сбор и обработку информации, позволяя вашему бизнесу сосредоточиться на стратегическом развитии и повышении эффективности.

- **Luxms BI**

    ![Luxms BI](../img/luxmbi-1.png.webp)

    Российская платформа бизнес-аналитики с мощными функциональными и визуальными возможностями для создания аналитических решений — от «готовых» дэшбордов до развитого функционала self-service. Платформа гибко настраивается под конкретные бизнес цели компании.

### Разработка систем Big Data
Опыт показывает, что внедрение любой инициативы в сфере Big Data обычно занимает от года до нескольких лет. Для успеха проекта важна проработка концепции управления данными, определение архитектуры и выбор технологического стека. Когда возникает нехватка конкретной экспертизы или времени, компании привлекают внешних интеграторов.

Распространённая практика — создавать отдел, отвечающий за анализ и обработку больших массивов данных. В такой команде работают архитекторы, аналитики и инженеры по качеству, благодаря чему почти любая масштабная задача выполняются быстрее. Если система разворачивается в облаке, зоны ответственности разделяются между компанией-заказчиком, интегратором и провайдером, что способствует прозрачности и гармоничной координации.

#### Специалисты для работы с Big Data
Можно выделить несколько групп специалистов, без которых вряд ли удастся организовать хранилище больших данных:

- **Инженеры** — создают инфраструктуру для сбора и хранения данных. К ним относятся также разработчики центров обработки данных и сотрудники облачных сервисов.
- **Аналитики** — помогают находить скрытые закономерности и вырабатывать решения по улучшению продукта. Это не только дата-сайентисты, но и маркетологи, дизайнеры интерфейсов, специалисты по обработке естественного языка и другие.
- **Специалисты по нейросетям и машинному обучению** — подключают к работе искусственный интеллект, упрощающий анализ массивов информации.[^bigdata]

#### Этапы разработки систем Big Data

1. **Анализ задачи**. Сбор исходной информации, изучение существующих процессов и подходящих СУБД. Важна точная формулировка целей и понимание того, как данные будут использоваться и какие результаты ожидаются.

2. **ТЗ на разработку Big Data**. На базе полученных сведений формируется техническое задание. В нём учитываются все требования к функционалу, детально описывается модель решения и определяются используемые инструменты.

3. **Проектирование и дизайн**. Архитектурный отдел продумывает логику модулей, а также внешний вид будущей системы. На этом этапе выбираются методы интеграции и технология, позволяющие добиться высокой производительности.

4. **Программная реализация**. Специалисты приступают к коду, выбирая гибкие методологии (Scrum, Agile) или каскадные (Waterfall), в зависимости от потребностей заказа. Мы можем разрабатывать модули параллельно с тестированием, чтобы поддерживать высокое качество.

5. **Тестирование**. После завершения основной части работ команда проверяет все компоненты на корректность обработка данных и устойчивость к нагрузкам. Результаты согласовываются со стейкхолдерами.

6. **Внедрение и сопровождение**. Готовое решение интегрируется в инфраструктуру компании. Далее специалисты контролируют стабильность системы, занимаются её обновлением и развитием. Правильно организованная поддержка позволяет сохранять эффективность в долгосрочной перспективе.

При грамотном подходе даже очень большой проект в области Big Data становится полезным инструментом для усиления позиций на рынке. Благодаря углубленной аналитике руководители получают информацию о ключевых тенденциях, а это помогает разрабатывать более точные стратегии и повышать конкурентоспособность. Именно такой подход DecoSystems стремится внедрять, реализуя решения любой сложности и масштаба.[^resheniya-bi-big-data]

### Направления работы в области Big Data

*[LTV]: Lifetime Value

1. **Разработка банковских антифрод-систем и сценариев поиска недобросовестных клиентов**

      - Автоматизированная оценка онлайн-операций
      - Выявление паттернов поведения пользователей
      - Учет множества критериев при сегментарном анализе действий пользователя

      ![Card](../img/card-1.jpg.webp)

2. **Увеличение среднего чека и минимизация оттока существующих клиентов**

      - Проведение клиентской аналитики
      - Сегментация клиентов с помощью алгоритмов ML
      - Настройка рекомендательных систем и расчет LTV клиентов

      <details>
      <summary>Что такое LTV</summary>

      LTV, или Lifetime Value, — пожизненная ценность клиента. Метрика показывает, сколько денег клиент принёс компании за всё время взаимодействия с ней. Это может быть и чистая прибыль от клиента, и доход от всех его заказов. LTV — одна из главных маркетинговых метрик. С её помощью можно оценить эффективность выбранной бизнес-модели и понять, окупаются ли на самом деле затраты на маркетинг. Метрику используют, чтобы понять, оправданы ли затраты на привлечение, вовлечение и удержание клиента. Другие названия показателя — CLV и CLTV: Customer Lifetime Value.[^chto-takoe-ltv-zachem-eye-schitat-i-kak-pravilno-eto-delat]

      </details>

      ![Card](../img/card-2.jpg.webp)

3. **Создание маркетинговых движков и реализация персонализированного real-time маркетинга**

      - Интеграция бэкофисных систем с метаданными из веб-источников и социальных сетей
      - Интеграция бэкофисных систем с геолокационными метаданными
      - Реализация обогащения данных через интеграционное взаимодействие с публичными источниками для улучшения качества базы данных

      <details>
      <summary>Что такое бэк-офис</summary>

      <dfn title="бэк-офис">Бэк-офис</dfn> (от англ. *back* — задняя часть) — внутренние отделы компании, которые выполняют обслуживающие и административные функции и не взаимодействуют напрямую с клиентами и заказчиками. Среди прочего в круг задач входит оптимизация и автоматизация рабочих процессов, упразднение неэффективных операций. Фактически большинство компаний имеют бэк-офис, но не всегда выделяют его как нечто обособленное. Как правило, к бэк-офису относятся:

      - юристы
      - бухгалтеры и экономисты
      - HR
      - IT-специалисты
      - аналитики

      Существует противоположное понятие — фронт-офис. В него входят сотрудники, взаимодействующие с клиентами. В небольших компаниях обычно нет территориального разделения на фронт- и бэк-офис: все сотрудники работают в одном месте.[^bek-ofis]

      </details>

      ![Card](../img/card-3.jpg.webp)

4. **Проведение аудита текущих систем отчетности и реализация дашбордов**

   - Формирование требований к системам отчетности
   - Обучение специалистов использованию систем визуализации данных
   - Обучение специалистов использованию отчетных движков (Qlik Sense, Stimulsoft, Tableau и другие)

      ![Card](../img/card-5.jpg.webp)

5. **Построение логической модели данных для различных сфер бизнеса**

      - Разработка DWH, Data Lake, Data Marts
      - Определение оптимальной инфраструктуры при использовании MPP систем и ETL-инструментов
      - Реализация алгоритмов пакетной и real time модели обновления слоев данных для надежной работы с большими объемами информации

      ![Card](../img/card-4.jpg.webp)

### Применение Big Data
Необходимость в хранилище больших сегодня возникает практически у каждой крупной компании. Рассмотрим примеры из разных отраслей, для которых может потребоваться внедрение хранилища больших данных.

- **Телекоммуникации**. Отрасль является абсолютным лидером по использованию Big Data: около 90% телекоммуникационных компаний уже собирают и анализируют большие данные, а остальные планируют начать в будущем. Например, такие онлайн-сервисы, как YouTube, VK и другие не смогли бы существовать без объемных хранилищ данных.

- **Продажи**. Немецкий производитель автомобилей BMW несколько лет назад решил собрать данные о своих продажах, продажах конкурентов, а также отследить, где автомобили этой марки пользуются наибольшим спросом. Анализ и визуализация информации помогли им выявить слабые и сильные места своего бизнеса и внести коррективы в стратегию компании.

- **Маркетинг**. Сложно представить, какое количество потребительских данных непрерывно поступает на серверы гиганта электронной коммерции Amazon. Благодаря анализу больших данных ритейлер в курсе интересов покупателей, а также предлагает собранную информацию другим компаниям, которые тоже используют ее в маркетинге.

- **Банкинг**. Такие банки, как СберБанк, Тинькофф и многие другие с помощью Big Data не только анализируют действия клиентов и предлагают им свои продукты, но и повышают безопасность. Например, биометрические данные клиентов помогают им бороться с мошенниками, а анализ доходов и затрат клиентов — оценивать их кредитоспособность.

- **Транспорт**. Получение больших объемов данных от водителей в режиме реального времени может сильно помочь сервисам такси. Так, Яндекс.Такси отслеживает спрос и количество водителей на территории, что позволяет предлагать клиентам актуальные цены.

- **Подбор персонала**. Рутинную работу по подбору кандидатов в крупных компаниях уже давно выполняют роботы, которые анализируют многочисленные резюме без помощи рекрутеров. Например, компания PepsiCo заполнила 10% своих вакансий с помощью робота. По словам представителей производителя, искусственный рекрутер может провести 1500 интервью за 9 часов, на что у HR-сотрудника ушли бы месяцы.

- **Автомобилестроение**. Наличие хранилища больших данных и умелых специалистов по их анализу иногда может даже спасти жизни. Например, компания Toyota с помощью Big Data выяснила, что большинство аварий происходит из-за того, что водители путают педали. Производитель начал разработку сервиса по определению манеры давления на педаль, который помешает водителю сделать ошибку во время стрессовой ситуации.[^bigdata]

### Преимущества и недостатки Big Data
Резюмируя опыт использования больших данных, можно выделить следующие неоспоримые преимущества данной технологии:

- **Улучшение принятия решений**: анализ больших объемов данных позволяет выявлять точные корреляции и тренды, которые недоступны при работе с малыми наборами данных, что повышает качество стратегических и оперативных решений.

- **Персонализация и таргетинг**: использование больших данных позволяет предлагать клиентам более релевантный контент и продукты на основе их поведения, предпочтений и контекста в реальном времени.
​
- **Прогнозирование и оперативная оптимизация**: модели на основе больших данных улучшают точность прогнозов спроса, планирования запасов, обслуживания оборудования и др., что снижает издержки и увеличивает эффективность.
​
- **Инновации и новые бизнес-модели**: анализ больших данных стимулирует создание новых услуг, продуктов и цифровых экосистем, включая аналитические платформы, IoT-решения и автоматизацию процессов.
​
- **Эффективность процессов и автоматизация**: автоматизация сбора, обработки и анализа больших массивов данных ускоряет циклы принятия решений и сокращает время реакции на изменения рынка

Несмотря на очевидную пользу, пользователи больших данных сталкиваются с рядом трудностей:

- **Сложность**. Чтобы правильно собирать, фильтровать, обрабатывать и анализировать разрозненную и разнообразную информацию, требуется труд множества квалифицированных специалистов, а также вычислительные мощности и инфраструктура.

- **Затраты**. Специалисты по работе с данными очень востребованы, для хранения и обработки требуются серьезные вычислительные мощности, а многие инструменты являются платными.

- **Безопасность**. Чем больше у вас важной информации, тем выше риски, что она попадет не в те руки. Так, если взломать хранилище данных банка, то миллионы его клиентов могут остаться без денег. Чтобы не допустить этого, нужен основательный подход к сохранности данных и квалифицированные специалисты.[^bigdata]

### Наука о данных
<dfn title="наука о данных">Наука о данных</dfn> (*data science*) — это междисциплинарная область, которая использует научные методы, процессы, алгоритмы и системы для извлечения знаний и инсайтов из больших и структурированных или неструктурированных данных, объединяя математику, статистику, программирование и аналитику для решения сложных задач, прогнозирования и принятия решений. По сути, это превращение хаоса сырых данных в полезную информацию, модели и прогнозы, которые используются в бизнесе, науке, медицине и других сферах. 

Если говорить простыми словами, то <dfn title="data science">data science</dfn> (наука о данных) — это дисциплина, которая позволяет сделать данные полезными. Если найти пересечение различных определений что же такое Data Science, то им будет лишь одно слово — данные. Всё это говорит о том, что широта применения Data Science огромна. К сожалению, эта широта не дает никакой информации о потенциальной деятельности человека, решившего освоить это направление. Ведь с данными можно делать всё, что угодно. Можно строить сложные отчеты или «шатать» таблички с помощью SQL. Можно предсказывать спрос на такси константой или строить сложные математические модели динамического ценообразования. А еще можно настроить поточную обработку данных для высоконагруженных сервисов, работающих в режиме реального времени. 

А вообще, причем здесь слово «наука»? Безусловно, под капотом у Data Science серьезнейший математический аппарат: теория оптимизации, линейная алгебра, математическая статистика и другие области математики. Но настоящим академическим трудом занимаются единицы. Бизнесу нужны не научные труды, а решение проблем. Лишь гиганты могут позволить себе штат сотрудников, которые будут только и делать, что изучать и писать научные труды, придумывать новые и улучшать текущие алгоритмы и методы машинного обучения.

К сожалению, многие эксперты в этой области на разных мероприятиях зачастую связывают Data Science в первую очередь с построением моделей с помощью алгоритмов машинного обучения и довольно редко рассказывают самое важное, по-моему, — откуда возникла потребность в той или иной задаче, как она была сформулирована на «математическом языке», как это всё реализовано в эксплуатации, как провести честный эксперимент, чтобы правильно оценить бизнес-эффект.[^557416]

![Data scientist](../img/9b389ab7909bffed8bf8eb3653fb23bf.png)

Для того, чтобы лучше понять суть data science, рассмотрим следующую картинку с [распределением Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), то есть с вероятностью вероятностей:

![data science](../img/e2f56de4745c2eadd0fa550b12fb6271.png)

Предположим, что в Data Science существуют три основные компетенции:

1. **Математика**. Теоретические знания алгоритмов машинного обучения, и математическая статистика для проверки разных статистических гипотез и обработки результатов, а также любые другие фундаментальные знания, которые будут важны в вашей предметной области.

2. **Разработка**. Всё, что связано с разработкой, инженерными составляющими проекта, DevOps, SysOps, SRE, и прочее.

3. **Предметная область**. Навыки коммуникации с коллегами и бизнесом, чтобы понимать, какую проблему они хотят решить, на какие вопросы ответить.

#### Направления и специальности
*[DevOps]: Development & Operations
*[ML]: Machine Learning
*[R&D]: Research & Development
*[ИИ]: искусственный интеллект

И Data Scientist в этой парадигме — это некоторое наблюдение из нашего распределения Дирихле. Но с помощью этого распределения можно ввести несколько новых должностей, которые будут давать более ясное представление о вашей потенциальной деятельности. Рассмотрим несколько из них.

![Data science branches](../img/181c4de21df8ba4b94e4ea5e29f9bc2b.png)

- <dfn title="инженер машинного обучения">Инженер машинного обучения</dfn> (ML-инженер, *Machine Learning Engineer*) — специалист, который создает, обучает и внедряет модели искусственного интеллекта (ИИ), позволяя компьютерам решать задачи, анализируя большие объемы данных без явного программирования каждого шага. Он трансформирует идеи в рабочие системы, интегрируя их в реальные бизнес-процессы, оптимизируя производительность и обеспечивая стабильную работу в продакшне, занимется введением в эксплуатацию моделей машинного обучения и поддерживает их в актуальном состоянии. Для этого требуются навыки и знания в области алгоритмов машинного обучения, ну и, конечно, разработки.

- <dfn title="аналитик данных">Аналитик данных</dfn> (*data analyst*) — специалист, который собирает, обрабатывает и интерпретирует большие объемы данных, чтобы помочь компаниям принимать обоснованные решения, выявлять закономерности и тренды, оптимизировать процессы и снижать риски. По сути, он "переводит" хаотичные цифры в понятные выводы и рекомендации для бизнеса, используя статистические методы и инструменты визуализации. Данный специалист занимается проверкой статистических гипотез, проектирует и проводит эксперименты. Для этого требуются фундаментальные знания математической статистики, а также необходимо держать руку на пульсе бизнеса.

- <dfn title="инженер данных">Инженер данных</dfn> (дата-инженер, *data engineer*) — это IT-специалист, который строит и обслуживает инфраструктуру для сбора, хранения, обработки и перемещения больших объемов данных, делая их доступными и готовыми для аналитиков и ученых по данным (*Data Scientists*). Это тот человек, который занимается ETL-процессами, архитектурой хранилища, составляет витрины и поддерживает их, организовывает потоковую обработку данных. По сути, он «архитектор и строитель» мира данных, который обеспечивает надежные потоки информации, чтобы другие специалисты могли извлекать из них ценные инсайты.

- <dfn title="исследователь машинного обучения">Исследователь машинного обучения</dfn> (*machine learning researcher*) — исследователь, ориентированный на разработку новых методов и архитектур, проведение экспериментов и публикацию научных статей. Часто работает в академическом или R&D-контексте. Данный специалист в основном занимается исследовательской работой. Пишет и изучает статьи, придумывает новые математические методы. Таких позиций в России довольно мало, да и встречаются они, как правило, в крупных компаниях, которые могут себе это позволить.

- <dfn title="аналитик">Аналитик</dfn> (*analyst*) — специалист, который собирает, обрабатывает и интерпретирует данные, превращая их в понятные выводы и рекомендации для принятия обоснованных решений в бизнесе, IT или других сферах. <dfn title="бизнес-аналитик">Бизнес-аналитик</dfn> (*business analyst*) — это специалист, который изучает бизнес-процессы компании, выявляет проблемы и возможности для повышения эффективности, а затем переводит потребности бизнеса на понятный язык для команд разработки, предлагая и помогая внедрять решения для достижения целей компании. Это человек, который отвечает на вопросы бизнеса, и его плотность вероятности приходится на предметную область. Он выступает связующим звеном между бизнесом и IT-специалистами, работая над оптимизацией процессов, созданием новых продуктов и принятием управленческих решений, основанных на фактах. 

- <dfn title="оператор машинного обучения">Оператор машинного обучения</dfn> (MLOps-инженер) — это специалист на стыке Data Science и DevOps, который автоматизирует и управляет всем жизненным циклом моделей машинного обучения (ML) — от экспериментов и разработки до развертывания (deployment), мониторинга и поддержки в промышленной эксплуатации, делая ML-системы надежными, масштабируемыми и стабильными. Он создает конвейеры (pipelines) CI/CD для моделей, контейнеризирует их, настраивает мониторинг и обеспечивает интеграцию с IT-инфраструктурой, превращая прототипы в реальные бизнес-решения. Этот человек максимально сосредоточен на разработке и развёртывании кода в продакшене.

#### Уровни компетенций

Попробуем коротко сформулировать профиль человека, который будет находиться на каждом из грейдов в мире Data Science. Не стоит забывать, что от компании к компании уровень компетенций для каждого из грейдов может довольно сильно отличаться.[^557416]

1. **Junior Data Scientist**

   - Умеет реализовать полный DS-пайплайн: «приготовить» данные, обучить модель, измерить ее качество.
   - Делает только то, что ему сказали.
   - Нуждается в постоянной опеке и контроле.

2. **Middle Data Scientist**

   - Имеет подтвержденный на практике результат, например, построил и внедрил модель оттока клиентов, которая экономит компании N млн. руб в год.
   - Может обсуждать бизнес-постановку задачи.
   - В меру самостоятельный.
   - Редко ошибается.

3. **Senior Data Scientist**

   - Имеет более обширный опыт по сравнению с мидлом.
   - Может самостоятельно формулировать и решать задачи.
   - Имеет опыт наставничества или готов быть ментором.
   - Обладает высоким уровнем эмоционального интеллекта.
   - Уровень технических компетенций выше мидла.

   Если у middle ребят возникают проблемы с ростом и развитием, то зачастую это связано с

   - отсутствием проактивности;
   - неготовностью брать ответственность и инициативу на себя и доводить дело до конца;
   - неумением находить общий язык с бизнес заказчиками и смежниками;
   - синдромом самозванца;
   - недостаточным уровнем эмоционального интеллекта и/или отсутствия понимания его важности в рабочей деятельности

   А дальше уже сложнее, потому что тимлид может руководить как командой из 2-3 человек, так и несколькими отделами.

4. **Teamlead**

   - Эксперт, который отвечает за конкретные участки DS-пайплайна. Работает в соответствие с поставленными перед ним задачами. Координирует работу нескольких младших коллег.
   - Ставит задачи экспертам в соответствии с заданным планом и координирует их работу. Несет ответственность за конкретное направление DS в компании.
   - Отвечает за продукт/проект/направление, имеющие большое значение для крупной компании. Определяет требования к команде и составляет планы в соответствии с заданным направлением действий.
   - Отвечает за стратегически важный продукт/проект/направление в крупной компании. Руководит большой командой data scientist’ов и аналитиков. Задает команде направление действий, оценивает сроки и затраты, отвечает за результаты проектов.

    Чем выше уровень специалиста, тем больше ответственности и тем сложнее направление R&D. А значит, и больше зарплата.

    Но всё же можно выделить характерные отличия тимлида. Безусловно, этот человек должен обладать техническими навыками (hard skills): он знает, как сделать так, чтобы «всё заработало», может ответить на специфичные для продукта вопросы, знает, как работает продукт. А еще тимлид планирует и формулирует задачи (впоследствии «продаёт»), раскладывает их на составляющие, напрямую общается с бизнесом, работает с командой, занимается развитием и ростом своих ребят. Для тимлида важно думать и жить в терминах продукта и бизнеса, быть проактивным и доводить дело до конца.[^557416]

### Связь между машинным обучением и большими данными
На пересечении двух революционных технологий — машинного обучения и больших данных — рождается симбиоз, который кардинально меняет парадигмы современного мира. Осознание глубины и значения этой связи имеет ключевое значение для понимания будущего IT-сферы. Для начала, рассмотрим суть обеих дисциплин. Большие данные представляют собой огромные объемы информации, которые сложно обработать с помощью традиционных методов. Машинное обучение же — это способность машин адаптироваться и «учиться» на основе данных без явного программирования. Казалось бы, где здесь переплетение?

- **Топливо для машин**: Большие данные становятся «топливом» для систем машинного обучения. Благодаря такому объему информации, машины могут обучаться гораздо эффективнее, распознавая закономерности и шаблоны в данных, которые раньше оставались незамеченными.

- **Высокая скорость принятия решений**: Машинное обучение позволяет обработать массивы больших данных в реальном времени, предоставляя компаниям моментальные аналитические выводы и прогнозы.

- **Персонализация и оптимизация**: Используя большие данные, системы машинного обучения могут предоставлять высоко персонализированные решения для пользователей, учитывая их индивидуальные предпочтения и поведение.

- **Автоматизация процессов**: На основе анализа больших данных, машины могут автоматизировать рутинные процессы, выполняя задачи, которые ранее требовали человеческого вмешательства.

Большие данные предоставляют необходимую основу для обучения машин, в то время как машинное обучение обеспечивает инструменты для извлечения ценной информации из этих данных. Вместе они становятся мощным катализатором инноваций и прогресса в современном цифровом мире.[^mashinnoe-obuchenie-i-big-data]

### Машинное обучение и большие данные: взаимосвязь и применение
Для качественного МО нужны большие объёмы данных — больших данных. Большие данные — источник информации для обучения моделей машинного обучения. Чем больше и качественнее данные, тем лучше можно обучить модель.

Современные алгоритмы глубокого обучения требуют огромных объёмов данных и вычислительных ресурсов. Глубокие нейросети требуют масштабных данных и ресурсов.

В условиях больших данных необходимость в эффективной автоматизации анализа и построения моделей огромна. Совместное использование позволяет строить точные и сложные модели, работать с реальным временем и масштабными задачами (например, рекомендации, анализ видео).

Области применения и примеры
| Сфера | Примеры
-- | --
Рекомендательные системы | Netflix, YouTube, Amazon
финансовые технологии | Кредитный скоринг, обнаружение и борьба с мошенничеством
Медицина | Диагностика заболеваний по изображениям  или генетике, обработка генетических данных
Автомобильная промышленность | беспилотные автомобили
Социальные сети | Анализ и модерация контента

Таким образом МО и большие данные — ключевые технологии будущего и важные тренды. Следующие шаги в обучении: изучение Python, библиотек (scikit-learn, TensorFlow), баз данных и распределённых систем. Для старта — изучить Python, библиотеку scikit-learn, основы Hadoop/Spark.

### Представление данных для машинного обучения. Признаки объектов
В каком виде данные подаются машине?

Классический способ — представление данных в виде таблицы.

| Объекты | Признак 1 | Признак 2 | $\dots$ | Признак $m$
-- | -- | -- | -- | --
$A_1$ | $P_{11}$ | $P_{12}$ | $\dots$ | $P_{1m}$
$A_2$ | $P_{21}$ | $P_{22}$ | $\dots$ | $P_{2m}$
$\dots$ | $\dots$ | $\dots$ | $\dots$ | $\dots$
$A_n$ | $P_{n1}$ | $P_{n2}$ | $\dots$ | $P_{nm}$

- Здесь строки — это объекты, а столбцы — признаки. Таким образом, у каждого объекта есть несколько признаков.

- Соответственно, в данной выборке $n$ объектов, у каждого из которых имеется $m$ признаков.

- Число $n$ называется <dfn title="объем выборки">объёмом выборки</dfn>.

С помощью $P(A)$ будем обозначать значение признака $P$ для объекта $A$.

##### Типы признаков
Признаки могут очень сильно отличаться по своей природе.

- <dfn title="количественный признак">Количественный</dfn> (<dfn title="числовой признак">числовой</dfn>): признак, выражаемый по своему физическому смыслу в виде некоторого вещественного (действительного) числа. Область его значений (см. область отправления и прибытия, область определения и значений) — вещественные числа, и сам признак имеет числовую природу.

- <dfn title="порядковый признак">Порядковый</dfn>: не имеет числовой природы, он всего лишь задает порядок (см. отношение строгого порядка) на некотором множестве объектов. Порядковые признаки иначе называют <dfn title="псевдоколичественный признак">псевдоколичественными</dfn>, поскольку хотя они и имеют представление в виде числа, но не выражают количественных характеристик. Дело в том, что есть числовые признаки, а есть числа, но числовыми признаками, как ни странно, не являющиеся. Отличие первых от вторых в том, что над первыми можно производить операции, свойственным числам (арифметические), а над вторыми нет, ибо смысла они не имеют. Порядковые признаки поддерживают только операции сравнения — проверки на равенство (равно / не равно) и сравнения между собой (больше / меньше и т.д.). Также псевдоколичественные признаки позволяют работать с модой и медианой, но никак не со средними!

- <dfn title="номинальный признак">Номинальный</dfn> (<dfn title="категориальный признак">категориальный</dfn>): признак не имеет числовой природы и, как правило, число его возможных значений конечно (вспомнить про перечисления в ЯП — набор именованных констант). В частности, <dfn title="бинарный признак">бинарный признак</dfn> — это номинальный признак с двумя возможными значениями.

*Пример*

| Студент | Пол | Рост | Вес | Группа крови | Место на олимпиаде
-- | -- | -- | -- | -- | --
Иванов | 1 | 172 | 107 | 1 | 3
Запеканка | 1 | 185 | 64 | 2 | 4
Ватрушкина | 0 | 168 | 61 | 3 | 2
Ололоева | 0 | 201 | 85 | 4 | 1

- Рост и вес — это вещественные числа (**количественный** признак).
- Пол — это **бинарный** признак (в классическом понимании). Числа 0 и 1 не обозначают возможности совершения арифметических действий с признаками (например, сложение мужчины с женщиной не дает мужчину, равно как сложение женщин не дает женщину) или некоторую важность (приоритет, превосходство) одного над другим. Другими словами, это просто метки классов и не более того.
- Группа крови — это **номинальный** (но не бинарный) признак. Хотя исторически она и выражается в числах, тем не менее по факту она не имеет числовой природы, поскольку с группами крови невозможно выполнение арифметических операций и операци сравнения.
- Место на олимпиаде — это **порядковый** признак. Хотя места на олимпиаде и выражаются числами, но их нельзя складывать, умножать и т.д., т.к. это по сути не числа, а **ранги**, выражающие порядок.

!!! tip Упражнение

    - Какие еще числовые, порядковые, бинарные признаки существуют у человека?

      <details>
      <summary><em>Признаки человека</em></summary>

      Числовые признаки:

        - возраст;

        - индекс массы тела (ИМТ);

        - давление крови (систолическое и диастолическое);

        - частота пульса и дыхания;

        - уровень гормонов (например, количество тестостерона, эстрогена);

        - количество гемоглобина и других клеток крови.

        Порядковые признаки:

        - уровень образования;

        - степень физической активности;

        - категория состояния здоровья по шкале (например, нормальное, предболезненное, болезненное);

        - порядок рождения в семье (первый ребенок, второй и т.д.).

      Бинарные признаки:

        - резус-фактор крови (положительный или отрицательный);

        - наличие определенных заболеваний (например, диабет: есть/нет);

        - курение (курит/не курит);

        - способность сворачивать язык трубочкой (да/нет);

        - левша или правша.

      Таким образом, кроме основных физиологических и биометрических характеристик, у человека много других признаков разного типа, которые используются в медицине, генетике, социологии и других областях для более полного описания и анализа личности и состояния здоровья человека

      </details>

    - А слабо найти номинальный, но не бинарный признак у человека?

      <details>
      <summary><em>Номинальные признаки человека</em></summary>

      Пример номинального, но не бинарного признака у человека — это цвет глаз. Это качественный признак, который имеет несколько категорий (например, синий, карий, зеленый, серый), при этом между категориями нет упорядочивания или ранжирования, то есть нельзя сказать, что один цвет глаз "больше" или "лучше" другого. Такой признак является номинальным, так как это просто разные категории без внутреннего порядка.

      Другие примеры номинальных немонопольных признаков: национальность, род занятий, цвет волос, семейное положение (холост, женат, разведен, овдовевший) — все они представляют разные категории без упорядочивания, и не сводятся к бинарному разрезу.

      </details>

А теперь представьте, что у вас есть объекты более сложной природы. Как представить в виде строк таблицы набор картинок, аудио-файлов, текстов и т.п.?

Допустим, есть черно-белые рисунки, состоящие из 9 пикселов. Для простоты представим, что они имеют один и тот же размер (3 &times; 3 = 9 пиксейлей), причем все пиксели монохромные.

![Image set](../img/img-set.png)

Самое простое — это ввести 9 бинарных признаков. Нумеруем пиксели. Получаем 9 бинарных (так как рисунки черно-белые) признаков, каждый из которых будет отвечать за цвет того или иного пикселя.

![Numbered box](../img/numbered_box.png)

!!! tip Упражнение

    Сколько вариантов квадратов 3×3 с монохромными пикселями всего возможно?

    <details>
    <summary><em>Ответ</em></summary>

    В квадрате 3×3 всего 9 пикселей. Если каждый пиксель монохромный, то у него может быть 2 состояния: черный или белый (0 или 1).

    Количество всех возможных комбинаций расположения таких пикселей вычисляется как $2^9$, так как каждый из 9 пикселей может принимать 2 состояния независимо друг от друга.

    С точки зрения комбинаторики это относится к числу сочетаний с повторениями, где каждый элемент массива (пиксель) имеет 2 возможных состояния, и они могут повторяться независимо. Это можно рассматривать как вариант размещения с повторениями — выбор из двух вариантов для каждого из 9 мест без ограничений на количество повторений.

    Формула для подсчёта количества всех возможных комбинаций для $n$ и $k$ вариантов значений каждой позиции:

    $$ k^n $$

    В данном случае: $k=2$ (черный или белый), $n=9$ (пиксели в квадрате 3×3), значит

    $$ 2^9 = 512 $$

    Итого, всего возможно 512 различных комбинаций расположения монохромных пикселей в квадрате 3×3. Это не перестановка или классическое сочетание, а именно размещение с повторениями, так как порядок в 3×3 фиксирован (позиции разные) и каждая позиция выбирает значение независимо.

    </details>


*Превращение рисунка в строку из таблицы*

| Рисунок | пр1 | пр2 | пр3 | пр4 | пр5 | пр6 | пр7 | пр8 | пр9 |
-- | -- | -- | -- | -- | -- | -- | -- | -- | --
Рис1 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 1 | 1
Рис2 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1
Рис3 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0

Аналогичным образом можно закодировать любые другие монохромные картинки (разных размеров).

!!! question Какие недостатки имеются у такого представления рисунков?

    Главный недостаток такого представления — это то, что в процессе перехода от рисунка к строке теряется информация о смежности пикселей, т.е. утрачивается информацию о том, какие пиксели были расположены рядом друг с другом. Это главная проблема подобного представления рисунков.

##### Ограничения табличного представления объектов
Таблично представление объектов накладывает различные ограничения. Самое главное ограничение — это то, что все объекты должны иметь одинаковое количество признаков (чтобы их можно было поместить в одну таблицу). Выполнить это требование не всегда легко:
1. Если объект $A$ имеет более сложную структуру (более богатую историю) чем $B$.
2. Если объекты $A$ и $B$ – картинки, то они должны иметь одинаковый формат и размер.
3. Что делать если объекты имеют совершенно разную структуру (форму)? Например, это актуально для земельных участков.


### Заключение
В заключение, большие данные – это не просто термин или модный тренд. Это катализатор технологического прогресса и новое направление в развитии информационных технологий, которое уже сейчас определяет будущее нашего цифрового мира.[^mashinnoe-obuchenie-i-big-data]

##### Выводы
- Данные машине подаются в виде таблиц.
- Каждый объект в таблице описывается с помощью набора признаков.
- Признаки бывают разного типа.

### Практическая работа. Представление признаков в табличной форме

#### Задание
Сформировать таблицу с выборкой, содержащей признаки рисунков в соответствии со своим индивидуальным вариантом. Образец (вариант 0) представлен в прилагаемом файле *task_01.xlsx*, содержащем исходные данные по вариантам, в том числе индивидуально для каждого студента по группам (на соответствующих листах).

Задание представить в виде заполненного файла (свой фрагмент) в соответствии с представленным образцом.

### Глоссарий
Big Data
: крупные массивы разнообразной информации и стек специальных технологий для работы с ней. Термин применяется к таким объемам данных, с которыми пользовательский компьютер и офисные программы не справятся. С помощью анализа больших данных бизнес может получить возможность принимать решения по развитию продукта и завоевывать конкурентное преимущество.

Business Intelligence (BI)
: технология аналитики, которая призвана предоставлять компании доступ к целостной картине деятельности в режиме реального времени. BI-системы отображают ключевые метрики, формируют детализированные отчёты и помогают ориентироваться в изменениях, оказывая поддержку при принятии стратегических решений.

Dashboarding
: визуальное представление показателей, помогающее отслеживать изменения в режиме реального времени. Гибкие дашборды упрощают работа с ключевыми метриками и улучшают процессы управления, за счет чего повышается понимание текущих тенденций и возможностей компании.

Data Lake (озеро данных)
: данные в хранилище поступают непрерывно в неструктурированном или, наоборот, структурированном или слабоструктурированном виде. Используется для сбора данных из разных источников в режиме реального времени.

Data Mart (витрина данных)
: хранилище данных, предназначенных для повседневного использования. Поступающую информацию необходимо тщательно обрабатывать, но после этого к ней проще регулярно обращаться.

Data Science (наука о данных)
: методология, в рамках которой применяются машинное обучение и нейронные сети. Такой подход помогает создавать модели для прогнозирования спроса, удержания аудитории или оптимизации маркетинговых кампаний, задействуя весь доступный объем данных.

Data Vault (свод данных)
: одна из моделей хранилища Data Warehouse с временными отметками размещения данных, которые позволяют проследить изменение хранимой информации во времени.

DAS (англ. *Direct-attached storage* — система хранения данных с прямым подключением, дисковое хранилище)
: запоминающее устройство, непосредственно подключённое к серверу или рабочей станции, без помощи сети хранения данных. Это ретроним, используемый в основном для отличия несетевых устройств хранения от SAN и NAS. Де-факто DAS — это быстрое (если интерфейс быстрый) локальное хранилище, доступное только тому устройству, к которому оно подключено. Жёсткий диск внутри ПК тоже своего рода DAS. DAS часто называют «островами информации».

Data Lake (*озеро данных*)
: технология для получения и управления данными в разных форматах: в необработанном, неупорядоченном или, наоборот, структурированном или слабоструктурированном виде, в едином репозитории.

Data Warehouse (хранилище данных)
: единая среда хранения, рассчитанная на большой объем корпоративной информации. Представляет собой единое корпоративное хранилище с обработанной и структурированной информацией. Хранилище упрощает анализ полученных данных, но требует структурированности. Грамотная архитектура DWH обеспечивает стабильную работу основных сервисов, а также сбор и консолидацию всех данных для дальнейших аналитических вычислений.

ERP-система
: конкретный программный пакет, реализующий стратегию ERP.

NAS (англ. *Network Attached Storage*, сетевое хранилище)
: сервер для хранения данных на файловом уровне. По сути представляет собой компьютер с некоторым дисковым массивом, подключённый к сети (обычно локальной) и поддерживающий работу по принятым в ней протоколам. Несколько таких компьютеров могут быть объединены в одну систему.

OLAP-кубы
: структурированный инструмент, необходимый для многомерного анализа показателей. Благодаря ему специалисты выявляют скрытые закономерности, проводят глубокую обработку информации и прогнозируют динамику развития.

SAN (англ. *Storage Area Network*, сеть хранения данных)
: архитектурное решение для подключения внешних устройств хранения данных, таких как дисковые массивы, ленточные библиотеки, оптические приводы к серверам таким образом, чтобы операционная система распознала подключённые ресурсы как локальные.

Агрегация данных (*data aggregation*)
: процесс обобщения информации в сводную форму для анализа. Агрегация в пайплайне следует после интеграции: сначала сливаются источники, затем данные суммируются. Уменьшает объём данных, ускоряя обработку без потери ключевых инсайтов. Агрегация снижает нагрузку на хранение, интеграция обеспечивает полноту. Результат — компактный датасет с метриками, удобный для отчётов и визуализации.

Аналитик (*analyst*)
: специалист, который собирает, обрабатывает и интерпретирует данные, превращая их в понятные выводы и рекомендации для принятия обоснованных решений в бизнесе, IT или других сферах.

Аналитик данных (*data analyst*)
: специалист, который собирает, обрабатывает и интерпретирует большие объемы данных, чтобы помочь компаниям принимать обоснованные решения, выявлять закономерности и тренды, оптимизировать процессы и снижать риски. По сути, он "переводит" хаотичные цифры в понятные выводы и рекомендации для бизнеса, используя статистические методы и инструменты визуализации. Данный специалист занимается проверкой статистических гипотез, проектирует и проводит эксперименты. Для этого требуются фундаментальные знания математической статистики, а также необходимо держать руку на пульсе бизнеса.

Аналитика настроений (*sentiment analysis*)
: изучение отзывов клиентов и обсуждений продукта в соцсетях, чтобы выявить слабые стороны продукта и уровень удовлетворенности потребителей.

Бизнес-аналитик (*business analyst*)
: специалист, который изучает бизнес-процессы компании, выявляет проблемы и возможности для повышения эффективности, а затем переводит потребности бизнеса на понятный язык для команд разработки, предлагая и помогая внедрять решения для достижения целей компании. Это человек, который отвечает на вопросы бизнеса, и его плотность вероятности приходится на предметную область. Он выступает связующим звеном между бизнесом и IT-специалистами, работая над оптимизацией процессов, созданием новых продуктов и принятием управленческих решений, основанных на фактах.

Бэк-офис (от англ. *back* — задняя часть)
: внутренние отделы компании, которые выполняют обслуживающие и административные функции и не взаимодействуют напрямую с клиентами и заказчиками. Среди прочего в круг задач входит оптимизация и автоматизация рабочих процессов, упразднение неэффективных операций. Фактически большинство компаний имеют бэк-офис, но не всегда выделяют его как нечто обособленное. Как правило, к бэк-офису относятся: юристы, бухгалтеры и экономисты, HR, IT-специалисты, аналитики. Существует противоположное понятие — фронт-офис. В него входят сотрудники, взаимодействующие с клиентами. В небольших компаниях обычно нет территориального разделения на фронт- и бэк-офис: все сотрудники работают в одном месте.

Бинарный признак (*binary feature*)
: номинальный признак с двумя возможными значениями.

Большие данные (*big data*)
: наборы данных настолько объёмные или сложные, что традиционные методы обработки не справляются с ними эффективно.

Данные (*data*)
: необработанные, сырые факты и цифры, не имеющие самостоятельного смысла

Инженер данных (дата-инженер, *data engineer*)
: IT-специалист, который строит и обслуживает инфраструктуру для сбора, хранения, обработки и перемещения больших объемов данных, делая их доступными и готовыми для аналитиков и ученых по данным (*Data Scientists*). Это тот человек, который занимается ETL-процессами, архитектурой хранилища, составляет витрины и поддерживает их, организовывает потоковую обработку данных. По сути, он «архитектор и строитель» мира данных, который обеспечивает надежные потоки информации, чтобы другие специалисты могли извлекать из них ценные инсайты.

Инженер машинного обучения (ML-инженер, *Machine Learning Engineer*)
: специалист, который создает, обучает и внедряет модели искусственного интеллекта (ИИ), позволяя компьютерам решать задачи, анализируя большие объемы данных без явного программирования каждого шага. Он трансформирует идеи в рабочие системы, интегрируя их в реальные бизнес-процессы, оптимизируя производительность и обеспечивая стабильную работу в продакшне, занимется введением в эксплуатацию моделей машинного обучения и поддерживает их в актуальном состоянии. Для этого требуются навыки и знания в области алгоритмов машинного обучения, ну и, конечно, разработки.

Инсайт (*insight*)
: глубокое, неожиданное понимание или ценное открытие, полученное из данных, которое приводит к практическим рекомендациям. Инсайт отличается от обычных фактов тем, что объясняет "почему" и "как использовать": например, не просто "продажи упали на 20%", а "отток вырос из-за задержек доставки в регионы X и Y". Он рождается на стыке данных, гипотез и контекста.

Интеграция даных (*data integration*)
: объединение данных из разных источников в единый набор данных (*dataset*).

Интеллектуальный анализ данных (*data mining*)
: подмножество анализа для поиска скрытых зависимостей, процесс «просеивания» больших массивов данных с целью извлечь из них ценную информацию для конкретного применения. Он является неотъемлемой частью науки о данных и бизнес-аналитики и направлен в первую очередь на поиск закономерностей.

Информация (*information*)
: обработанные, структурированные и контекстуализированные данные, которые приобретают значение и цель для пользователя.

Исследователь машинного обучения (*machine learning researcher*)
: исследователь, ориентированный на разработку новых методов и архитектур, проведение экспериментов и публикацию научных статей. Часто работает в академическом или R&D-контексте. Данный специалист в основном занимается исследовательской работой. Пишет и изучает статьи, придумывает новые математические методы.

Количественный (числовой) признак
: признак, выражаемый по своему физическому смыслу в виде некоторого вещественного (действительного) числа. Область его значений (см. область отправления и прибытия, область определения и значений) — вещественные числа, и сам признак имеет числовую природу.

Локальное развертывание (*on-premise* или *on-premises*)
: модель развертывания программного обеспечения и инфраструктуры, когда все ресурсы, включая оборудование и данные, находятся внутри компании, на её собственных серверах, а не в облаке. Локальное решение относится к программной или технологической инфраструктуре, которая устанавливается и обслуживается на собственных серверах или оборудовании компании. Локальные решения считаются более безопасными, поскольку компания имеет полный контроль над инфраструктурой, но они также могут быть более дорогостоящими и трудоемкими в управлении по сравнению с облачными или веб-решениями.

Маркетинговая аналитика (*marketing analytics*)
: изучение данных о клиентах, чтобы улучшить маркетинговые компании и разработать бизнес-инициативы.

Наука о данных (*data science*)
: междисциплинарная область, которая использует научные методы, процессы, алгоритмы и системы для извлечения знаний и инсайтов из больших и структурированных или неструктурированных данных, объединяя математику, статистику, программирование и аналитику для решения сложных задач, прогнозирования и принятия решений. По сути, это превращение хаоса сырых данных в полезную информацию, модели и прогнозы, которые используются в бизнесе, науке, медицине и других сферах. 

Номинальный (категориальный) признак
: признак, не имеющий числовой природы и, как правило, число его возможных значений конечно.

Облачное решение (*on-cloud*)
: Программное обеспечение или услуга, предоставляемая через интернет или сеть удаленных серверов. Подобное решение позволяет компаниям получать доступ и использовать программное обеспечение или сервис из любого места, где есть подключение к интернету, поскольку данные и приложения размещаются на удаленных серверах, а не на собственном компьютере пользователя или на локальных серверах. Облачные решения часто обеспечивают такие преимущества, как масштабируемость, доступность и экономичность, поскольку они не требуют поддержки аппаратной или программной инфраструктуры.

Обогащение данных (*data enrichment*)
: добавления дополнительной ценной информации к существующим наборам (например, дополняет записи новыми атрибутами из внешних источников). Отличается от агрегации расширением (добавление), а не сжатием данных.

Озеро данных (*Data Lake*)
: логическая совокупность репозиториев данных, предназначенных для хранения и анализа больших данных в их исходном формате. В отличие от традиционного понимания централизованного хранилища, Data Lake может быть распределенным по множеству физических местоположений, включая облачные платформы, on-premises инфраструктуру или гибридные среды. Концепция озера данных представляет собой эволюционный подход к управлению корпоративными данными, обеспечивающий гибкость, масштабируемость и экономическую эффективность в условиях постоянно растущих объемов информации.

Оператор машинного обучения (MLOps-инженер)
: специалист на стыке Data Science и DevOps, который автоматизирует и управляет всем жизненным циклом моделей машинного обучения (ML) — от экспериментов и разработки до развертывания (deployment), мониторинга и поддержки в промышленной эксплуатации, делая ML-системы надежными, масштабируемыми и стабильными. Он создает конвейеры (pipelines) CI/CD для моделей, контейнеризирует их, настраивает мониторинг и обеспечивает интеграцию с IT-инфраструктурой, превращая прототипы в реальные бизнес-решения. Этот человек максимально сосредоточен на разработке и развёртывании кода в продакшене.

Очистка данных (*data cleaning*)
: процесс выявления и устранения ошибок, несоответствий и "грязи" в датасетах для повышения их качества. Очистка обеспечивает точность ML-моделей, снижая шум и предвзятость. Включает следующие методы: удаление дублей, пропусков, выбросов и исправление ошибок.

Планирование ресурсов предприятия (Enterprise Resource Planning, ERP)
: организационная стратегия интеграции производства и операций, управления трудовыми ресурсами, финансового менеджмента и управления активами, ориентированная на непрерывную балансировку и оптимизацию ресурсов предприятия посредством специализированного интегрированного пакета прикладного программного обеспечения, обеспечивающего общую модель данных и процессов для всех сфер деятельности.

Пожизенная ценность клиента (*Lifetime Value*, LTV)
: метрика, показывающая, сколько денег клиент принёс компании за всё время взаимодействия с ней. Это может быть и чистая прибыль от клиента, и доход от всех его заказов. Метрику используют, чтобы понять, оправданы ли затраты на привлечение, вовлечение и удержание клиента. Другие названия показателя — CLV и CLTV: Customer Lifetime Value.

Порядковый (псевдоколичественный) признак
: не имеет числовой природы, он всего лишь задает порядок (см. отношение строгого порядка) на некотором множестве объектов.

Система управления взаимоотношениями с клиентами (CRM, CRM-система, сокращение от англ. *customer relationship management*)
: прикладное программное обеспечение для организаций, предназначенное для автоматизации стратегий взаимодействия с заказчиками (клиентами), в частности, для повышения уровня продаж, оптимизации маркетинга и улучшения обслуживания клиентов путём сохранения информации о клиентах и истории взаимоотношений с ними, установления и улучшения бизнес-процессов и последующего анализа результатов. CRM — модель взаимодействия, основанная на теории, что центром всей философии бизнеса является клиент, а главными направлениями деятельности компании являются меры по обеспечению эффективного маркетинга, продаж и обслуживания клиентов. Поддержка этих бизнес-целей включает сбор, хранение и анализ информации о потребителях, поставщиках, партнёрах, а также о внутренних процессах компании. Функции для поддержки этих бизнес-целей включают продажи, маркетинг, поддержку потребителей.

Сбор данных (*data collection*)
: процессы получения информации из различных источников для последующего анализа и использования.

Сравнительная аналитика (*competitive analytics*)
: изучение поведения потребителей и их вовлеченность в режиме реального времени, чтобы сравнить продукт компании с продуктами конкурентов.

Трансформация данных (*data transformation*)
: процесс преобразования сырых данных в удобный для анализа или хранения формат. Включает следующие методы: нормализация, кодирование категориальных переменных, масштабирование признаков.

Хранение данных (*data retention*, *data storage*)
: процессы сохранения, организации и обеспечения доступа к информации на цифровых носителях.

Хранилище данных (*Data Warehouse*, DWH)
: централизованная система, где собираются данные из разных источников: например из CRM, с сайта, из мобильного приложения и ERP. В отличие от обычной базы, которая нужна для оперативной работы приложений, например чтобы быстро оформлять заказы или собирать данные пользователей, хранилище создаётся именно для аналитики. В нём данные очищаются, приводятся к единому формату и структурируются так, чтобы их было удобно анализировать.

### Источники информации
[^38087337]: [Подскажите пожалуйста в чем заключается отличие информации от данных,и приведите примеры этих отличий](https://otvet.mail.ru/question/38087337)
[^resheniya-bi-big-data]: [Решения на основе Big Data](https://www.decosystems.ru/uslugi/resheniya-bi-big-data/)
[^chto-takoe-ltv-zachem-eye-schitat-i-kak-pravilno-eto-delat]: [Что такое LTV, зачем её считать и как правильно это делать](https://skillbox.ru/media/marketing/chto-takoe-ltv-zachem-eye-schitat-i-kak-pravilno-eto-delat/)
[^bek-ofis]: [Бэк-офис](https://netology.ru/glossariy/bek-ofis)
[^data-lake]: [Data Lake](https://bigdataschool.ru/wiki/data-lake/)
[^crm]: [Система управления взаимоотношениями с клиентами](https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0_%D1%83%D0%BF%D1%80%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B2%D0%B7%D0%B0%D0%B8%D0%BC%D0%BE%D0%BE%D1%82%D0%BD%D0%BE%D1%88%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%D0%B8_%D1%81_%D0%BA%D0%BB%D0%B8%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8)
[^810741]: [Что такое ERP?](https://habr.com/ru/articles/810741/)
[^erp]: [ERP](https://ru.wikipedia.org/wiki/ERP)
[^chto-znachit-on-premise]: [On-premise: что это, чем отличается от облака и кому подходит](https://www.fromtech.ru/blog/chto-znachit-on-premise)
[^on-premise-i-on-cloud-v-chem-raznitsa-i-chto-vybrat]: [On-premise и on-cloud: в чем разница и что выбрать](https://express.ms/blog/tekhnologii/on-premise-i-on-cloud-v-chem-raznitsa-i-chto-vybrat/)
[^datamart]: [Data Mart](https://yandex.cloud/ru/docs/glossary/datamart?utm_referrer=https%3A%2F%2Fwww.google.com%2F)
[^mashinnoe-obuchenie-i-big-data]: [Машинное обучение и большие данные](https://www.decosystems.ru/mashinnoe-obuchenie-i-big-data/)
[^OLAP]: [OLAP](https://ru.wikipedia.org/wiki/OLAP)
[^bigdata]: [Big Data](https://yandex.cloud/ru/docs/glossary/bigdata)
[^DAS]: [DAS](https://ru.wikipedia.org/wiki/DAS)
[^SAN]: [Сеть хранения данных](https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%82%D1%8C_%D1%85%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85)
[^NAS]: [NAS](https://ru.wikipedia.org/wiki/NAS_(%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80))
[^datalake]: [Data Lake](https://yandex.cloud/ru/docs/glossary/datalake?utm_referrer=https%3A%2F%2Fyndx.auth.yandex.cloud%2F)
[^business-intelligence]: [Разработка и внедрение систем бизнес-аналитики BI](https://www.decosystems.ru/uslugi/business-intelligence/)
[^557416]: [Все что вы (не) хотели знать о Data Science](https://habr.com/ru/companies/citymobil/articles/557416/)
