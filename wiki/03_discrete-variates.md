<link href="../styles.css" rel="stylesheet" />

## 3. Характеристики дискретных величин

- [3. Характеристики дискретных величин](#3-характеристики-дискретных-величин)
  - [Основные понятия теории вероятности](#основные-понятия-теории-вероятности)
  - [Числовые характеристики ДСВ](#числовые-характеристики-дсв)
    - [Размах](#размах)
    - [Математическое ожидание](#математическое-ожидание)
    - [Дисперсия](#дисперсия)
    - [Среднее квадратическое отклонение](#среднее-квадратическое-отклонение)
    - [Мода](#мода)
    - [Медиана](#медиана)
    - [Начальные моменты](#начальные-моменты)
    - [Центральные моменты](#центральные-моменты)
  - [Задание](#задание)

Наша дальнейшая работа будет тесно связана с основными понятиями теории вероятности и математической статистики. Давайте вспомним основные моменты (или познакомимся с ними).

Во втором случае я вам выдаю задание, вы его делаете, и мы приступаем к изучению характеристик признаков. Во втором случае мы разбираем основные понятия теории вероятности, после чего вы уже выполняете предложенное задание.

### Основные понятия теории вероятности
<dfn title="теория вероятностей">Теория вероятностей</dfn> — это раздел математики, который изучает закономерности случайных явлений, такие как случайные события и случайные величины, а также их вероятности и свойства. Она помогает предсказывать шанс наступления различных событий, когда результат не всегда однозначен, учитывая множество влияющих факторов. Теория вероятностей применяется в различных областях, включая прогнозирование, страхование, экономику, биологию, информатику и др., для анализа и предсказания случайных процессов и явлений.

*[СЭ]: случайный эксперимент

<dfn title="случайный эксперимент">Случайный эксперимент</dfn> (СЭ) — это многократно воспроизводимый процесс или испытание, результат которого заранее точно неизвестен и зависит от случайных факторов. Его повторение при одних и тех же условиях может дать разные исходы.

<dfn title="исход">Исход</dfn> ($\omega$) — это один конкретный результат случайного эксперимента. Например, при бросании кубика исходом может быть выпадение числа 3.

<dfn title="пространство исходов">Пространство</dfn> (<dfn title="множество исходов">множество</dfn>) исходов (или <dfn title="пространство элементарных событий">пространство элементарных событий</dfn>) — это множество всех возможных различных исходов случайного эксперимента.

$$ \Omega = \{w_1, \dots, w_n\} $$

Элемент этого множества называется <dfn title="элементарное событие">элементарным событием</dfn> или <dfn title="исход">исходом</dfn>.

Например, для СЭ — бросания игральных костей:

$$ \Omega = \{1, 2, 3, 4, 5, 6\} $$

Количество элементов множества исходов называется <dfn title="мощность пространства исходов">мощностью пространства исходов</dfn>:

$$ N = | \Omega | $$

<dfn title="случайное событие">Случайное событие</dfn> — совокупность некоторых исходов. <dfn title="случайное событие">Случайное событие</dfn> — событие, которое при проведении эксперимента может произойти или не произойти, то есть его наступление зависит от случайных факторов. Например, выпадение четного числа при бросании кубика — случайное событие (обозначим его $A$):

$$ A = \{2, 4, 6\} $$

Случайное событие — это исход эксперимента или множество исходов, которые либо произошли, либо могут произойти. Это качественное понятие, описывающее факт наступления или ненаступления какого-то события. Например, «выпала четная цифра» при бросании кубика или «выпал орел» при подбрасывании монеты.

<dfn title="достоверное событие">Достоверное событие</dfn> — событие, которое при проведении эксперимента обязательно происходит. Вероятность такого события равна 1. Например, «выпадет число от 1 до 6» при бросании шестигранного кубика (обозначим его $B$):

$$ B = \Omega $$

<dfn title="невозможное событие">Невозможное событие</dfn> — событие, которое при проведении эксперимента не может произойти. Вероятность такого события равна 0. Например, «выпадет 7» при бросании шестигранного кубика.

$$ C = \emptyset $$

<dfn title="классическое определение вероятности">Классическое определение вероятности</dfn> — вероятность случайного события $A$ равна отношению числа благоприятных ему исходов $m$ к общему числу равновозможных исходов $n$:

$$ p(A) = \frac{m}{n} $$

при этом $0 \leq p(A) \leq 1$, где $0$ — вероятность невозможного события, а $1$ — достоверного.

*[СВ]: случайная величина
*[ДСВ]: дискретная случайная величина
*[НСВ]: непрерывная случайная величина
*[ТВ]: теория вероятности

<dfn title="случайная величина">Случайная величина</dfn> (СВ) $\xi$ или $X$ — это функция, ставящая в соответствие пространству (случайных) событий множество действительных чисел:

$$ \Omega \xrightarrow{\xi} R $$

Случайная величина — это числовая функция, которая каждому исходу случайного эксперимента сопоставляет число. Она количественно выражает результат эксперимента. Например, случайная величина может характеризовать число очков на кубике или продолжительность жизни объекта.

Отличие случайной величины от исхода заключается в следующем:

- Исход (или элементарный исход) — это конкретный результат случайного эксперимента, который происходит в реальности. Например, при бросании кубика исходом может быть выпадение числа 3.

- Случайная величина — это функция, которая каждому исходу сопоставляет численное значение. Другими словами, случайная величина — это численное отображение исходов случайного эксперимента. Например, можно определить случайную величину как "число, выпавшее на кубике", которая принимает значения 1, 2, ..., 6.

Например, цвет пикселя изображения (красный, синий, желтый и т.п.) — это конкретный исход, то есть одна из возможных категорий (значений) случайного эксперимента. А численная характеристика этого цвета (код цвета, например RGB-код) — это случайная величина, которая каждому исходу (цвету) ставит в соответствие числовое значение.

Случайная величина отображает качественный признак с помощью чисел, что позволяет использовать математические методы для анализа изображений. Таким образом, исход — это элементарное событие, а случайная величина — функция на множестве исходов, принимающая числовые значения и описывающая итоги эксперимента с числовой точки зрения.

Виды случайных величин:

- дискретные (ДСВ): $\{0, 1, 2, 3\}$
- непрерывные (НСВ): $x \in [0;50]$

В дальнейшем мы в основном будем иметь дело с ДСВ.

<dfn title="закон распределения случайной величины">Закон распределения случайной величины</dfn> — это правило или соотношение, которое устанавливает связь между всеми возможными значениями случайной величины и соответствующими им вероятностями. Он показывает, с какой вероятностью случайная величина принимает те или иные значения.

Для дискретной случайной величины закон распределения обычно задаётся таблицей (<dfn title="ряд распределения">рядом распределения</dfn>), в которой перечислены все возможные значения случайной величины (обычно в порядке возрастения) и вероятности их наступления. Ряд распределения имеет следующий вид:

| $x$ | $x_1$ | $x_2$ | $\dots$ | $x_n$
-- | -- | -- | -- | -- |
$p$ | $p_1$ | $p_2$ | $\dots$ | $p_n$

При этом $\sum{p} = 1$.

Формально, <dfn title="закон распределения">закон распределения</dfn> — это функция, которая каждой точке множества значений случайной величины сопоставляет вероятность того, что величина примет это значение. Закон распределения можно задать *аналитически*, *таблично* или *графически*.

Закон распределения служит полным описанием вероятностного поведения случайной величины. Другими словами, он дает полную информацию о случайной величине.

<dfn title="функция распределения случайной величины">Функция распределения случайной величины</dfn> — это функция $F(x)$, которая для каждого числа $x$ даёт вероятность того, что случайная величина $\xi$ примет значение, меньшее или равное $x$:

$$ F(x) = p(\xi \leq x) $$

либо строго меньшее $x$:

$$ F(x) = p(\xi < x) $$

Другими словами, функция распределения показывает накопленную вероятность того, что случайная величина не превысит заданного значения $x$. Она характеризует распределение вероятностей случайной величины и является неубывающей функцией, принимающей значения от 0 (при $x → −∞$) до 1 (при $x→+∞$).

Например, возмьмем следующий ряд распределения:

| $x$ | -2 | 1 | 5 | 10 |
-- | -- | -- | -- | -- | --
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$$
F(x) =
\begin{cases}
x \leq -2; & 0\\
-2 < x \leq 1; & 0.3 = 0 + 0.3\\
1 < x \leq 5; & 0.5 = 0 + 0.3 + 0.2\\
5 < x \leq 10; & 0.6 = 0 + 0.3 + 0.2 + 0.1\\
x > 10; & 1 = 0 + 0.3 + 0.2 + 0.1 + 0.5
\end{cases}
$$

*[CDF]: Cumulative Distribution Function

Функцию распределения часто называют <dfn title="интегральная функция распределения">интегральной функцией распределения</dfn> или <dfn title="кумулятивная функция распределения">кумулятивной функцией распределения</dfn> (CDF).

<div style="padding: 10px; background: white">

![](../img/distribution_fn.png)

</div>

Основные свойства функции распределения:

- $0≤F(x)≤1$ для всех $x$.
- Неубывающая функция по $x$.
- Непрерывна слева.
- $lim_{x→−∞}{F(x)}=0$, $lim_{x→+∞}{F(x)}=1$.

Функция распределения дает полную информацию о случайной величине. $F(x)$ — это и есть вероятность по своей сути.

С помощью функции распределения можно вычислять вероятность того, что случайная величина попадёт в определённый интервал, используя разность значений функции в концах интервала.

В более распространённой формулировке функцию распределения определяют как вероятность того, что случайная величина примет значение меньше или равно $x$ (то есть $P(\xi≤x)$). Разница между этими двумя определениями невелика и связана с вопросами непрерывности функции распределения: для дискретных случайных величин эти определения отличаются тем, включается ли вероятность для значения $x$ в саму функцию, для непрерывных случайных величин разница исчезает.

То есть, оба варианта определения функции распределения встречаются в литературе, и выбор зависит от контекста. В любом случае функция распределения — это неубывающая функция, которая накапливает вероятность появления случайной величины до точки $x$.

### Числовые характеристики ДСВ
*[МО]: математическое ожидание
*[СКО]: среднее квадратическое отклонение

Распространенные числовые характеристики дискретной случайной величины:

- **Размах случайной величины**: разность между её наибольшим и наименьшим значениями.

- **Математическое ожидание $M(X)$**: средневзвешенное значение величины, центральная мера сдвига. Это среднее арифметическое случайной величины.

- **Дисперсия $D(X)$**: мера разброса значений относительно математического ожидания.

- **Среднее квадратическое отклонение (СКО) $σ(X)$**: корень квадратный из дисперсии, удобная мера изменчивости в тех же единицах, что и сама величина.

- **Моменты (начальные и центральные)**: характеристики формы распределения, включающие асимметрию и куртозис. <dfn title="куртозис">Куртозис</dfn> — это числовая характеристика, которая измеряет степень остроты пика распределения случайной величины и форму его хвостов по сравнению с нормальным распределением. Куртозис показывает, насколько распределение имеет тяжелые или легкие хвосты, то есть вероятность наличия экстремальных значений (выбросов).

- **Мода**: наиболее вероятное значение.

- **Медиана**: значение, делящее распределение на две равные части.

- **Коэффициент вариации**: отношение среднего квадратического отклонения к математическому ожиданию, выраженное в процентах, показывает относительную изменчивость.

Таким образом, эти характеристики дают комплексное представление о среднем значении, вариабельности и форме распределения дискретной случайной величины.

#### Размах
<dfn title="размах случайной величины">Размах случайной величины</dfn> — это разность между её наибольшим и наименьшим значениями.

То есть, если случайная величина $X$ принимает значения от $x_{min}$ до $x_{max}$, то размах $W$ определяется как

$$ W = x_{max} - x_{min}. $$

Размах обычно используется как мера вариабельности и показывает ширину диапазона значений случайной величины. В статистике для выборки размах — это простая разница между максимальным и минимальным элементами выборки.

В теории вероятностей размах сам по себе является случайной величиной (если рассматриваются выборочные моменты) и имеет собственное распределение. Этот показатель применяется, например, для оценки дисперсии или стандартного отклонения, особенно в контроле качества и статистике.

Таким образом, размах — одна из простейших числовых характеристик, позволяющих оценить разброс случайной величины.

#### Математическое ожидание
Среднее арифметическое случайной величины в теории вероятностей называется **математическим ожиданием**. Это сумма всех возможных значений случайной величины, взвешенная по соответствующим вероятностям этих значений.

<dfn title="математическое ожидание">Математическое ожидание</dfn> (МО) (среднее) $M(X)$ или $E(X)$ — это среднее (взвешенное по вероятностям) значение случайной величины, отражающее её центр распределения. Для дискретной случайной величины вычисляется как сумма произведений значений на вероятности. Оно показывает средний ожидаемый результат (среднее значение величин $x$ с учетом их весов — вероятности).

Для ряда распределения
$x$ | $x_1$ | $x_2$ | $\dots$ | $x_n$
-- | -- | -- | -- | -- |
$p$ | $p_1$ | $p_2$ | $\dots$ | $p_n$

$\sum{p} = 1$.

$$ M(X) = x_1 p_1 + x_2 p_2 + \dots + x_n p_n = \sum_{i=1}^n{x_n p_n} $$

Это и есть вероятность-взвешенное среднее, которое описывает центр распределения случайной величины.

$x$ | -2 | 1 | 5 | 10
-- | -- | -- | -- | -- |
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$$ M(X) = -2 \cdot 0.3 + 1 \cdot 0.2 + 5 \cdot 0.1 + 10 \cdot 0.4 = 4.1 $$

Свойства МО (свойства линейности):

- $M(c) = c$, где $c$ — константа;
- $M(c \cdot X) = c \cdot M(X)$ — константу можно вынести за скобки;
- $M(X \pm Y) = M(X) \pm M(Y)$ — МО алгебраической суммы двух независимых случайных величин равно алгебраической сумме их МО.

Свойство линейности математического ожидания означает, что математическое ожидание сохраняет операцию сложения и умножения на константу. Формально, если $X$ и $Y$ — случайные величины, а $a$ и $b$ — константы, то выполняется равенство:

$$ M(aX+bY)=aM(X)+bM(Y). $$

Это означает, что математическое ожидание суммы случайных величин равно сумме их математических ожиданий, при этом константы можно выносить за знак математического ожидания. Благодаря линейности можно упростить вычисления и анализ случайных величин.

Таким образом, среднее арифметическое для случайной величины — это математическое ожидание, одно из самых важных числовых характеристик в теории вероятностей и статистике.

#### Дисперсия
<dfn title="дисперсия">Дисперсия</dfn> $D(X)$ — мера разброса значений случайной величины относительно её математического ожидания. Равна среднему арифметическому квадратов отклонений от математического ожидания:

$$ D(X) = M\left((X-M(X))^2 \right) $$

Чем меньше дисперсия, тем стабильнее значения случайной величины. Дисперсия показывает, насколько в среднем значения сосредоточены, сгруппированы около $M(X)$: если дисперсия маленькая — значения сравнительно близки друг к другу, если большая — далеки друг от друга

$$
D(X) = M\left((X-M(X))^2 \right) =\\[2ex]
\text{Раскроем скобки внутри математического ожидания в исходной формуле:}\\[2ex]
= M\left(X^2 - 2x \cdot M(X) + (M(X))^2\right) =\\[2ex]
\text{Применим линейность (третьей свойство МО) математического ожидания:}\\[2ex]
= M(X^2) - 2M\left(X \cdot M(X)\right) + M\left((M(X))^2\right).\\[2ex]
\text{Так как } M(X) \text{— это константа по отношению к случайной величине }X\text{, то:}\\[2ex]
M\left(X \cdot M(X)\right) = M(X) \cdot M(X) = \left(M(X)\right)^2,\\[2ex]
M\left((M(X))^2\right) = \left(M(X)\right)^2\\[2ex]
\text{с учетом этих преобразований:}\\[2ex]
D(X) = M(X^2) - 2\left(M(X)\right)^2 + \left(M(X)\right)^2 = M(X^2) - \left(M(X)\right)^2.
$$

Таким образом, дисперсия равна разности между математическим ожиданием квадрата случайной величины и квадратом её математического ожидания.

Вторая формула для дисперсии $D(X)=M(X^2)−(M(X))^2$ более удобна для вычислений, потому что позволяет вычислять дисперсию через два математических ожидания, которые часто проще считать отдельно:

- $M(X)$ — математическое ожидание самой случайной величины;
- $M(X^2)$ — математическое ожидание квадрата случайной величины.

Такой подход упрощает вычисления, особенно если значение случайной величины задано таблицей значений и вероятностей или функцией плотности. Можно сначала найти $M(X)$, затем $M(X^2), и подставить в формулу, избегая вычисления отклонений $X−M(X)$ для каждого значения.

Кроме того, вторая формула удобна для работы с теорией моментов и при доказательствах, а также для анализа случайных величин с помощью начальных моментов. Это универсальная и более практичная форма для анализа и расчетов дисперсии.

Математическое ожидание $M(X−M(X))=0$ потому, что $M(X)$ — это константа (число), а математическое ожидание обладает свойством линейности. По свойствам математического ожидания:

$$ M(X−M(X))=M(X)−M(M(X))=M(X)−M(X)=0. $$

То есть математическое ожидание отклонения случайной величины от её среднего равно нулю. Это отражает то, что в среднем отклонения компенсируются друг другом — положительные и отрицательные смещения в сумме дают ноль.

$x$ | -2 | 1 | 5 | 10
-- | -- | -- | -- | -- |
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$$ M(x) = -2 \cdot 0.3 + 1 \cdot 0.2 + 5 \cdot 0.1 + 10 \cdot 0.4 = 4.1 $$

$$ M(x^2) = (-2)^2 \cdot 0.3 + 1^2 \cdot 0.2 + 5^2 \cdot 0.1 + 10^2 \cdot 0.4 = 1.2 + 0.2 + 2.5 + 40 = 43.9 $$

$$ D(x) = 43.9 - 4.1^2 = 27.09 > 0 $$

Свойства (дисперсии):

- $D(X) \geq 0$ — всегда неотрицательна;
- $D(c) = 0$, где $c$ — константа;
- $D(c \cdot X) = c^2 \cdot D(X)$ — константу можно вынести за скобки (с квадратом);
- $D(X \pm Y) = D(X) + D(Y)$ — дисперсия _алгебраической_ суммы двух независимых случайных величин равна _арифметической_ сумме их дисперсий (см. ниже).

$$ D(x-y) = D(x + (-y)) = D(x) + D(-y) =\\[2ex] D(x) + D(-1 \cdot y) = D(x) + (-1)^2 \cdot D(y) = D(x) + D(y) $$

Дисперсия неудобна тем, что имеет размерность в квадрате исходной величины, что затрудняет интерпретацию и сравнение с исходными данными. Например, если измеряется рост в метрах, дисперсия выражена в квадратных метрах, что не имеет прямого физического смысла. Из-за этого для оценки разброса часто применяют стандартное отклонение (СКО) — это корень квадратный из дисперсии. Стандартное отклонение имеет ту же размерность, что и исходные данные, и поэтому его восприятие и использование более наглядны и удобны в практических задачах.

#### Среднее квадратическое отклонение
<dfn title="среднее квадратическое отклонение">Среднее квадратическое отклонение</dfn> (СКО) или <dfn title="стандартное отклонение">стандартное отклонение</dfn> $\sigma(X)$ — это статистическая характеристика, которая показывает среднюю степень разброса значений случайной величины относительно её математического ожидания (среднего). Оно определяется как квадратный корень из дисперсии:

$$\sigma(X) = \sqrt{D(X)} $$

СКО измеряется в тех же единицах, что и сама случайная величина, что делает его более наглядным и удобным для интерпретации по сравнению с дисперсией. Чем выше значение СКО, тем сильнее разброс данных вокруг среднего значения. Это ключевой показатель в статистике для оценки изменчивости данных, построения доверительных интервалов и проверки гипотез. Кроме того, СКО облегчает интерпретацию, позволяет прямое сравнение с самим средним значением и другими показателями, что делает его предпочтительной мерой разброса данных в статистике и анализе.

$x$ | -2 | 1 | 5 | 10
-- | -- | -- | -- | -- |
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$$ \sigma(X) = \sqrt{27.09} \approx 5.20\ $$

#### Мода
<dfn title="мода">Мода</dfn> $m_0$ — это значение, которое встречается наиболее часто в наборе данных или наблюдений (наивероятнейший $x$, т.е. $x$ с наибольшей вероятностью). Она показывает, какое значение является самым распространённым среди всех, и отражает "типичное" или "характерное" значение признака.

$x$ | -2 | 1 | 5 | 10
-- | -- | -- | -- | -- |
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$m_0 = 10$

Мода может быть одной (<dfn title="унимодальное распределение">унимодальное распределение</dfn>), нескольких (<dfn title="мультимодальное распределение">мультимодальное распределение</dfn>) или не определяться, если все значения встречаются с одинаковой частотой.

Для номинальных данных (например, цвета, фамилии) мода — это категория с наибольшей частотой. Для интервальных данных мода определяется как значение или интервал с максимальной частотой.

Мода полезна для понимания наиболее популярного, часто встречающегося результата в выборке, что важно при анализе и принятии решений, например, для определения самых востребованных товаров или предпочтений.

#### Медиана
<dfn title="медиана">Медиана</dfn> $m_e$ — это статистическая характеристика, которая делит упорядоченный набор данных на две равные части: половина значений меньше медианы, а другая половина — больше. Если данные упорядочить по возрастанию, медиана будет находиться посередине этого ряда.

Если количество наблюдений нечётное, медиана — это средний элемент упорядоченного ряда. Если чётное — медиана вычисляется как среднее арифметическое двух средних элементов.

$x$ | -2 | 1 | 5 | 10
-- | -- | -- | -- | -- |
$p$ | 0.3 | 0.2 | 0.1 | 0.4

$m_e = \frac{1 + 5}{2} = 3$

Таким образом, для случайной величины медиана — это такое число, при котором вероятность получить значение меньше или больше этой точки равна 0,5. Медиана характеризует центр распределения и является устойчивой мерой центральной тенденции, менее чувствительной к выбросам и асимметрии, чем среднее арифметическое.

#### Начальные моменты
<dfn title="начальные моменты случайной величины">Начальные моменты случайной величины</dfn> $\nu_k(X)$ — это числовые характеристики распределения, определяемые как математическое ожидание степени случайной величины. Формально, начальный момент порядка $k$ случайной величины $x$ определяется как:

$$ v_k(X) = M(X^k) $$

или

$$ v_k = M(X^k) $$

где $M$ — оператор математического ожидания, а $k$ — натуральное число (<dfn title="порядок момента">порядок момента</dfn>).

$
\nu_1(X) = M(X)\\
\nu_2(X) = M(X^2)\\
\nu_3(X) = M(X^3)\\
\nu_4(X) = M(X^4)\\
\dots\\
\nu_k(X) = M(X^k)
$

Таким образом, первый начальный момент $ν_1=M(X)$ — это математическое ожидание самой случайной величины, а второй начальный момент $ν_2=M(X^2)$ используется в вычислениях дисперсии.

Начальные моменты дают информацию о положении и форме распределения случайной величины и служат основой для вычисления других характеристик, таких как дисперсия и асимметрия.

#### Центральные моменты
<dfn title="центральные моменты">Центральные моменты</dfn> $\mu_k(X)$ — это числовые характеристики случайной величины, которые измеряют распределение отклонений этой величины от её математического ожидания (среднего). Центральный момент порядка $k$ определяется как математическое ожидание $k$-й степени разности между случайной величиной $X$ и её средним значением:

$$ \mu_k(X) = M\left((X - M(X))^k\right) $$

или

$$ \mu_k = M\left((X - M(X))^k\right) $$

$
\mu_1(X) = M(X - M(X)) = 0\\
\mu_2(X) = M\left((X - M(X))^2\right) = D(x) = M(X^2)−(M(X))^2 = \nu_2 - \nu_1^2\\
\mu_3(X) = M\left((X - M(X))^3\right) = \nu_2 - 3 \nu_1 \nu_2 + 2 \nu_1^3\\
\mu_4(X) = M\left((X - M(X))^4\right) = \nu_4 - 4 \nu_1 \nu_3 + 6 \nu_1^2 \nu_2 - 3 \nu_1^4\\
\dots\\
\mu_k(X) = M\left((X - M(X))^k\right)
$

Таким образом:

- первый центральный момент $μ_1$ всегда равен нулю;
- второй центральный момент $μ_2$ — дисперсия, показывающая разброс значений вокруг среднего;
- третий и четвёртый центральные моменты характеризуют асимметрию и "островершинность" распределения соответственно.

Центральные моменты важны для описания формы и особенностей распределения случайной величины, таких как его симметрия и вариабельность.

Таким образом, начальные моменты описывают основные положения и форму распределения относительно начала координат, а центральные моменты — относительно центра (математического ожидания), позволяя лучше понимать разброс, асимметрию и форму распределения.

### Задание
По заданному ряду распределения определить основные характеристики ДСВ:
- моду;
- медиану
- начальные моменты первого (математическое ожидание) и второго порядка;
- центральный момент второго порядка (дисперсию);
- среднее квадратическое (стандартное) отклонение.

Вычисленные значения проставить в соответствующих ячейках электронной таблицы. Результаты округлять до двух десятичных знаков.
