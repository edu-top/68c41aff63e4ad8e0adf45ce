<link href="../styles.css" rel="stylesheet" />

## Восстановление пропусков

- [Восстановление пропусков](#восстановление-пропусков)
  - [Постановка проблемы](#постановка-проблемы)
  - [Механизмы формирования пропусков](#механизмы-формирования-пропусков)
  - [Методы устранения пропусков](#методы-устранения-пропусков)
  - [Простейшие способы устранения пропусков](#простейшие-способы-устранения-пропусков)
    - [Исключение данных](#исключение-данных)
    - [Общие принципы реализации ad-hoc импутации](#общие-принципы-реализации-ad-hoc-импутации)
    - [Пропуски в вещественных признаках](#пропуски-в-вещественных-признаках)
    - [Пропуски в категориальных и бинарных признаках](#пропуски-в-категориальных-и-бинарных-признаках)
    - [Пропуски в порядковых признаках](#пропуски-в-порядковых-признаках)
    - [Пропуски в хронологических данных](#пропуски-в-хронологических-данных)
    - [Индикатор пропуска](#индикатор-пропуска)
    - [Особенности ad-hoc методов](#особенности-ad-hoc-методов)
    - [Выбор метода заполнения пропусков](#выбор-метода-заполнения-пропусков)
  - [Оценка качества восстановления данных](#оценка-качества-восстановления-данных)
    - [Количественные метрики](#количественные-метрики)
      - [Средняя абсолютная ошибка (MAE)](#средняя-абсолютная-ошибка-mae)
      - [Средняя абсолютная процентная ошибка (MAPE)](#средняя-абсолютная-процентная-ошибка-mape)
      - [Средняя квадратическая ошибка (MSE)](#средняя-квадратическая-ошибка-mse)
      - [Корень из среднеквадратической ошибки (RMSE)](#корень-из-среднеквадратической-ошибки-rmse)
      - [Интерпретация результатов](#интерпретация-результатов)
      - [Выбор метрики](#выбор-метрики)
    - [Сравнение распределений](#сравнение-распределений)
    - [Кросс-валидация и диагностика](#кросс-валидация-и-диагностика)
    - [Практическая реализация (Python)](#практическая-реализация-python)
  - [Заключение](#заключение)
  - [Практическая работа. Восстановление данных с помощью простых методов](#практическая-работа-восстановление-данных-с-помощью-простых-методов)
  - [Дополнительные источники](#дополнительные-источники)
  - [Источники информации](#источники-информации)

*[MICE]: Multiple/Multivariate Imputation by Chained Equations
*[MCAR]: Missing Completely At Random
*[MAR]: Missing At Random
*[MNAR]: Missing Not At Random
*[LOCF]: Last observation carried forward

### Постановка проблемы
Идеальные данные бывают лишь в теории. На практике не существует наборов без пропусков или некорректных значений. На практике в реальных данных очень часто встречаются пропуски. Причинами могут быть ошибки ввода данных, сокрытие информации, фрод.  Отвечать на вопрос "Кто в этом виноват?" бесполезно, поэтому в этом разделе мы затронем лишь вопрос "Что с этим делать?"

Очень редко в жизни встречаются таблицы с данными, в которых все ячейки заполнены корректными значениями. Гораздо чаще встречаются таблицы, в которых часть ячеек вообще пустая, а другая часть может быть заполнена заведомо некорректными значениями, противоречащими здравому смыслу? Естественно возникает вопрос: "А что делать в этом случае? Как бороться с пустыми ячейками или ячейками, заполненными заведомо недостоверными данными?" Ниже демонстрируется таблица, часть ячеек которой не заполнена, а часть содержит заведомо некорректные значения.

Студент | Пол | Рост | Вес | Место на олимпиаде
-- | -- | -- | -- | --
Иванов | 1 | 172 | 107 | 3
Запеканка | **?** | 185 | 64 | **-4**
Ватрушкина | 0 | 168 | **666** | 2
Ололоева | 0 | **?** | 85 | 1

Видно, что в таблице могут быть незаполненные ячейки, или же содержимое некоторых ячеек заведомо некорректное и противоречит здравому смыслу. Скорее всего, данные значения являются следствием описки человека, заносившего данные в таблицу. Однако выяснение первопричин пропусков и ошибок не относится к задачам машинного обучения. Наша задача — восстановить пропущенные значения и исправить ошибочные. Какие существуют простые способы для борьбы с пропусками данных и некорректными значениями? 

Таким образом, когда мы измеряем признаки объектов, некоторые из признаков могут отсутствовать. В этом случае вектор признаков будет содержать пропуски (*missing values*). Например, если объект описывает человека по данным заполняемой анкеты, то человек мог не заполнять отдельные поля или сделать это неразборчиво. При этом большинство моделей машинного обучения требуют для обработки _полный вектор признаков без пропусков_.

### Механизмы формирования пропусков
Для того чтобы понять, как правильно обработать пропуски, необходимо определить механизмы их формирования. <dfn title="механизм пропусков">Механизм пропусков</dfn> (*missing data mechanism*) — это классификация причин отсутствия данных по модели Рубина (Rubin), определяющая, зависит ли вероятность пропуска от наблюдаемых или пропущенных значений, что влияет на выбор метода импутации.

Различают следующие 3 механизма формирования пропусков: MCAR, MAR, MNAR:

- <dfn title="полностью случайные пропуски">Полностью случайные пропуски</dfn> **MCAR** (Missing Completely At Random) — механизм формирования пропусков, при котором вероятность пропуска для каждой записи набора одинакова. Например, если проводился социологический опрос, в котором каждому десятому респонденту один случайно выбранный вопрос не задавался, причем на все остальные заданные вопросы респонденты отвечали, то имеет место механизм MCAR. В таком случае игнорирование/исключение записей, содержащих пропущенные данные, не ведет к искажению результатов. Поскольку вероятность отсутствия значения одинакова для всех записей и не зависит ни от самих данных, ни от других переменных (например, сбой оборудования), то простые методы (удаление, среднее) работают без смещения.

- <dfn title="случайные пропуски">Случайные пропуски</dfn> **MAR** (Missing At Random) — на практике данные обычно пропущены не случайно, а ввиду некоторых закономерностей. Здесь вероятность пропуска зависит от наблюдаемых данных, но не от пропущенных самих по себе (например, молодые чаще пропускают доход, но возраст известен). Пропуски относят к MAR, если вероятность пропуска может быть определена на основе другой имеющейся в наборе данных информации (пол, возраст, занимаемая должность, образование…), не содержащей пропуски. В таком случае удаление или замена пропусков на значение «Пропуск», как и в случае MCAR, не приведет к существенному искажению результатов. Подходят KNN, регрессия, MICE.

- <dfn title="неслучайные пропуски">Неслучайные пропуски</dfn> **MNAR** (Missing Not At Random) — механизм формирования пропусков, при котором данные отсутствуют в зависимости от неизвестных факторов. Здесь вероятность зависит от самих пропущенных значений или неизвестных факторов (например, богатые скрывают доход). MNAR предполагает, что вероятность пропуска могла бы быть описана на основе других атрибутов, но информация по этим атрибутам в наборе данных отсутствует. Как следствие, вероятность пропуска невозможно выразить на основе информации, содержащейся в наборе данных. Требуют специальных моделей (модели с выбором, Bayesian), удаление рискует сильным смещением.

Рассмотрим различия между механизмами MAR и MNAR на примере.

Люди, занимающие руководящие должности и/или получившие образование в престижном вузе чаще, чем другие респонденты, не отвечают на вопрос о своих доходах. Поскольку занимаемая должность и образование сильно коррелируют с доходами, то в таком случае пропуски в поле доходы уже нельзя считать совершенно случайными, то есть говорить о случае MCAR не представляется возможным.

Если в наборе данных есть информация об образовании и должности респондентов, то зависимость между повышенной вероятностью пропуска в графе доходов и этой информацией может быть выражена математически, следовательно, выполняется гипотеза MAR. В случае MAR исключение пропусков вполне приемлемо.

Однако если информация о занимаемой должности и образовании у нас отсутствует, то тогда имеет место случай MNAR. При MNAR просто игнорировать или исключить пропуски уже нельзя, так как это приведет к значительному искажению распределения статистических свойств выборки.

### Методы устранения пропусков
Простые методы подразумевают использование следующих стратегий:

- **удаление строк/столбцов**: применяется, если пропусков мало (менее 5-10%) или они сосредоточены в одном атрибуте, минимизируя потери информации, при этом минимизирует искажения, но уменьшает объем данных;
- **замена средним, медианой или модой**: заполняет пропуски статистическими мерами по столбцу, подходит для числовых или категориальных данных с нормальным/симметричным распределением;
- **замена константой или нулем**: использует фиксированное значение, простое для категориальных переменных, но может вносить смещение;
- **интерполяция и экстраполяция**: восстанавливает значения на основе соседних точек в упорядоченных данных, например, временных рядах.​

Продвинутые методы:
- **регрессионная импутация** предсказывает значения с помощью линейной регрессии на основе других признаков, учитывая их взаимосвязи, а **стохастическая** добавляет шум для реалистичности;
- **KNN** (k-ближайших соседей) находит похожие строки и усредняет значения из похожих строк по евклидову расстоянию, эффективно для многомерных данных;
- **MICE** (множественная импутация на основе марковских цепей) генерирует несколько версий датасета для учета неопределенности, а datawig использует нейросети для дискретных значений;
- **глубокое обучение** (нейросети через библиотеки вроде datawig) обучается на полных записях для предсказания отсутствующих значений, особенно полезно для категориальных данных.

### Простейшие способы устранения пропусков
Рассмотрим популярные методы восстановления для различных типов данных.[^Data-imputation]

#### Исключение данных
Часто в данных, с которыми необходимо работать, присутствуют пропуски, в результате чего аналитик оказывается перед выбором: игнорировать, отбросить или же заполнить пропущенные значения. Заполнение пропусков зачастую и вполне обоснованно кажется более предпочтительным решением. Однако это не всегда так. Неудачный выбор метода заполнения пропусков может не только не улучшить, но и сильно ухудшить результаты.[^missing]

Простейшим выходом при работе с пропусками могло бы быть исключение всех объектов, у которых хотя бы один из признаков не указан. При данном подходе удаляются строки таблицы (*объекты*), содержащие пропущенные или некорректные значения. Этот приём подходит, если число объектов с пропущенными значениями невелико относительно общего объема выборки (число пропусков менее 5-10%). Если же таких объектов много, то нужно выработать **метод заполнения пропущенных значений** (*missing data imputation*). <dfn title="импутация">Импутация</dfn> — это процесс заполнения пропущенных значений в датасетах для машинного обучения, чтобы сохранить объем данных и избежать искажений в моделях.

Другим вариантом является удаление столбца таблицы (*признака*), содержащего ошибки и пропуски, особенно в том случае, если в нём очень много пропусков. Данный метод применяется, если пропуски сосредоточены в одном атрибуте. Эти способы являются довольно-таки радикальными и применять их следует с осторожностью, потому что если в таблице будет много пустых ячеек, разбросанных более-менее равномерно по всей таблице, то удаляя объекты или признаки можно уменьшить количество и качество данных настолько, что из них уже будет невозможно извлечь интересующую нас полезную информацию. Оба рассмотренных подхода минимизирует искажения, но уменьшает объем данных.​ Поэтому рекомендуется избегать прямого удаления строк или столбцов таблицы и применять более изощренные методы восстановления данных.

<dfn title="complete-case analysis">Complete-case Analysis</dfn> (он же <dfn title="listwise deletion method">Listwise Deletion Method</dfn>) — метод обработки пропусков, применяемый во множестве прикладных пакетов как метод по умолчанию. Заключается в исключении из набора данных записей/строк или атрибутов/колонок, содержащих пропуски.

В случае первого механизма пропусков (MCAR) применение данного метода не приведет к существенному искажению параметров модели. Однако удаление строк приводит к тому, что при дальнейших вычислениях используется не вся доступная информация, стандартные отклонения возрастают, полученные результаты становятся менее репрезентативными. В случаях, когда пропусков в данных много, это становится ощутимой проблемой.

Кроме того, в случае второго (MAR) и, особенно, третьего механизма пропусков (MNAR) смещение статистических свойств выборки, значений параметров построенных моделей и увеличение стандартных отклонений становятся еще сильнее.

Таким образом, несмотря на широкое распространение, применение данного метода для решения практических задач ограничено.

<dfn title="available-case analysis">Available-case analysis</dfn> (он же <dfn title="pairwise deletion">Pairwise Deletion</dfn>) — методы обработки, основанные на игнорировании пропусков в расчетах. Эти методы, как и Complete-case Analysis, тоже часто применяются по умолчанию.

Статистические характеристики, такие как средние значения, стандартные отклонения, можно рассчитать, используя все непропущенные значения для каждого из атрибутов/столбцов. Как и в случае Complete-case Analysis, при условии выполнения гипотезы MCAR применение данного метода не приведет к существенному искажению параметров модели.

Преимущество данного подхода в том, что при построении модели используется вся доступная информация.

Главный же недостаток данных методов заключается в том, что они применимы для расчета далеко не всех показателей и, как правило, сопряжены с алгоритмическими и вычислительными сложностями, приводящими к некорректным результатам.

Например, рассчитанные значения коэффициентов корреляции могут оказаться вне диапазона [-1; 1]. Кроме того, не всегда удается однозначно ответить на вопрос об оптимальном выборе числа отсчетов, используемого при расчете стандартных отклонений.

К недостаткам первых двух методов обработки пропусков (Complete-case Analysis и Available-case analysis) относится и то, что далеко не всегда исключение строк в принципе приемлемо. Нередко процедуры последующей обработки данных предполагают, что все строки и колонки участвуют в расчетах (например, когда пропусков в каждой колонке не очень много, но при этом строк, в которых нет ни одного пропущенного поля, мало).

Исключение и игнорирование строк с пропущенными значениями стало решением по умолчанию в некоторых популярных прикладных пакетах, в результате чего у начинающих аналитиков может возникнуть представление, что данное решение — правильное. Кроме них существуют довольно простые в реализации и использовании методы обработки пропусков, получившие название ad-hoc методы, простота которых может послужить причиной их выбора.

Далее мы рассмотрим методы, которые предполагают заполнение пропусков на основе имеющейся информации. Часто эти методы объединяют в одну группу, называемую Single-imputation methods.

#### Общие принципы реализации ad-hoc импутации

> Ad hoc (дословно — «к этому») — латинская фраза, означающая «для данного случая», «специально для этого». Как правило, фраза обозначает способ решения специфической проблемы или задачи, который невозможно приспособить для решения других задач и который не вписывается в общую стратегию решений, составляет некоторое исключение. Например, закон ad hoc — это закон, принятый в связи с каким-то конкретным инцидентом или для решения какой-то особой задачи, который не вписывается в законодательную практику и не решает других схожих проблем; отдел ad hoc — это подразделение в организации, созданное для решения какой-то узкой задачи, не попадающей в сферу компетенции ни одной из постоянных структур. В некоторых случаях выражение ad hoc может иметь негативный подтекст, предполагая отсутствие стратегического планирования и реакционные непродуманные действия.[^Ad_hoc]
> 
> Ad hoc задачи — это задачи, которые возникают спонтанно и требуют немедленного решения. Обычно они не являются частью регулярного рабочего процесса или заранее запланированных мероприятий. Такие задачи могут возникать в результате неожиданных ситуаций, проблем или потребностей, которые требуют быстрого реагирования. Например, клиент изменил условия сделки и срочно нужно переделать договор, государство повысило налоги — нужно срочно пересмотреть бюджет компании.[^chto-takoe-ad-hoc-zadachi]

Ad-hoc методы (среднее, медиана, мода) применяют для быстрого заполнения пропусков в тренировочных таблицах: выбор зависит от типа признака (числовой/категориальный), распределения (симметрия/выбросы) и % пропусков (<20% для простоты). Ниже приведен шаблон на Python с обоснованиями и оценкой. Предполагаем датасет `df` с числовыми (например, `age`, `income`) и категориальными (например, `gender`) признаками. Обоснование: среднее — для симметричных числовых без выбросов; медиана — при выбросах; мода — для категориальных с majority-классом

```python
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error
import numpy as np

# Загрузка данных (замените на ваш файл)
# df = pd.read_csv('your_data.csv')

# 1. Числовой признак 'age' (<10% пропусков, нормальное распределение) — среднее
imp_mean = SimpleImputer(strategy='mean')
df['age_mean'] = imp_mean.fit_transform(df[['age']])
# Обоснование: сохраняет центр распределения без искажения при MCAR.[web:81]

# 2. Числовой 'income' (выбросы) — медиана
imp_median = SimpleImputer(strategy='median')
df['income_median'] = imp_median.fit_transform(df[['income']])
# Обоснование: устойчива к выбросам, лучше среднего для скошенных данных.[web:2]

# 3. Категориальный 'gender' (0/1, мода=0) — мода
imp_mode = SimpleImputer(strategy='most_frequent')
df['gender_mode'] = imp_mode.fit_transform(df[['gender']])
# Обоснование: сохраняет доминирующий класс, подходит при <20% пропусков.[web:81]
```

Качество оценивают метриками на тестовых пропусках (маск-аут: искусственно удалить известные значения, импутировать, сравнить): MAE/RMSE для числовых ($MAE = \frac{1}{n} \sum{|y_i - \hat{y_i}|}$), accuracy для категориальных.

```python
# Тест: маска известных, MAE
mask = ~df['age'].isna()
mae_mean = mean_absolute_error(df.loc[mask, 'age'], df.loc[mask, 'age_mean'])
print(f'MAE age (mean): {mae_mean}')  # Вывод: низкий MAE → эффективно
# Аналогично для других; медиана лучше при выбросах (MAE ниже на 10-20%).[web:81]
```

**Выводы** (обобщенные): Среднее эффективно для `age` (MAE<5%, сохраняет mean); медиана — для `income` (MAE<10%, игнорирует выбросы); мода — для `gender` (accuracy>90%, но смещает minority). Интерполяция лучше для временных рядов.

#### Пропуски в вещественных признаках
Для вещественных признаков пропуски можно заполнять

- константой;

- выборочным средним[^Arithmetic_mean];

- выборочной медианой[^Median];

Замена константой или нулем в импутации данных — это простой метод, при котором все пропущенные значения (NaN) в столбце заменяются фиксированным значением, таким как 0, -1, без учета распределения данных. Данный метод подходит для числовых данных, где отсутствие значения логически равно нулю (возраст 0 для несуществующих записей). Он быстрый и не искажает корреляции, но может вносить смещение в средние значения и снижать вариативность датасета, что вредно для моделей машинного обучения.

**Заполнение пропуска средним значением** (*Mean Substitution*) (другие варианты: заполнение нулем, медианой и тому подобные) — название метода говорит само за себя. 
Выборочные статистики считаются по присутствующим значениям признака в других объектах. Медиана более предпочтительна, поскольку является мерой оценки центра распределения, устойчивой к наличию выбросов (*robust to outliers*), в отличие от среднего.

!!! info Задача

    Оцените, насколько сильно может сместиться среднее и медиана при внесении одного очень большого или очень малого наблюдения в выборку.

Итак, для числовых признаков можно заменить значение в ячейке на среднее (медиану, моду, ...) из значений столбца. Например для ряда (столбца) значений признака $<0, 1, 2, 4, 4, 5, ?>$ последнее значение можно восстановить, заменив его на среднее ($2.67$), медиану ($3$) или моду ($4$).

> Может смутить, что малый перевес в сторону нулей в случае применения моды или медианы, увеличивает этот перевес, что может привести к ещё большему дисбалансу в сторону "большинства". Тогда, если на самом деле реальные данные соответствовали равномерному распределению объектов по полу, наблюдаемая вероятность нахождения единицы в признаке с 40 % исказится до 33 %, а не приблизится к действительной оценке в 50 %. Отсюда вопрос, применяются ли какие-то "компенсаторные" методы при восстановлении пропущенных значений? Если да, от по какому ключевому слову поискать о них информацию?
>
> В больших наборах данных метод вероятностной подстановки не приводит к смещению, т.к. нули и единицы будут генерироваться в той же пропорции. В маленькой таблице, как в этом примере, любая подставновка приведет к дисбалансу.

Всем вариантам данного метода свойственны одни и те же недостатки. Рассмотрим эти недостатки на примере одного из наиболее простых способов заполнить пропуски непрерывной характеристики: заполнения пропусков средним арифметическим значением и модой.

На рисунке 1 показано распределение значений непрерывной характеристики до заполнения пропусков средним значением и после него.

![Распределение значений непрерывной характеристики до заполнения пропусков](../img/blog_schemes_027-article-missing-data_continuous-char-val.svg)

*Рисунок 1a — Распределение значений непрерывной характеристики до заполнения пропусков*

![Распределение значений непрерывной характеристики после заполнения пропусков](../img/blog_schemes_027-article-missing-data_distortion-continuous.svg)

*Рисунок 1б — Распределение значений непрерывной характеристики после заполнения пропусков*

На рисунке 1 хорошо видно, что распределение после заполнения пропусков выглядит крайне неестественно. Это в итоге проявляется в искажении всех показателей, характеризующих свойства распределения (кроме среднего значения), заниженной корреляции и завышенной оценке стандартных отклонений.

Таким образом, данный метод приводит к существенному искажению распределения характеристики даже в случае MCAR.[^missing]

#### Пропуски в категориальных и бинарных признаках
Для категориальных признаков, принимающих одно из $K$ дискретных значений, таких как марка машины, профессия и город проживания человека пропуски можно заполнять:

- максимально частой категорией (в статистике это называется **модой распределения**, *mode imputation*);

- сгенерированным вероятностно рандомизированными значением — **стохастическая импутация по распределению** (*stochastic imputation based on empirical distribution*) или **импутацией по вероятностным весам** (*probability-weighted imputation*), где пропуски заполняются случайными значениями из наблюдаемого распределения с сохранением исходных пропорций (в примере 3/5 для 0 и 2/5 для 1);

- новой категорией — пропуск заменяется уникальной строкой ("unknown", "missing"), превращая его в отдельный класс без смещения моды; лучше моды, когда категорий много, и позволяет моделям учить "отсутствие" как сигнал;

В случае категориальной дискретной характеристики наиболее часто используется заполнение модой.

На рисунке 2 показано распределение категориальной характеристики до и после заполнения пропусков.

![Распределение дискретной характеристики до заполнения пропусков модой](../img/blog_schemes_027-article-missing-data_categorical-char-val.svg)

*Рисунок 2а — Распределение дискретной характеристики до заполнения пропусков модой*

![Распределение дискретной характеристики после заполнения пропусков модой](../img/blog_schemes_027-article-missing-data_distortion-categorical.svg)

*Рисунок 2б — Распределение дискретной характеристики после заполнения пропусков модой*

Таким образом, при заполнении пропусков категориальной характеристики модой проявляются те же недостатки, что и при заполнении пропусков непрерывной характеристики средним арифметическим (нулем, медианой и тому подобным).[^missing]

Второй подход учитывает частоты классов в столбце (эмпирическое распределение), генерируя значения случайно, но с заданными вероятностями, чтобы избежать смещения моды и сохранить вариативность данных — в отличие от простой замены на моду, которая всегда ставит majority-класс. Например, есть такой признак, как пол человека ($<0, 0, 0, 1, 1, ?>$) с пропущенным значением. Для него можно сгенерировать случайную величину, которая примет значение 0 с вероятностью 3/5 ($A = 0, p(A) = \frac{3}{5}$) или 1 с вероятностью 2/5 ($B=1, p(B) = \frac{2}{5}$). Полученное значение следует записать вместо пропуска.

Если возник вопрос как сгенерировать 0 или 1 с разной вероятностью, то на питоне можно сделать так:  `random.choices([0, 1], weights=[3/5, 2/5])[0]`. В Python это реализуется через random.choices() с weights, как указано, или в scikit-learn через комбинацию `SimpleImputer(strategy='most_frequent')` с последующей рандомизацией; в продвинутых библиотеках (`iterativeimputer`) добавляется шум для стохастичности

Для нашего примера ($<0,0,0,1,1,?>$): `random.choices([0,1], weights=[0.6,0.4])[0]` даст 0 в ~60% случаев, сохраняя баланс без искажения корреляций.​ Данный метод подходит для категориальных признаков с несбалансированными классами, лучше моды при >2 категорий, но требует осторожности с большой долей пропусков (>20%), чтобы не усилить шум.

Третий способ подразумевает использование фиксированного значение ("missing", "unknown" и т.п.), простого для категориальных переменных, что, очевидно, лучше, когда число категорий велико, и нет оснований во всех неопределённых случаях предпочитать самую частую категорию. Метод подходит для категориальных переменных, где пропуски интерпретируют как отдельную категорию (например, fill_value='unknown'), он быстрый и не искажает корреляции, но может вносить смещение в средние значения и снижать вариативность датасета, что вредно для моделей машинного обучения.

Замена константой или нулем и заполнение новой категорией — это частные случаи одного метода импутации (SimpleImputer с strategy='constant'), но они отличаются по применению: первая подходит для числовых данных (например, 0), вторая — специально для категориальных, где пропуск вводится как отдельная категория вроде "missing" или "[UNK]".

**Различия в подходах**
- **Константа/ноль для числовых**: Заполняет NaN фиксированным числом (0, -1), что логично, если пропуск означает отсутствие (например, нулевой доход), но искажает статистику и снижает вариативность.​

- **Новая категория для категориальных**: Пропуск заменяется уникальной строкой ("unknown", "missing"), превращая его в отдельный класс без смещения моды; лучше моды, когда категорий много, и позволяет моделям учить "отсутствие" как сигнал.

Более продвинутая техника заключается в предсказании пропущенной категории отдельным классификатором, обученным предсказывать значение признака с пропусками по оставшимся известным признакам. Это позволит заполнять значения не константой, а переменной величиной в зависимости от других характеристик объекта. Например, если человек не указал город проживания, но указал место работы, то его местоположение можно восстановить с некоторой точностью.[^Data-imputation]

#### Пропуски в порядковых признаках
Выбор методов импутации для порядковых данных отличается от количественных, несмотря на числовое представление: порядковые (оценки 0-5, уровень "низкий/средний/высокий") имеют дискретный порядок без равных интервалов, поэтому среднее может дать нецелые значения (например, 2.7), искажая шкалу.

Для порядковых признаков, которые имеют упорядоченные дискретные значения (например, уровни образования, рейтинги, ранги), заполнение пропусков можно выполнить следующими способами:

- заполнение выборочной медианой — медиана учитывает порядок значений и лучше отражает центральное значение для упорядоченных данных;

- заполнение наиболее частым уровнем (модой) — полезно, если распределение категорий сильно скошено;

- заполнение константой — например, одним из крайних уровней или специальным значением, обозначающим пропуск;

- импутация с помощью порядкового кодирования и моделей, учитывающих порядок — например, прогнозирование пропущенных уровней с помощью порядковых регрессий или деревьев решений;

- создание отдельной категории для пропусков, если это оправдано — особенно когда отсутствие значения само по себе может нести информацию; это превращает пропуски в отдельный класс, как в категориальных признаках.

Такой подход позволяет сохранять порядок данных и минимизировать искажения, связанные с заполнением пропусков.

#### Пропуски в хронологических данных
Для данных, полученных в хронологическом порядке, правильнее всего брать предыдущее значение, считая, что оно не изменилось. Либо брать значение за аналогичный период времени из прошлого (время суток). Данные подходы правомерно применять только для временных рядов (1 и 2 метода), имеющих компоненту цикличности (2 метода). Опять же не помешало бы при этом рассчитать скользящее среднее, а для второго варианта скорее всего более уместно будет применить что-то типа "гусеницы".

- **LOCF** (*Last observation carried forward*) — повторение результата последнего наблюдения. Данный метод применяется, как правило, при заполнении пропусков во временных рядах, когда последующие значения априори сильно взаимосвязаны с предыдущими.

- **Интерполяция и экстраполяция** — методы заполнения пропусков в хронологических данных (временных рядах), где интерполяция оценивает значения внутри известного интервала по соседним точкам, а экстраполяция — за его пределами (в начало или конец).

Рассмотрим 2 случая, когда применение LOCF обосновано.

**Случай 1**. Если мы измеряем температуру воздуха в некоторой географической точке на открытом пространстве, причем измерения проводятся каждую минуту, то при нормальных условиях — если исключить природные катаклизмы — измеряемая величина априори не может резко (на 10–20 °C) измениться за столь короткий интервал времени между последующими измерениями. Следовательно, заполнение пропусков предшествующим известным значением в такой ситуации обоснованно.

**Случай 2**. Если данные представляют собой результаты измерения (допустим, той же температуры воздуха) в один и тот же момент времени в близких географических точках таким образом, что гипотеза о малых изменениях значений от одной точки набора данных до другой остается справедливой, то опять же использование LOCF логично.

> Ситуации, когда использование LOCF обосновано, не ограничиваются только этими двумя случаями.

Хотя в описанных выше ситуациях метод логичен и обоснован, он тоже может привести к существенным искажениям статистических свойств даже в случае MCAR [Molenberghs, 2007]. Так, возможна ситуация, когда применение LOCF приведет к дублированию выброса (заполнению пропусков аномальным значением). Кроме того, если в данных много последовательно пропущенных значений, то гипотеза о небольших изменениях уже не выполняется и, как следствие, использование LOCF приводит к неправильным результатам.

<dfn title="линейная интерполяция">Линейная интерполяция</dfn> строит прямую между соседними точками: для значений $y_0$ в $x_0$ и $y_1$ в $x_1$ пропуск в $x$ заполняется как:

$$ y = y_0 + \frac{(y_1-y_0)(x-x_0)}{x_1-x_0} $$

Полиномиальная (квадратичная, кубическая) или сплайн-интерполяция использует кривые для трендовых данных, минимизируя осцилляции (феномен Рунге); в pandas: `df.interpolate(method='linear')` или `'cubic'`. Для временных индексов применяется `method='time'`, учитывая даты.

<dfn title="экстраполяция">Экстраполяция</dfn> продлевает тренд за интервал: линейная — по последней/первой паре точек, полиномиальная — с риском ошибок из-за неопределенности; в pandas через `limit_direction='both'` или `'forward/backward'` с `limit_area='outside'`. Подходит для прогнозирования на краях ряда, но менее точна, чем интерполяция, и требует осторожности с шумом.

Применение в Python: временной ряд с пропусками: `df['value'].interpolate(method='linear', limit_direction='both')` заполнит внутри и снаружи; для сплайнов `method='spline', order=3`. Методы эффективны при регулярных интервалах и трендах, но требуется проверка на выбросы.

#### Индикатор пропуска
Можно создать дополнительный бинарный признак, характеризующий, было ли значение первоначального признака известно заранее или было пропущено с последующим заполнением. Это позволит модели машинного обучения различать эти две ситуации и относиться к автоматически заполненному значению признака _с большим недоверием_.

При заполнении условной модой/средним/медианой можно также генерировать признак условного стандартного отклонения, чтобы подсказать модели, с каким уровнем неопределённости признак был предсказан.

<dfn title="индикаторный метод">Индикаторный метод</dfn> (*Indicator Method*) — метод, предполагающий замену пропущенных значений нулями и добавление специального атрибута-индикатора, принимающего нулевые значения для записей, где данные изначально не содержали пропусков, и ненулевые значения там, где ранее были пропуски. Проще и нагляднее продемонстрировать данный метод на примере.

**Пример**. В таблице 3 приведены данные до заполнения пропусков.

| Параметр | 12,7 | 7,5 | ?  | 3,1 | ?  | ?  | 5 | 5,8 | 3,7 |
| -------- | ---- | --- | -- | --- | -- | -- | - | --- | --- |
| Пропуск  |      |     | Да |     | Да | Да |   |     |     |

*Таблица 3 — Данные до заполнения пропусков*

> Знаком ? обозначены пропуски в наборе данных.

В таблице 4 приведены данные после заполнения пропусков.

| Параметр | 12,7 | 7,5 | 0 | 3,1 | 0 | 0 | 5 | 5,8 | 3,7 |
| -------- | ---- | --- | - | --- | - | - | - | --- | --- |
| Флаг     | 0    | 0   | 1 | 0   | 1 | 1 | 0 | 0   | 0   |

*Таблица 4 —Таблица после заполнения пропусков*

На практике применяются и модификации этого метода, предполагающие заполнение пропусков ненулевыми значениями. Стоит отметить, что при таком заполнении (например, средним) допустимо использование инверсных значений поля флагов (то есть 0 — для случая, когда в исходных данных значения изначально были пропущены, и ненулевое значение для случаев, когда значение поля исходных данных было известно).

Также при заполнении пропусков ненулевыми значениями часто добавляется взаимодействие поля-флага и исходного поля.[^missing]

Таким образом, <dfn title="индикаторный метод">индикаторный метод</dfn> (*indicator method* или *dummy variable method*) — подход к обработке пропусков, при котором пропущенные значения заполняются константой (часто средним/медианой или модой), а дополнительно создается бинарный индикаторный признак (0/1), отмечающий наличие пропуска, чтобы модель могла учитывать информацию об отсутствии данных.

Пропуски в столбце заменяются фиксированным значением (например, средним по колонке), а параллельно добавляется новый столбец-индикатор: 1 для пропусков, 0 — для заполненных. Это позволяет моделям машинного обучения (регрессия, деревья) интерпретировать пропуски как отдельный сигнал, снижая смещение от простой импутации, особенно при MAR/MNAR механизмах.

Данный метод используется для категориальных/числовых признаков с 5-20% пропусков, когда удаление строк нежелательно. Пример в Python (pandas): `df['feature_na'] = df['feature'].isna().astype(int); df['feature'].fillna(df['feature'].mean())` — добавляет индикатор и заполняет средним.

**К преимуществам данного метода относятся**:

1. Использование всего набора данных (репрезентативность выборки не страдает).
2. Явное использование информации о пропущенных значениях.

**Недостатки**

1. Метод увеличивает размерность датасета и может привести к неэффективным оценкам по сравнению с анализом полных наблюдений при MCAR; не рекомендуется при >20% пропусков или MNAR.
2. Несмотря на эти преимущества, даже при выполнении гипотезы MCAR и небольшом числе пропущенных значений данный метод может привести к существенному искажению результатов [Vach, 1991, Knol, 2010].

#### Особенности ad-hoc методов
Часто, однако, признаки неправильно заполнять значением "в среднем", поскольку сам факт того, что значение пропущено, может говорить о _нестандартности реального значения признака_. Например, человек мог не указать величину своей зарплаты, если ему кажется, что она слишком маленькая или, наоборот, слишком большая. Для таких ситуаций нужно предсказывать значение пропущенного признака по другим признакам, решая задачу регрессии. Либо просто подставлять условное среднее или медиану при условии другого известного признака, связанного с рассматриваемым.

!!! tip Индикатор пропуска

    Можно создать дополнительный бинарный признак, характеризующий, было ли значение первоначального признака известно заранее или было пропущено с последующим заполнением. Это позволит модели машинного обучения различать эти две ситуации и относиться к автоматически заполненному значению признака _с большим недоверием_.

    При заполнении условной модой/средним/медианой можно также генерировать признак условного стандартного отклонения, чтобы подсказать модели, с каким уровнем неопределённости признак был предсказан.

Программные способы заполнения пропущенных значений в данных представлены в библиотеках pandas[^missing_data], sklearn[^impute] и feature-engine[^imputation].

Выборочные статистики считаются по присутствующим значениям признака в других объектах. Медиана более предпочтительна, поскольку является мерой оценки центра распределения, устойчивой к наличию выбросов (robust to outliers), в отличие от среднего.[^Data-imputation]

Вероятно, именно из-за своей простоты ad-hoc методы широко использовались на заре развития современной теории обработки пропусков. И, хотя по состоянию на сегодняшний день известно, что применение этих методов может приводить к искажению статистических свойств выборки и, как следствие, к ухудшению результатов, получаемых после такой обработки пропусков [Horton, 2007], их по-прежнему часто используют.

Так, известны статьи, посвященные сбору и оценке статистики использования методов заполнения пропусков в научных работах медицинской тематики [Burton, 2004, Karahalios, 2012, Rezvan, 2015], из результатов которых можно сделать вывод, что даже ученые часто отдают предпочтение интуитивно-понятным ad-hoc методам и игнорированию/удалению строк, несмотря на то, что применение этих методов в контексте решаемой задачи порой неуместно.

Применение ad-hoc методов и удаление строк таит в себе множество подводных камней, о которых необходимо знать каждому аналитику.[^missing]

#### Выбор метода заполнения пропусков
Выбор метода импутации пропусков основан на типе данных, механизме пропусков (MCAR/MAR/MNAR), проценте пропусков, распределении, корреляциях между признаками и задаче анализа (ML или статистика).

| Метод                            | Тип данных              | % пропусков | Когда использовать                                   | Преимущества/недостатки ​                            |
| -------------------------------- | ----------------------- | ----------- | ---------------------------------------------------- | ---------------------------------------------------- |
| Среднее/медиана                  | Числовые                | <20%        | Нормальное/симметричное распределение, мало выбросов | Быстро; искажает дисперсию                           |
| Мода                             | Категориальные          | <10%        | Несколько классов, сбалансированные данные           | Простота; смещает majority-класс                     |
| Константа/ноль/новая категория   | Числовые/категориальные | Любые       | Пропуск = отсутствие (0); категории с "missing"      | Логично для редких случаев; снижает вариативность    |
| Стохастическая (по вероятностям) | Категориальные          | 10-30%      | Несбалансированные классы, сохранение распределения  | Сохраняет пропорции; добавляет шум                   |
| KNN                              | Любые                   | <30%        | Многомерные данные с локальными паттернами           | Учитывает сходство; вычислительно затратно           |
| Регрессионная                    | Числовые                | <20%        | Сильные корреляции между признаками                  | Точна при зависимостях; риск мультиколлинеарности    |
| Интерполяция/экстраполяция       | Временные ряды          | <15%        | Хронологические данные с трендами (линейная/сплайн)  | Сохраняет последовательность; плохо для нерегулярных |
| MICE/Deep Learning               | Любые                   | >20%        | Сложные зависимости, высокая неопределенность        | Учитывает неопределенность; требует ресурсов         |

*Обобщённые методы заполнения пропусков для разных типов признаков*

Тип признаков | Методы заполнения пропусков | Когда лучше применять
-- | -- | --
**Вещественные**	| Константой (например, 0 или фиксированное число)| Когда отсутствующее значение имеет фиксированный смысл или для простоты
| | Выборочным средним (Arithmetic mean) | При примерно симметричном распределении и отсутствии выбросов
| | Выборочной медианой (Median) | При наличии выбросов или скошенном распределении
**Категориальные** | Наиболее частой категорией (мода) | Если одна категория доминирует, и простота важнее точности
| | Случайной категорией на основе эмпирического распределения (стохастическая импутация по вероятностям) |	Для сохранения исходных пропорций и вариативности данных
| | Новой категорией ("unknown", "missing") | Когда наличие пропуска потенциально информативно; много категорий
**Порядковые** | Выборочной медианой (с учётом порядка) | Для сохранения порядковой структуры данных
| | Наиболее частым уровнем (модой) | При небольшой вариативности и устоявшемся доминирующем уровне
| | Константой (крайний уровень или специальное значение) | Для кодирования отсутствия значений или четкой интерпретации
| | Моделями, учитывающими порядок (например, порядковая регрессия) | При наличии информации для предсказания пропусков
| | Отдельной категорией (пропуск как собственный уровень) | Если важно учесть пропуск как отдельный сигнал
**Хронологические**	| Интерполяцией между соседними значениями (линейная, сплайн) | Для равномерных или плавных временных рядов
| | Заполнением ближайшим известным значением (forward fill, backward fill) | Для нерегулярных данных или событий с кумулятивным эффектом
| | Заполнением константой (например, фиксированной датой или временным маркером) | Для обозначения фиксированных моментов или отсутствия данных
| | Моделями временных рядов (например, ARIMA, LSTM) для прогнозирования пропущенных точек | При сложных временных зависимостях и достаточном объёме данных

Эта таблица помогает не только выбрать метод заполнения, но и понять, в какой ситуации он будет работать лучше всего.

### Оценка качества восстановления данных
Методы оценки качества импутации проверяют, насколько заполненные значения близки к истинным, и сохраняют ли свойства датасета (распределение, корреляции), используя метрики, визуализацию и статистические тесты.

#### Количественные метрики
*[MAE]: Mean Absolute Error
*[MSE]: Mean Square Error
*[RMSE]: Root Mean Square Error
*[MAPE]: Mean Absolute Percentage Error
*[KS]: Kolmogorov-Smirnov

Для числовых признаков применяют регрессионные метрики на маскированных данных (искусственно удаляют известные значения, импутируют, сравнивают). MAE, RMSE и MAPE — это популярные метрики для оценки точности моделей регрессии, которые измеряют разницу между предсказанными и реальными значениями, но делают это по-разному: **MAE** (Средняя Абсолютная Ошибка) показывает среднюю величину ошибок в тех же единицах, что и данные; **RMSE** (Корень из Среднеквадратичной Ошибки) также в единицах данных, но сильнее штрафует большие ошибки из-за возведения в квадрат; а **MAPE** (Средняя Абсолютная Процентная Ошибка) выражает ошибку в процентах, что делает её полезной для сравнения моделей на данных разного масштаба.

##### Средняя абсолютная ошибка (MAE)
<dfn title="средняя абсолютная ошибка">Средняя абсолютная ошибка</dfn> **MAE** (Mean Absolute Error) — среднее значение абсолютных разниц между фактическими и предсказанными значениями.: 

$$ MAE = \frac{1}{n} \sum_{i=1}^n{|y_i - \hat{y_i}|} $$

**Особенности**: устойчива к выбросам, низкие значения указывают на точность.​

**Интерпретация**: легко интерпретируется, так как находится в тех же единицах, что и целевая переменная (например, рубли, градусы). Не чувствительна к выбросам.

##### Средняя абсолютная процентная ошибка (MAPE)
<dfn title="средняя абсолютная процентная ошибка">Средняя абсолютная процентная ошибка</dfn> **MAPE** (Mean Absolute Percentage Error) — среднее значение абсолютных процентных ошибок.

$$ MAPE = \frac{100}{n} \sum_{i=1}^n{\left| \frac{y_i-\hat{y_i}}{y_i} \right|}, \% $$

**Особенности**: относительная точность, но не для нулевых значений; для категориальных: accuracy, F1-score на предсказанных классах.

**Интерпретация**: показывает ошибку в процентах; идеальна для сравнения точности моделей на разных наборах данных с разным масштабом, так как не зависит от единиц измерения. Может быть бесконечной или неопределенной, если реальные значения $y_{i}$ близки к нулю, поэтому не всегда применима. 

##### Средняя квадратическая ошибка (MSE)
<dfn title="средняя квадратическая ошибка">Средняя квадратическая ошибка</dfn> **MSE** (Mean Square Error) —  среднее арифметическое квадратов разностей между фактическими и прогнозируемыми значениями. Это самая популярная метрика оценки качества прогнозов временных рядов.

$$ MSE = \frac{1}{n} \sum_{i=1}^n{(y_i - \hat{y_i})^2} $$

**Особенности**: квадратичный штраф (большие ошибки наказываются сильнее), подчеркивает грубые промахи, дифференцируема (гладкая функция, идеальна для градиентного спуска — loss функция в регрессии), идеальна для временных рядов и регрессии без сильных выбросов.

**Интерпретация**: не интерпретируется напрямую, так как выражается в квадратных единицах целевой переменной; чувствительна к выбросам (один outlier доминирует в сумме).

##### Корень из среднеквадратической ошибки (RMSE)
<dfn title="корень из среднеквадратичной ошибки">Корень из среднеквадратичной ошибки</dfn> **RMSE** (Root Mean Square Error) — Квадратный корень из средней квадратичной ошибки.

  $$ RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n{(y_i - \hat{y_i})^2}} $$

**Особенности**: штрафует большие ошибки, стандарт для временных рядов.​

**Интерпретация**: Также в единицах данных, но большие ошибки "наказываются" сильнее из-за возведения в квадрат. Хороша, когда большие ошибки особенно нежелательны.

##### Интерпретация результатов
Абсолютные метрики (MAE, MSE, RMSE) не имеют универсальных абсолютных порогов из-за специфичных единиц измерения, их оценивают относительно других показателей распределения (стандартное отклонение, дисперсия).

Относительная метрика (MAPE) имеет универсальные пороги (приняты в прогнозировании и импутации):

| Величина | Оценка               | Интерпретация                                            | Действия ​         |
| -------- | -------------------- | -------------------------------------------------------- | ------------------ |
| <10%     | ✅ Отлично            | Высокая точность, модель/импутация промышленно-приемлема | Использовать       |
| 10-20%   | ⚠️ Удовлетворительно | Допустимо для аналитики, требует мониторинга             | Оптимизировать     |
| 20-50%   | ⚫ Плохо              | Низкая точность, только для прототипов                   | Сменить метод      |
| >50%     | ❌ Критично           | Модель бесполезна, хуже случайного угадывания            | Пересобрать данные |

*Универсальные пороги RMSE*

| RMSE/std | Оценка               | Интерпретация                                            | Действия ​         |
| -------- | -------------------- | -------------------------------------------------------- | ------------------ |
| <0.3     | ✅ Отлично            | Модель/импутация объясняет >90% вариации | Использовать       |
| 0.3-0.5   | ⚠️ Удовлетворительно | 70-90% вариации, мониторить             | Оптимизировать     |
| 0.5-1.0  | ⚫ Плохо              | <70% вариации, лучше baseline                   | Сменить метод      |
| >1.0   | ❌ Критично           | Хуже случайного угадывания            | Пересобрать данные |

*Критерии оценки метрик*

| Метрика | Хорошо | Удовлетворительно | Плохо | Критично
-- | -- | -- | --
MAE |  <5-10% std | 10%-20% std | 20%-50% std | >50%
MAPE | <10% | 10-20% | 20-50% | >50%
MSE |  <10% var | 10%-25% var | 25%-50% var | >50%
RMSE | <0.3 std | 0.3-0.5 std | 0.5-1.0 std | >1.0 std

##### Выбор метрики
**Когда что использовать**
- **MAE**: когда нужно простое, понятное среднее отклонение;
- **MSE**: стандарт для оптимизации моделей (дифференцируема), но для интерпретации лучше использовать RMSE/MAE;
- **RMSE**: когда большие ошибки особенно критичны;
- **MAPE**: когда важна относительная ошибка, и данные не имеют нулей или очень близких к нулю значений.

Метрика |	Когда использовать |	Особенности |	Ограничения
-- | -- | -- | --
MAE |	Простое, понятное среднее отклонение. Устойчиво к выбросам. |	Линейный штраф, единицы исходных данных (см, кг) |	Не дифференцируема (плохо для градиентного спуска)
MSE |	Оптимизация моделей (loss функция), временные ряды, градиентный спуск. Чувствительна к большим ошибкам. |	Квадратичный штраф, дифференцируема, bias-variance разложение	| $[y]^2$ (см² — неинтерпретируемо), чувствительна к выбросам
RMSE |	Когда большие ошибки особенно критичны, нужна интерпретируемость. Стандарт для сравнения моделей. |	√MSE → единицы $[y]$, квадратичный штраф |	Чувствительна к выбросам (как MSE)
MAPE |	Когда важна относительная ошибка, данные не имеют нулей или очень близких к нулю значений. |	Процентная ошибка (%) |	$∞$ при $y_i=0$, штрафует низкие значения

Золотое правило:

- обучайте на MSE (дифференцируемо);

- оценивайте на RMSE/MAE (интерпретируемо);

- MAPE — только для % отчетов без нулей.

#### Сравнение распределений
Проверяют, не исказило ли заполнение статистику:

- **KS-тест (Kolmogorov-Smirnov)**: Максимальное расхождение КСД исходного и импутированного распределений (p-value >0.05 — сходны).​

- **Q-Q plots и гистограммы**: Визуально сравнивают формы распределений до/после.​

- **Сравнение моментов**: Mean, variance, skewness — дисперсия не должна падать >10%.

#### Кросс-валидация и диагностика
- **CV на downstream модели**: Обучают ML-модель (e.g. RandomForest) на импутированных данных, сравнивают CV-score (R², AUC) с baseline без пропусков.​

- **Little's MCAR test**: Проверяет механизм пропусков (p>0.05 — MCAR, простые методы OK).​

- **Residual analysis**: ACF/PACF остатков для временных рядов, проверка на автокорреляцию после импутации.

#### Практическая реализация (Python)
Комплекс: метрики <5-10% ошибки + стабильные распределения + рост CV-score:
```python
from sklearn.metrics import mean_absolute_error
from scipy.stats import ks_2samp
# После импутации на маске
mae = mean_absolute_error(true_values, imputed_values)
ks_stat, p_val = ks_2samp(original_dist, imputed_dist)
# Низкий MAE + высокий p-value KS = хорошая импутация
```

### Заключение
В таблицах с данными очень часто присутствуют ячейки с пропущенными или некорректными значениями. Нужно осознать важность и сложность данной проблемы. Методы восстановления данных в тренировочных таблицах (датасетах для машинного обучения) в основном подразумевают обработку пропущенных значений (импутацию), чтобы избежать искажений в моделях.​ Наиболее простой способ борьбы с такими ячейками — это удаление строк (столбцов), вместе с тем, существуют и более сложные методы восстановления данных.

Мы рассмотрели простые методы заполнения пропусков. Хотя применение этих методов может приводить к существенному искажению статистических свойств набора данных (среднее значение, медиана, вариация, корреляция…) даже в случае MCAR, они остаются часто используемыми не только среди обычных пользователей, но и в научной среде (как минимум в областях, связанных с медициной).

Так, согласно [Burton, 2004], из 100 работ, посвященных проблеме раковых заболеваний, которые были опубликованы в 2002 году, в 82% случаев авторы указали, что столкнулись с не-обходимостью заполнения пропусков в данных. При этом в 32 случаях был явно указан метод заполнения пропусков. В 12 из этих 32 работ использовался Complete Case Analysis, еще в 12 — Available Case Analysis, в 4 — Indicator Method, в 3— ad-hoc методы, и только в 1 случае использовался более сложный метод.

Спустя десятилетие ситуация не сильно изменилась к лучшему. [Karahalios, 2012] пишут, что среди рассмотренных ими научных трудов в 54% случаев (в 21 статье) использовался Complete Case Analysis, в 7 случаях – LOCF, в 3 случаях – заполнение средним значением, в 1 случае — Indicator Method.

И даже по состоянию на 2014 год рекомендуемые к использованию методы заполнения пропусков (Multiple Imputation, методы функции максимального правдоподобия) в научных статьях медицинской тематики по-прежнему применяются редко [Rezvan, 2015].

В качестве заключения хотелось бы отметить, что использование простых методов, таких как удаление строк или применение ad-hoc методов, не всегда приводит к ухудшению результатов. Более того, когда это уместно, использование простых методов более предпочтительно.[^missing]

### Практическая работа. Восстановление данных с помощью простых методов
Реализовать различные варианты восстановления данных, используя ad-hoc методы в соответствии с данными индивидуального варианта, приводимыми в прилагаемом файле:

- выборочным средним;
- выборочной медианой;
- модой.

Для каждого восстанавливаемого признака обосновать выбор того или иного метода. Провести оценку качества восстановления на маскированных данных. Сделать выводы об эффективности реализованных методов восстановления для каждого признака на основе методов сравнения результатов восстановления с фактическими значениями отсутствующих признаков, количественных метрик (MAE, MAPE, MSE, RMSE) и сравнения формы распределения с помощью гистограмм.

### Дополнительные источники
- [Burton, 2004] — Burton A., Altman D. G. Missing covariate data within cancer prognostic studies: A review of current reporting and proposed guidelines. British Journal of Cancer, 2004, 91(1):4–8.
- Wa[Horton, 2007] — Horton N.J., Kleinman K.P. Much ado about nothing: A comparison of missing data methods and software to fit incomplete data regression models. Am. Stat. 2007; 61: pp 79–90.
- [Karahalios, 2012] — Karahalios A., Baglietto L., Carlin J.B., English D.R., Simpson J.A. A review of the reporting and handling of missing data in cohort studies with repeated assessment of exposure measures. BMC Med Res Methodology, 2012;12:96.
- [Knol, 2010] — Knol, M. J., Janssen, K. J. M., Donders, A. R. T., Egberts, A. C. G., Heerdink, E. R., Grobbee, D. E., Moons, K. G. M., and Geerlings, M. I. (2010). - Unpredictable bias when using the missing indicator method or complete case analysis for missing confounder values: an empirical example. Journal of Clinical Epidemiology, 63: pp 728–736.
- [Miettinen, 1985] — Miettinen, O. S. Theoretical Epidemiology: Principles of Occurrence Research in Medicine. John Wiley & Sons, New York. 1985, p. 232.
- [Molenberghs, 2007] — Molenberghs, G. and Kenward, M. G. Missing Data in Clinical Studies. John Wiley & Sons, Chichester, UK. 2007 — pp. 47-50.
- [Rezvan, 2015] — Panteha Hayati Rezvan, Katherine J Lee, Julie A Simpson -The rise of multiple imputation: a review of the reporting and implementation of the method in medical research. BMC Medical Research Methodology, 15(30), pp 1–14.
- [Vach, 1991] — Vach, W. and Blettner, M. (1991). Biased estimation of the odds ratio in case-control studies due to the use of ad hoc methods of correcting for missing values for confounding variables. American Journal of Epidemiology, 134(8), pp 895–907.
- [Van Buuren, 2012] — Van Buuren S. Flexible Imputation of Missing Data. Chapman and Hall/CRC; 1 ed., 2012 — 342 p.
- [Loginom Data Quality. Очистка клиентских данных. Деморолик](https://loginom.ru/blog/demo-ldq)
- [Как найти и объединить дубли клиентов](https://loginom.ru/blog/how-search-dublicate)
- "Статистика для тех,  кто (думает, что) ненавидит статистику" (Нил Дж. Салкинд)
- "Общая теория статистики" (Громыко)
- "Практикум по общей теории статистики" (Ефимова, Ганченко, Петрова)

### Источники информации
[^Data-imputation]: [Заполнение пропусков в данных](https://deepmachinelearning.ru/docs/Machine-learning/Data-preprocessing/Data-imputation)
[^Arithmetic_mean]: [Wikipedia: arithmetic mean](https://en.wikipedia.org/wiki/Arithmetic_mean)
[^Median]: [Median](https://en.wikipedia.org/wiki/Median)
[^missing_data]: [Документация pandas: missing data](https://pandas.pydata.org/docs/user_guide/missing_data.html)
[^impute]: [Документация scikit-learn: восстановление пропущенных значений](https://scikit-learn.ru/stable/modules/impute.html#impute)
[^imputation]: [Документация feature-engine: imputation](https://feature-engine.trainindata.com/en/1.6.x/user_guide/imputation/index.html)
[^missing]: [Обработка пропусков в данных](https://loginom.ru/blog/missing)
[^Ad_hoc]: [Ad hoc](https://ru.wikipedia.org/wiki/Ad_hoc)
[^chto-takoe-ad-hoc-zadachi]: [Что такое ad hoc задачи, зачем они нужны и как ими управлять](https://practicum.yandex.ru/blog/chto-takoe-ad-hoc-zadachi/)
