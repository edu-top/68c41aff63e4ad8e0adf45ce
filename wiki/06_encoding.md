<link href="../styles.css" rel="stylesheet" />

## 06. Подготовка данных: агрегация и кодирование признаков

- [06. Подготовка данных: агрегация и кодирование признаков](#06-подготовка-данных-агрегация-и-кодирование-признаков)
  - [Агрегация данных](#агрегация-данных)
    - [Методы агрегации](#методы-агрегации)
    - [Типы агрерации](#типы-агрерации)
    - [Уменьшение размерности с помощью агрегации](#уменьшение-размерности-с-помощью-агрегации)
  - [Кодирование данных](#кодирование-данных)
    - [Основные методы кодирования](#основные-методы-кодирования)
      - [Сопоставление и замена признаков (feature mapping and replacement)](#сопоставление-и-замена-признаков-feature-mapping-and-replacement)
      - [Дихотомизация для бинарных признаков](#дихотомизация-для-бинарных-признаков)
      - [Порядковое (ординальное) кодирование для порядковых признаков](#порядковое-ординальное-кодирование-для-порядковых-признаков)
      - [Прямое кодирование (кодирование метками) для категориальных признаков](#прямое-кодирование-кодирование-метками-для-категориальных-признаков)
      - [Частотное кодирование для категориальных признаков](#частотное-кодирование-для-категориальных-признаков)
      - [Кодирование средним (таргет-кодирование)](#кодирование-средним-таргет-кодирование)
      - [Унитарное кодирование для номинальных признаков](#унитарное-кодирование-для-номинальных-признаков)
    - [Обработка категорий с большим числом уникальных значений](#обработка-категорий-с-большим-числом-уникальных-значений)
    - [Кодирование циклических переменных](#кодирование-циклических-переменных)
    - [Выбор метода кодировки](#выбор-метода-кодировки)
  - [Практический пример подготовки и обработки данных](#практический-пример-подготовки-и-обработки-данных)
    - [Подготовка данных с использованием агрегации и кодирования](#подготовка-данных-с-использованием-агрегации-и-кодирования)
    - [Исследование связи между признаками](#исследование-связи-между-признаками)
  - [Практическая работа. Обработка и анализ признаков для неметрических шкал](#практическая-работа-обработка-и-анализ-признаков-для-неметрических-шкал)
  - [Дополнительные источники](#дополнительные-источники)
  - [Источники информации](#источники-информации)


Подготовка данных в современных информационных системах происходит в три этапа:

1. **Сбор данных**. Данные собирают из различных источников в базе данных.
2. **Обработка данных**. Агрегатор находит элементарные данные и агрегирует их, используя алгоритмы из области искусственного интеллекта или машинного обучения, а также статистические методы, например прогнозный анализ.
3. **Представление данных**. После обработки данные представляют в обобщённом формате, который обеспечивает желаемый статистический результат с подробными и точными данными.

### Агрегация данных
<dfn title="агрегация данных">Агрегация данных</dfn> в машинном обучении — это процесс объединения и обобщения исходных данных для получения новых признаков или сводной информации, которая влияет на качество модели. Основная цель агрегации — упростить и структурировать данные, выявить тренды и закономерности, снизить шум и повысить информативность признаков.

Примеры агрегирования данных:

- Агрегирование данных о продажах по различным продуктам и регионам для создания консолидированного отчета о продажах.

- Суммирование ежемесячных расходов различных отделов компании для визуализации распределения бюджета и тенденций расходов.

- Анализ финансовых данных для отображения динамики различных секторов промышленности с течением времени и составления прогнозов.

Агрегация помогает сократить размерность, улучшить устойчивость модели и выявить важные закономерности. В информационных системах агрегация реализуется через алгоритмы машинного обучения, статистические методы, кластеризацию и интеллектуальный анализ данных.

В коде машинного обучения агрегация часто реализуется средствами библиотек, таких как pandas (groupby + agg), с возможностью сложных многоуровневых агрегатов с фильтрацией и вычислительной логикой.

Агрегация — важный этап подготовки данных, особенно при работе с большими и разнородными данными, и способствует повышению точности и обобщающей способности моделей машинного обучения.

Зачастую агрегация данных выполняется с помощью специализированных инструментов — агрегаторов данных. В зависимости от характера данных и целей процесс агрегирования может включать группировку, усреднение, суммирование и подсчет.

#### Методы агрегации
<dfn title="агрегация данных">Агрегация данных</dfn> в контексте визуализации данных относится к процессу сбора, обобщения, консолидации и представления отдельных элементов данных в более полном и значимом формате, что облегчает анализ и интерпретацию информации. Методы агрегирования данных имеют основополагающее значение в области визуализации данных, поскольку они позволяют разработчикам, специалистам по данным и бизнес-специалистам эффективно обрабатывать большие объемы необработанных данных, извлекать ценную информацию и представлять ее в визуально привлекательной форме. Этот процесс играет решающую роль в различных областях, таких как бизнес-аналитика, принятие решений, исследования и статистический анализ.[^agregatsiia-dannykh]

Внедрение эффективных методов агрегирования данных может привести к ряду преимуществ, включая повышение производительности приложений, управляемых данными, большую точность статистического анализа и расширение возможностей принятия решений для конечных пользователей.

Типичные методы агрегации включают:

- **Статистические операции**: среднее, сумма, минимум, максимум, медиана, мода, дисперсия — применяются к группам данных для создания новых агрегированных признаков.

- **Группировка данных по категориям** (например, по пользователю, времени, региону) с последующим вычислением агрегаций внутри групп.

- **Сложные методы**, например, скользящее среднее и другие временные агрегаты для анализа временных рядов.

- **Агрегация признаков из разнородных источников** для получения итогового набора признаков для модели.

#### Типы агрерации
Методы агрегирования данных можно условно разделить на следующие типы:

- **Временное агрегирование**. Этот метод предполагает консолидацию или обобщение данных за определенный период времени (например, ежечасно, ежедневно, ежемесячно). Временное агрегирование особенно актуально для данных временных рядов, которые обычно наблюдаются в финансах, продажах, анализе погоды и других областях, где жизненно важно понимание тенденций и закономерностей с течением времени.

- **Пространственная агрегация**. Пространственная агрегация относится к процессу агрегирования данных на основе географического или пространственного местоположения. Этот тип агрегирования весьма актуален в таких областях, как экологические исследования, городское планирование и транспортные системы, где анализ данных в контексте пространственных границ может дать ценную информацию и обеспечить принятие обоснованных решений.

- **Категориальная агрегация**. Категориальная агрегация включает группировку данных на основе определенных атрибутов или категорий. Этот подход может значительно упростить представление сложных, многомерных данных за счет использования интерактивных диаграмм и графиков, демонстрирующих различные категории и соответствующие им значения.

При реализации методов агрегирования данных важно учитывать различные факторы, такие как степень детализации данных, метод агрегирования и требования пользователей. Агрегирование данных на соответствующем уровне детализации обеспечивает правильный баланс между сложностью данных и понятностью визуализации. Крайне важно выбрать подходящий метод агрегирования на основе исходных данных и желаемой информации. Кроме того, понимание требований пользователей необходимо для достижения правильного баланса между упрощением и сохранением важной информации.[^agregatsiia-dannykh]

#### Уменьшение размерности с помощью агрегации
Агрегация может быть использована в качестве одного из методов снижения размерности данных, при котором множество исходных признаков или объектов объединяются и агрегируются в более обобщённые показатели. Цель агрегации — упростить исходный большой и сложный набор данных, сохранив основную информацию, но сократив количество переменных или объектов.

Основные характеристики агрегации при уменьшении размерности:

- Признаки могут объединяться по смыслу или географическому принципу (например, средние значения по временным интервалам или пространственным зонам).

- Используют статистические меры: среднее, медиана, сумма, максимум, минимум, дисперсия и другие.

- Агрегация позволяет снизить шум в данных, выделить тенденции и улучшить производительность моделей.

- В отличие от методов извлечения признаков (например, PCA), агрегация не создаёт новые признаки, а производит усреднение или обобщение существующих.

Таким образом, агрегация — это простой и эффективный способ уменьшения размерности, особенно полезный при работе с временными рядами, пространственными данными или очень большими наборами, где важна интерпретируемость и сохранение ключевой информации без сложных преобразований.

Например, если у есть ежечасные данные температуры и влажности, их можно агрегировать до среднесуточных значений, что сократит размерность и упростит анализ.

Этот подход широко применяется в анализе больших и комплексных данных, снижая вычислительные затраты и повышая качество моделей.

### Кодирование данных
Помимо количественных признаков часто наборы данных содержат категориальные переменные. Эти переменные обычно хранятся в виде текстовых значений, которые представляют различные характеристики. Некоторые примеры включают цвет ("Красный", "Желтый", "Синий"), размер ("Маленький", "Средний", "Большой") или географические обозначения ("Штат" или "Страна"). Другими словами, категориальные признаки — это признаки, которые описываются метками или строковыми значениями, такими как цвет, тип или категория объекта.

<dfn title="категориальный признак">Категориальные признаки</dfn> (categorical features) — это признаки, принимающие одно из $K$ дискретных значений, такие как профессия человека или город, в котором он родился. Такие признаки очень часто встречаются на практике. Частным случаем категориальных признаков являются <dfn title="бинарный признак">бинарные признаки</dfn> (binary features), принимающие всего два значения, такие как семейное положение человека или индикатор, были ли у человека просрочки по кредитам.[^Categorical-preprocessing]

Многие алгоритмы машинного обучения поддерживают категориальные значения без дополнительных манипуляций, но есть множество алгоритмов, которые этого не делают. Чаще всего модель машинного обучения ожидает на входе вектор, состоящий только из вещественных признаков. Следовательно, перед аналитиком стоит задача выяснить, как преобразовать эти текстовые атрибуты в числовые значения для дальнейшей обработки.[^pandas] Правильная обработка таких признаков критически важна для успеха модели.[^obrabotka-katieghorialnykh-priznakov]

Категориальные признаки могут быть преобразованы в числовые признаки, которые можно применять в моделях машинного обучения. <dfn title="кодирование категориальных данных">Кодирование категориальных данных</dfn> — это процесс преобразования качественных признаков в числовую форму для дальнейшего анализа или использования в алгоритмах машинного обучения, которые обычно требуют числовых входов.

**Почему это важно**

- Многие статистические методы и модели машинного обучения работают только с числовыми данными.

- Категориальные переменные без кодирования невозможно напрямую включить в такие модели.

- Кодирование позволяет сохранить информативность категорий, при этом облегчая математическую обработку.

Если бинарный признак мы можем представить в вещественном виде, закодировав категории цифрами 0 и 1, то в случае признака, описывающего несколько категорий, возможны различные варианты кодировок, которые мы рассмотрим далее.

#### Основные методы кодирования
*[OHC]: One-Hot Coding
*[OHE]: One-Hot Encoding

Существует несколько методов преобразования категориальных признаков.

##### Сопоставление и замена признаков (feature mapping and replacement)

Категориальный признак может быть связан с числовым признаком, таким как стоимость товара или количество проданных единиц. В таком случае категориальный признак может быть преобразован в числовой признак, чтобы стать частью общего набора признаков для модели машинного обучения.

Данный метод применим в том случае, если есть два столбца данных, значения которых представляют собой слова, используемые для представления чисел. В частности, количество цилиндров в двигателе (`num_cylinders`) и количество дверей в машине (`num_doors`). В отдельных случаях можно напрямую заменять текстовые значения их числовыми эквивалентами. Например, если данные `num_doors` включают только 2 или 4 двери. Количество цилиндров включает всего 7 значений, которые легко переводятся в действительные числа.

Хотя данный подход может работать только в определенных случаях, это очень полезная демонстрация того, как преобразовать текстовые значения в числовые, когда есть "легкая" интерпретация данных человеком. Представленная концепция также полезна для более общей очистки данных.

##### Дихотомизация для бинарных признаков
<dfn title="дихотомизация">Дихотомизация</dfn> (dichotomous coding) — это процесс преобразования непрерывной или категориальной переменной в бинарную, то есть в две категории (обычно 0 и 1). В статистике и машинном обучении дихотомизация позволяет представить сложные или многозначные данные в упрощённом виде для дальнейшего анализа или построения моделей. Суть метода заключается в том, что при двух категориях (например, пол: м/ж) каждой присваивается 0 или 1, что удобно для большинства алгоритмов.

**Основные моменты дихотомизации**:
- Переменная разбивается на две группы по какому-то критерию (например, значение выше или ниже порога).

- Каждой группе присваивается бинарный код (0 или 1).

- Применяется, когда нужно упростить данные, сделать их совместимыми с бинарными алгоритмами или выделить конкретные категории (например, "болен / здоров", "мужчина / женщина").

Дихотомизация помогает работать с качественными или количественными данными, если требуется категоризация на две части, что часто встречается в задачах классификации и в анализе бинарных признаков. Применяется, когда нужно упростить данные, сделать их совместимыми с бинарными алгоритмами или выделить конкретные категории (например, "болен / здоров", "мужчина / женщина"). Таким образом, дихотомизация — это важный инструмент подготовки данных, позволяющий переводить разнообразные типы данных в удобную для анализа бинарную форму.

##### Порядковое (ординальное) кодирование для порядковых признаков
<dfn title="порядковое кодирование">Порядковое кодирование</dfn> — это метод преобразования категориального признака, для которого существует естественный порядок, в числовой вид, сохраняя этот порядок. Каждой категории присваивается целое число, отражающее её позицию в этом порядке.

В **порядковом кодировании** (ordinal encoding) категория заменяется её номером. Этот метод хорошо подходит для признаков с порядком значений, таких, например, как уровень образования. Каждой категории присваивается числовой ранг согласно их естественному порядку (например, уровень облачности: ясно = 0, малая = 1, средняя = 2, высокая = 3, пасмурно = 4). Это сохраняет информацию о порядке, что важно для корреляционного анализа, учитывающего ранги. Так, в отличие от one-hot encoding, которое создаёт отдельные бинарные признаки для каждой категории и не учитывает порядок, порядковое кодирование компактно и отражает информационный смысл порядка категорий.

Порядковое кодирование широко используется для признаков с понятной и важной последовательностью значений, например, уровень образования, степень удовлетворённости, рейтинги и т.д. Таким образом, порядковое кодирование позволяет преобразовывать упорядоченные категориальные данные в числовую форму, сохраняя их естественную иерархию для последующего анализа и моделирования.

##### Прямое кодирование (кодирование метками) для категориальных признаков
<dfn title="кодирование метки">Кодирование метки</dfn> или <dfn title="прямое кодирование">прямое кодирование</dfn> (label encoding) — это простое преобразование каждого значения категориальных признаков в числовые значения. При этом каждой уникальной категории присваивается число, т.е. каждое значение категориального признака заменяется на соответствующее целое число.

_Пример_: "Синий" -> 1, "Красный" -> 2, "Зеленый" -> 3.

Рассмотрим кодировку признака "профессия". Пусть для простоты она принимает всего 4 возможных значения: программист, художник, дизайнер и системный администратор. В порядковом кодировании мы заменяем профессии их номерами:

<table><thead><tr><th>значение</th><th>номер</th></tr></thead><tbody><tr><td>программист</td><td>0</td></tr><tr><td>художник</td><td>1</td></tr><tr><td>дизайнер</td><td>2</td></tr><tr><td>системный администратор</td><td>3</td></tr></tbody></table>

```py
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
encoded = le.fit_transform(["кошка", "собака", "кошка", "хомяк"])
print(encoded) # [0 1 0 2]
```

**Особенности прямого кодирования**:

- Простое и компактное преобразование категорий в числа.

- Работает хорошо для признаков с упорядоченными категориями (порядковые признаки).

- Может ввести ошибочную интерпретацию порядка для номинальных категорий, так как модели могут воспринимать числовые коды как имеющие числовую величину и порядок.

- Требует осторожности при применении к номинальным данным, чтобы избежать ложных предположений.

Этот метод может вводить искусственную иерархию между категориями, что может быть проблематично для некоторых моделей, так как модель может принять числовые отношения за реальную зависимость (например, что "красный" больше чем "синий"). Проблема здесь в том, что многие алгоритмы будут интерпретировать эти числа как упорядоченность категорий.[^obrabotka-katieghorialnykh-priznakov]

Поэтому данный вид кодирования _не рекомендуется применять на практике_, поскольку метод машинного обучения впоследствии будет считать, что движение в направлении 0,1,2,3 будет соответствовать возрастанию какой-то реально существующей характеристики, которой в действительности нет, поскольку _нумерация была произвольной_. Также в нашем примере метод на основе близости численных значений будет считать, что программист ближе по смыслу к художнику, чем к системному администратору, что в действительности не так.[^Categorical-preprocessing]

Этот метод часто используется как базовый и этап подготовки данных, особенно если количество категорий невелико или признак порядковый. Таким образом, прямое кодирование — это простой способ представить категориальные данные числовыми значениями, при этом важно учитывать природу данных и возможные ограничения модели

##### Частотное кодирование для категориальных признаков
<dfn title="частотное кодирование">Частотное кодирование</dfn> (frequency encoding) — это метод преобразования категориальных переменных в числовые значения, при котором каждой категории присваивается число, равное частоте её встречаемости в наборе данных. То есть категорию заменяют на то, насколько часто она встречается среди всех наблюдений.

При **частотном кодировании** значение каждой категории заменяется на частоту встречаемости этой категории. Пусть, например, у нас 7 человек, среди которых два программиста, три системных администратора, один дизайнер и художник. Для этого случая частотное кодирование будет выглядеть так:

<table><thead><tr><th>значение</th><th>кодировка</th></tr></thead><tbody><tr><td>программист</td><td>2/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>дизайнер</td><td>1/7</td></tr><tr><td>художник</td><td>1/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>программист</td><td>2/7</td></tr></tbody></table>

Обратим внимание, что кодирование неоднозначно для дизайнера и художника, которые встретились одинаковое число раз.

> Полезность кодировки определяется тем, насколько частота встречаемости категорий связана с целевой переменной.[^Categorical-preprocessing]

**Преимущества частотного кодирования**:

- Простота реализации.

- Сохраняет информацию о распределении категорий.

- Позволяет эффективно кодировать признаки с большим числом уникальных категорий.

**Недостатки**:

- Может потерять информацию о порядке или содержании категорий.

- При использовании в некоторых моделях может внести смещение, если частота сама коррелирует с целевой переменной.

Частотное кодирование часто применяется в задачах с высококардинальными категориальными признаками, когда one-hot кодирование было бы слишком ресурсоёмким. Таким образом, частотное кодирование представляет каждую категорию через долю её встречаемости в данных, что упрощает работу с категориальными признаками в числовом формате.

##### Кодирование средним (таргет-кодирование)
<dfn title="кодирование средним">Кодирование средним</dfn> (mean encoding, target encoding) — это метод кодирования категориальных признаков, при котором каждой категории присваивается числовое значение, равное среднему значению целевой переменной для этой категории. Кодирование средним — компактный и максимально информативный способ кодирования категориального признака путём замены каждой категории на среднее прогнозируемого отклика _при условии этой категории_.

**Суть кодирования средним**:
- Для каждой категории вычисляется среднее значение отклика (цели) в обучающей выборке.

- Категория заменяется этим средним значением.

Такой подход позволяет компактно представить категориальный признак числами с учётом информации о связи с целевой переменной.

Приведём пример для регрессии, когда по профессии необходимо предсказать зарплату:

<table><thead><tr><th>признак (профессия)</th><th>отклик</th><th>кодирование признака</th></tr></thead><tbody><tr><td>программист</td><td>300</td><td>350</td></tr><tr><td>системный администратор</td><td>250</td><td>200</td></tr><tr><td>системный администратор</td><td>200</td><td>200</td></tr><tr><td>дизайнер</td><td>220</td><td>200</td></tr><tr><td>художник</td><td>150</td><td>150</td></tr><tr><td>дизайнер</td><td>180</td><td>200</td></tr><tr><td>программист</td><td>400</td><td>350</td></tr><tr><td>системный администратор</td><td>150</td><td>200</td></tr></tbody></table>

В данной таблице:

- признак (профессия) — это категориальный признак, который отражает профессию каждого объекта или человека.

- отклик — это целевая переменная (target), числовое значение, которое показывает реакцию, результат или показатель, связанный с профессией (например, количество продаж, выручку, доход и т.д.).

- кодирование признака — это числовое представление категориального признака профессии, полученное методом кодирования средним (mean encoding).

А ниже показан пример кодирования средним для классификации, когда по профессии предсказываем, вернёт человек кредит или нет:

<table><thead><tr><th>признак (профессия)</th><th>отклик</th><th>кодирование признака</th></tr></thead><tbody><tr><td>программист</td><td>1</td><td>1</td></tr><tr><td>системный администратор</td><td>1</td><td>2/3</td></tr><tr><td>системный администратор</td><td>0</td><td>2/3</td></tr><tr><td>дизайнер</td><td>1</td><td>1/2</td></tr><tr><td>художник</td><td>0</td><td>0</td></tr><tr><td>дизайнер</td><td>0</td><td>1/2</td></tr><tr><td>программист</td><td>1</td><td>1</td></tr><tr><td>системный администратор</td><td>1</td><td>2/3</td></tr></tbody></table>

Как видим, для регрессии и бинарной классификации один столбец исходного признака заменяется на один столбец условных средних. В случае многоклассовой классификации каждая категория будет заменяться на _вектор условных частот каждого из классов_ при условии категории.

Представленный способ кодирования максимально информативен для решения итоговой задачи предсказания отклика по кодировке, поскольку кодировка в явном виде агрегирует информацию об отклике.

!!! warning Переобучение

    Кодирование признака агрегацией по отклику _приводит к переобучению_, поскольку мы через признак явно передаём информацию об ожидаемом ответе, пусть и в усреднённом виде. Для категорий, которые встретились единожды ("художник" в примере) мы перенесли отклик в признак в явном виде! Получается, мы решаем нечестную задачу, поскольку сообщаем модели информацию об ожидаемом отклике, которую она не должна знать.

    Чтобы избежать переобучения и сделать прогнозы честными, можно выделить отдельную обучающую выборку на кодирование средним только по ней, а потом перенести вычисленное соответствие категорий средним откликам в основную обучающую выборку, по которой уже будем настраивать модель.

    Более эффективный способ с точки зрения переиспользования данных — для каждого объекта подставлять вместо категории условное среднее отклика по всем объектам _кроме рассматриваемого_ (**leave one out encoding**).[^Categorical-preprocessing]

!!! tip Варианты метода

    Вместо каждой категории можно подставлять условное среднее по другому вещественному или бинарному признаку. Такое кодирование не приводит к подглядыванию в неизвестный отклик, поэтому для него не нужна отдельная выборка для кодировки.

    Также вместо среднего значения при условии каждой категории можно подставлять условную медиану, максимум, минимум или стандартное отклонение - в зависимости от задачи.

**Преимущества**:
- Позволяет использовать информацию о целевой переменной в кодировке.

- Уменьшает размерность данных по сравнению с one-hot encoding.

- Может улучшать качество модели за счёт сохранения релевантной статистики.

**Недостатки**:
- Возможность переобучения модели, если кодирование применяется без дополнительных техник (например, сглаживания или кросс-валидации).

- Требует аккуратного применения в задачах машинного обучения.

Таким образом, кодирование средним представляет категориальные признаки числами, отражающими средний уровень целевой переменной, что помогает учитывать влияние категорий на результат и строить более информативные модели

##### Унитарное кодирование для номинальных признаков
Кодирование меток имеет тот недостаток, что числовые значения могут быть "неверно интерпретированы" алгоритмами. Например, значение 0 очевидно меньше значения 4, но действительно ли это соответствует набору данных в реальной жизни? Имеет ли универсал в 4 раза больший вес, чем у кабриолета?

Общий альтернативный подход называется **унитарным кодированием** (One-hot encoding, dummy encoding). <dfn title="унитарное кодирование">Унитарное кодирование</dfn> — это метод преобразования категориального признака в числовой формат, при котором каждая уникальная категория превращается в отдельный бинарный признак (столбец). В полученной матрице для каждой записи один из столбцов принимает значение 1 (указывая на принадлежность к данной категории), а все остальные — 0.

Основная стратегия состоит в том, чтобы преобразовать значение каждой категории в новый столбец и присвоить столбцу значение 1 или 0 (Истина / Ложь). Это дает преимущество в том, что значение не взвешивается неправильно, но имеет обратную сторону добавления дополнительных столбцов в набор данных.[^pandas]

Категории без внутреннего порядка преобразуются в несколько бинарных признаков — по одному на каждую категорию. То есть для каждой категории создается бинарный признак (dummy variable), при этом каждое значение категориального признака заменяется на столбец бинарных значений, где 1 указывает на присутствие значения признака, а 0 — на его отсутствие. Например, если есть типы облаков: кучевые, слоистые, перистые, создаётся три бинарных столбца, где "1" указывает на наличие этой категории. Этот метод подходит для признаков без порядка значений, таких как цвет или тип объекта.

_Пример_: Вместо столбца "Цвет" (синий, красный, зеленый) создаются столбцы "Синий", "Красный", "Зеленый".

Вначале все категории нумеруются произвольным образом. Каждый категориальный признак, принимающий значение i-й категории среди $K$ возможных, кодируется $K$-мерным вектором из нулей, где на одной только i-й позиции стоит единица.

Пример соответствия категорий кодировкам:

<table><thead><tr><th>направление</th><th>кодировка</th></tr></thead><tbody><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>юг</td><td>[0,0,1,0]</td></tr><tr><td>восток</td><td>[0,1,0,0]</td></tr><tr><td>запад</td><td>[1,0,0,0]</td></tr></tbody></table>

Пример применения кодировки к данным:

<table><thead><tr><th>направление</th><th>кодировка</th></tr></thead><tbody><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>запад</td><td>[1,0,0,0]</td></tr><tr><td>восток</td><td>[0,1,0,0]</td></tr><tr><td>север</td><td>[0,0,0,1]</td></tr></tbody></table>

Метод однозначно кодирует категорию и, в отличие от предыдущих методов, производит сопоставление одному категориальному признаку сразу набор бинарных признаков (по числу категорий). Все категории, независимо от порядка кодирования, получаются равнозначными: попарное расстояние между кодировками любой пары категорий получается одним и тем же.

```py
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder()
encoded = ohe.fit_transform([["кошка"], ["собака"], ["кошка"], ["хомяк"]]).toarray()
print(encoded)
# [[1. 0. 0.]
#  [0. 0. 1.]
#  [1. 0. 0.]
#  [0. 1. 0.]]
```

Теперь нет ложной упорядоченности, но возросла размерность данных.

**Особенности унитарного кодирования**:

- Позволяет избежать введения искусственного порядка, поскольку каждая категория представлена независимо.

- При увеличении числа уникальных категорий увеличивается размерность данных (создается столько новых признаков, сколько категорий).

- Широко используется в задаках машинного обучения для обработки номинальных (без внутреннего порядка) категориальных признаков.

Таким образом, унитарное (one-hot) кодирование — это удобный и распространенный способ представления категориальных данных в числовом виде, сохраняющий категорийную природу признаков без предположений о порядке.

One-hot кодирование — самый популярный способ представления категориальных признаков, однако у него есть недостаток, что при слишком большом числе категорий он приводит к сильному разрастанию числа признаков. Например, если категория — это город, то, поскольку городов очень много, число признаков значительно увеличивается, что приводит к сильному увеличению параметров модели машинного обучения, ухудшая её настройку. Одним из способов борьбы с этим является объединение различных родственных категорий в одну. Например, вместо указания города можно указывать область, в которой этот город находится. Если же не хочется терять детализации, то можно использовать усиленную [регуляризацию](https://deepmachinelearning.ru/docs/Machine-learning/Base-concepts/Regularization) модели.

#### Обработка категорий с большим числом уникальных значений
Иногда категориальный признак имеет очень много уникальных значений (например, список городов). Применение OHE приведет к "проклятию размерности". Есть несколько способов справиться с этим:

1. **Группировка редких категорий**. Категории с частотой ниже порога объединяются в одну группу "Другое":

    ```py
    def group_rare(df, col, threshold=0.05):
        s = df[col].value_counts(normalize=True)
        rare = s[s < threshold].index
        df[col] = df[col].replace(rare, "Другое")
        return df

    df = group_rare(df, "City", 0.01)
    ```

2. **Применение техник понижения размерности после OHE**, например, метод главных компонент (PCA).

3. **Использование числовых представлений категорий**, например, частоты (probability encoding) или таргет-кодирования (target encoding).

!!! tip Эмбеддинги

    Представление определённой дискретной сущности (например, категории в категориальном признаке) вектором вещественных чисел называется <dfn title="эмбеддинг">эмбеддингом</dfn> (embedding). One-hot кодирование приводит к слишком длинному вектору, если число категорий велико. Вместе с этим понятно, что если использовать не только значения 0/1, а весь спектр вещественных чисел, то можно даже большое число категорий однозначно закодировать компактным вектором эмбеддинга. Эмбеддинги можно сэмплировать случайно, при этом желательно обеспечивать одинаковое попарное расстояние между эмбеддингами разных категорий. Или генерировать эмбеддинги так, чтобы расстояние между эмбеддингами оказывалось более близким для более близких категорий по смыслу (например, работа программиста более близка к работе системного администратора, а работа художника - к работе дизайнера, поэтому и соответствующие эмбеддинги должны быть ближе). Существуют продвинутые методы автоматической генерации эмбеддингов, о которых можно прочитать, например, в [статье](https://cs.msu.ru/sites/cmc/files/docs/dyakonov.pdf).

Правильная обработка категориальных признаков — важный этап построения модели машинного обучения. One-Hot кодирование — наиболее универсальный подход. Но для признаков с большим числом категорий приходится применять дополнительные техники, чтобы избежать "проклятия размерности".[^obrabotka-katieghorialnykh-priznakov]

#### Кодирование циклических переменных
<dfn title="циклическое кодирование">Циклическое кодирование</dfn> (cyclic encoding) — это метод преобразования категориальных признаков, которые имеют естественный циклический порядок, в числовые признаки с сохранением такой цикличности. Часто используется для признаков, представляющих циклы времени или циклические явления, например, часы суток, дни недели, месяцы года.

**Циклическое кодирование** применяется для кодирования категориальных переменных, принимающих циклические значения, такие как час в сутках и день месяца. В этих случаях существует естественный порядок на значениях. Например, час в сутках принимает значения 0,1,2,3,...22,23. За счёт вещественного представления часа в сутках удаётся передать модели, что соседние часы близки, а дальние — далеки, что сделает зависимость от часа дня более плавной. При этом необходимо учесть, что, в силу цикличности, час 23 близок к нулевому часу.[^Categorical-preprocessing]

Моделировать такие виды близости можно с помощью **циклического кодирования**, при котором признак $u∈[0,max(u))$ кодируется парой вещественных значений:

$$ u \longrightarrow \left[ \sin{\left(\frac{2\pi \cdot u}{\max{(u)}}\right)}; \cos{\left(\frac{2\pi \cdot u}{\max{(u)}}\right)} \right] $$

Поскольку $sin()$ и $cos()$ — непрерывные функции, то такое представление для близких значений $u$ и $u′$ будет выдавать близкие кодировки, а дополнительно удастся сообщить модели, что 23 часа близко к часу ночи, а 31 число близко к первому! Эффект достигается за счёт свойств периодичности синуса и косинуса:

![Cyclical feature encoding](../img/cyclical-feature-encoding-f2987f8341923aa0852a54cc83bb90c4.jpg)

**Суть метода**:

- Изначально каждой категории присваивается число по порядку (например, месяцам — 1, 2, ..., 12).

- Затем из этого числового значения создаются два новых признака с помощью функций синуса и косинуса:

$$ x_1 = \sin{\left(\frac{2\pi \cdot i}{N}\right)}, x_2 = \cos{\left(\frac{2\pi \cdot i}{N}\right)} $$

где $i$ — порядковый номер категории, $N$ — общее число категорий.

Такое представление сохраняет информацию о цикличности: например, декабрь (12) и январь (1) оказываются близкими в пространстве признаков, что не учитывается при обычном порядковом или one-hot кодировании.

**Преимущества циклического кодирования**:

- Сохраняет циклическую структуру данных.

- Позволяет моделям воспринимать правильные «расстояния» между крайними категориями.

- Полезен для временных признаков и циклов в данных.

Таким образом, циклическое кодирование помогает корректно представить циклические категориальные признаки в числовом виде, улучшая качество анализа и прогнозирования при работе с такими данными.

#### Выбор метода кодировки
Выбор метода кодирования категориальных данных зависит от типа признака, количества уникальных категорий, а также целей и особенностей модели машинного обучения. Ниже основные рекомендации:

- Для номинальных признаков с небольшим числом уникальных категорий лучше использовать one-hot кодирование (унитарное кодирование), так как оно не вводит искусственного порядка и сохраняет категориальную природу переменной.

- При наличии большого количества категорий one-hot кодирование может привести к сильному росту размерности. В этом случае разумно применять binary encoding или hash encoding, которые уменьшают количество признаков, сохраняя различимость категорий.

- Если категориальные признаки имеют естественный порядок (порядковые признаки), целесообразно использовать порядковое (ординальное) кодирование, которое отражает этот порядок числовыми значениями.

- Для учета связи категорий с целевой переменной применяют кодирование средним (target encoding) или его варианты. Такой метод эффективен, но требует осторожности, чтобы избежать переобучения (необходима кросс-валидация или сглаживание).

- Методы кодирования могут влиять на качество модели, поэтому целесообразно экспериментировать с несколькими подходами и использовать методы валидации для выбора оптимального кодировщика.

- Также учитывают особенности модели: например, деревья принимает категориальные признаки без явного кодирования или хорошо работают с порядковым кодированием, а линейные модели требуют числовых кодов без искажений порядка.

Таким образом, выбор метода кодирования ориентируется на баланс между сохранением информации, размерностью признаков и спецификой модели, чтобы обеспечить максимальную эффективность анализа и прогнозирования.

Конечный вид кодировки подбирается методом проб и ошибок и в конечном счете определяется тем, какой из них будет приводить к более точным прогнозам. Можно кодировать категориальный признак и сразу несколькими способами![^Categorical-preprocessing]

Эти трансформации позволяют анализировать различные типы качественных переменных с помощью статистических методов и алгоритмов машинного обучения, корректно учитывая их природу и отношения между категориями.

Таким образом, кодирование категориальных данных — необходимый этап подготовки данных для успешного анализа и построения корректных моделей.

### Практический пример подготовки и обработки данных

#### Подготовка данных с использованием агрегации и кодирования
Например, имеется набор данных о посещаемости студентами занятиями и информации об итоговой аттестации (файлы *attestation.xlsx*). Например, необходимо выяснить, как аттестационные отметки связаны с посещаемостью студентами занятий. Как мы уже знаем, мерой взаимосвязи между признаками является корреляция. Мы уже научились проводить корреляционный анализ с использованием коэффициента корреляции, позволяющим количественно оценить характер взаимосвязи и степень зависимости двух признаков. Возникает ввопрос: как преобразовать наши данные об аттестации и посещаемости лекций студентами в пригодный для проведения корреляционного анализа и машинной обработки вид?

Во-первых, необходимо проанализировать исходные данные и определить, к какому типу они относятся. В таблице представлены ФИО студентов, данные о посещаемости за каждое занятие по датам и данные аттестации. Посещаемость представлена в виде цветовой маркировки с разбивкой по дням, аттестационные отметки — в виде текстовых значений. В таком виде данные непригодны для обработки статистическими алгоритмами. Для удобства можно сразу присвоить объектам исследования (данные студентов) идентификационные коды, абстрагировавшись от ФИО конкретных студентов. Аналогичным образом следует поступить и с датами, заменив их на порядковые номера (*лист 0*).

Посещаемость является по сути категорильным (номинальным) признаком и может быть представлена либо как бинарное (присутствие/отсутствие) или тернарное (присутствие/опоздание/отсутствие) значение. Для бинарных значений оптимально применить дихотомизацию (отсутствие как 0, присутствие и опоздание как 1), а для тернарных можно использовать прямое кодирование числовыми метками (как 0, 1, 2). Данные аттестации по своей сути являются порядковым признаком, что дает основание заменить текстовые названия отметок их числовым представлением, используя ординальное кодирование (отлично — 5, хорошо — 4, удовлетворительно — 3, н/а — 0). В закодированном виде данный признак удобно обозначить как результирующую переменную $y$ (*лист 1*).

Как уже говорилось выше, коэффициент корреляции является двумерной описательной статистикой, которая применяется для описания двух простых переменных. Мы в таблице имеем посещаемость как многомерную характеристику каждого из изучаемых объектов (студентов), что сильно усложняет исследование. Для уменьшения размерности можно использовать временное агрегирование (тип) с консолидацией данных за весь период времени. Для получения консолидированных значений можно использовать статистические методы — вычисление среднего или относительного значения. Поскольку в данном случае имеем дело с бинарным многомерным признаком, то более эффективным будет вычисление относительного значения. Для этого вычислим показатель посещаемости как отношение количества фактически посещенных дней ($m$) для каждого объекта к полной длине исследуемого интервала в днях, который составляет 10 дней ($n=10$). В итоге из многомерного бинарного признака получим количественные значения факторной переменной $x$ для каждого объекта (*лист 2*).

#### Исследование связи между признаками
Имея парные признаки, можно исследовать корреляцию между ними с помощью коэффициента корреляции. Поскольку одна из переменных является порядковой и отсутствуют какие-либо данные о характере распределения (насколько оно соответствует нормальному), то можно попробовать использовать ранговую корреляцию Спирмена. Для этого обоим признакам необходимо присвоить ранги. Для этого значения обоих признаков сортируются по возрастанию и каждому значению устанавливается порядковый ранг (повторящиеся значения получают средний по группе ранг). Контролем правильности расчета рангов является вычисление ранговой суммы для обоих признаков (*лист 3*).

Далее необходимо вычислить разности рангов и их квадраты для каждого объекта, после чего посчитать сумму квадартов разностей рангов. Далее остается подставить это значение вместе с объемом выборки (количеством студентов) в формулу для вычисления коэффициента корреляции Спирмена. Полученное значение (0.68) позволяет предположить заметную положительную связь между посещаемостью и аттестационной оценкой. Для проверки статистической значимости можно воспользоваться t-статистикой, приняв в качестве нулевой гипотезы утверждение о том, что корреляция между иерархиями признака посещаемости и аттестационного балла не отличается от нуля. Вычисленную t-статистику (4.448) необходимо сравнить с табличным пороговым значением для стандартного уровня значимости $\alpha=0.05$ при 23 уровнях свободы $df=n-2$ (поскольку исследуется линейная связь) — 2.069. Поскольку $t > t_п$, то нулевая гипотезу отвергается, а выявлянную связь между посещаемостью и аттестационной оценкой можно считать статистически значимой (*лист 4*).

Таким образом, была выявлена статистически значимая заметная положительная линейная связь между исследуемой парой признаков, свидетельствующая о том, что при повышении посещаемости у студентов, как правило, растут и их оценки. Это позволяет сделать вывод о том, что посещаемость является значимым фактором для успеваемости.

### Практическая работа. Обработка и анализ признаков для неметрических шкал
Обработать исходные данные в соответствии со стандартами кодирования для приведения их .

Процедура приведения исходных данных (например, пол — м/ж или уровень облачности) в числовой вид для анализа называется кодированием категориальных признаков или преобразованием качественных переменных. В зависимости от типа данных и задачи используются разные методы:

Для бинарных признаков (например, м/ж) применяется дихотомизация — присвоение значений 0 и 1 каждой категории.​

Для порядковых признаков (например, уровень облачности) — ординальное кодирование, при котором каждой категории присваивается ранг (например, ясно = 0, малая = 1, средняя = 2 и т.д.).​

Для номинальных признаков (без естественного порядка) — one-hot encoding (однократное кодирование), при котором каждая категория превращается в отдельный бинарный столбец.​

Такие преобразования позволяют использовать категориальные данные в алгоритмах машинного обучения и статистических моделях, требующих числовых входов.

Уровень облачности (ясно, малая, средняя, высокая, пасмурно) является порядковым признаком. Это означает, что категории облачности можно упорядочить по степени покрытия неба облаками: от полного отсутствия облаков (ясно) до полного покрытия (пасмурно). Такой порядок отражает количественную шкалу, где каждая категория соответствует определённому диапазону баллов по десятибалльной шкале (например, ясно — 0–2 балла, пасмурно — 8–10 баллов).

Выбрать наиболее подходящий коэффициент корреляции (в зависимости от типа данных — бинарные или порядковые).

---

Для исследования связи между температурой воздуха и каким-либо другим признаком (например, посещаемостью или успеваемостью) можно применить коэффициент ранговой корреляции Спирмена, так как позволяет анализировать непараметрические данные и выявлять монотонные зависимости.

Пример лабораторной работы: Анализ корреляции температуры воздуха и посещаемости студентов

Цель:
- Определить наличие и силу связи между значениями температуры воздуха в день лекции и посещаемостью студентов.

Пример данных:
| День | Температура (°C) | Посещаемость (%) |
| ---- | ---------------- | ---------------- |
| 1    | 15               | 85               |
| 2    | 20               | 90               |
| 3    | 10               | 70               |
| 4    | 25               | 95               |
| 5    | 18               | 80               |
| 6    | 12               | 65               |
| 7    | 22               | 88               |
| 8    | 8                | 60               |
| 9    | 17               | 78               |
| 10   | 14               | 73               |

Методы:

1. Присвоить ранги каждому набору данных (температуре и посещаемости).

2. Рассчитать разницу рангов для каждой пары наблюдений и её квадрат.

3. Вычислить коэффициент корреляции Спирмена по формуле:

    $$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} $$

4. Проверить статистическую значимость с помощью t-теста.

Ожидаемые результаты:

- Коэффициент корреляции покажет, насколько температура влияет на посещаемость (например, выявится положительная или отрицательная монотонная связь).

- Анализ позволит сделать выводы о влиянии погодных условий на поведение студентов.

Такой подход расширяет практические навыки по статистическому анализу в реальных условиях, помогает оценить влияние внешних факторов на поведение исследуемой выборки и применить непараметрические методы корреляции при работе с разными типами данных.

Проведем расчет коэффициента ранговой корреляции Спирмена для заданных данных температуры воздуха и посещаемости (по примеру из предыдущего ответа):

| День | Температура (°C) | Посещаемость (%) |
| ---- | ---------------- | ---------------- |
| 1    | 15               | 85               |
| 2    | 20               | 90               |
| 3    | 10               | 70               |
| 4    | 25               | 95               |
| 5    | 18               | 80               |
| 6    | 12               | 65               |
| 7    | 22               | 88               |
| 8    | 8                | 60               |
| 9    | 17               | 78               |
| 10   | 14               | 73               |

Шаг 1: Присвоение рангов

Ранги температуры по возрастанию:

| Темп. | 8 | 10 | 12 | 14 | 15 | 17 | 18 | 20 | 22 | 25 |
| ----- | - | -- | -- | -- | -- | -- | -- | -- | -- | -- |
| Ранг  | 1 | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 |

Ранги посещаемости по возрастанию:

| Посещаемость | 60 | 65 | 70 | 73 | 78 | 80 | 85 | 88 | 90 | 95 |
| ------------ | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |
| Ранг         | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 |

Шаг 2: Расчет разностей рангов $d_i$ и их квадратов

День | Ранг темп. | Ранг посещ.	| $d_i$ | $d_i^2$
-- | -- | -- | -- | --
| 1  | 5  | 7  | -2 | 4 |
| 2  | 8  | 9  | -1 | 1 |
| 3  | 2  | 3  | -1 | 1 |
| 4  | 10 | 10 | 0  | 0 |
| 5  | 7  | 6  | 1  | 1 |
| 6  | 3  | 2  | 1  | 1 |
| 7  | 9  | 8  | 1  | 1 |
| 8  | 1  | 1  | 0  | 0 |
| 9  | 6  | 5  | 1  | 1 |
| 10 | 4  | 4  | 0  | 0 |

Сумма квадратов разностей: $\sum{d_i^2} = 10$$

Шаг 3: Расчет коэффициента Спирмена

$$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} = 1 - \frac{6 \cdot 10}{10 \cdot (100-1)} = 1 - \frac{60}{990} = 1 - 0.0606=0.9394 $$

Шаг 4: Статистическая значимость

Степени свободы $n−2=8$, расчет t-статистики:

$$ t = r \sqrt{\frac{n-2}{1-r^2}} = 0.9394 \cdot \sqrt{\frac{8}{1-0.8824}} = 0.9394 \cdot \sqrt{\frac{8}{0.1176}} = 0.9394 \cdot 8.238 = 7.74 $$

Критическое значение $t_{0.05,8} ≈ 2.306$.

Так как $7.74 > 2.306$, связь статистически значима при уровне 0.05.

**Вывод**:
Коэффициент ранговой корреляции Спирмена $ρ≈0.94$ свидетельствует о очень сильной положительной монотонной связи между температурой воздуха и посещаемостью студентов. Высокая температура соответствует большей посещаемости. Статистическая значимость проверки подтверждает, что данная связь не случайна.

Таким образом, погодные условия (температура) существенно влияют на поведение студентов с точки зрения посещаемости лекций. Этот пример демонстрирует применение ранговой корреляции для количественных и порядковых данных с интерпретацией результатов и проверкой значимости.​

---

На основании найденных источников и теоретических знаний, проведем расчет и анализ корреляции между годом рождения и возрастом студента.

Исходные данные (примерные):

| Студент | Год рождения | Возраст (на текущий год) |
| ------- | ------------ | ------------------------ |
| 1       | 2000         | 25                       |
| 2       | 1998         | 27                       |
| 3       | 2002         | 23                       |
| 4       | 1995         | 30                       |
| 5       | 2001         | 24                       |
| 6       | 1997         | 28                       |
| 7       | 2003         | 22                       |
| 8       | 1996         | 29                       |
| 9       | 2000         | 25                       |
| 10      | 1999         | 26                       |

*Примечание*: Возраст рассчитываем как текущий год (2025) минус год рождения.

Шаг 1: Присвоение рангов

Ранги по году рождения — по убыванию (чем меньше год, тем старше студент):

| Год рождения | Ранг (по убыванию) |
| ------------ | ------------------ |
| 1995         | 1                  |
| 1996         | 2                  |
| 1997         | 3                  |
| 1998         | 4                  |
| 1999         | 5                  |
| 2000         | 6.5 (два студента) |
| 2001         | 8                  |
| 2002         | 9                  |
| 2003         | 10                 |

Ранги по возрасту — по возрастанию (чем больше возраст, тем выше ранг):

| Возраст | Ранг (по возрастанию) |
| ------- | --------------------- |
| 22      | 1                     |
| 23      | 2                     |
| 24      | 3                     |
| 25      | 4.5 (два студента)    |
| 26      | 6                     |
| 27      | 7                     |
| 28      | 8                     |
| 29      | 9                     |
| 30      | 10                    |

Шаг 2: Расчет разностей рангов и их квадраты

Пример для каждого студента:

День | Ранг по году | Ранг по возрасту	| $d_i$ | $d_i^2$
-- | -- | -- | -- | --
| 1  | 6.5 | 4.5 | 2  | 4  |
| 2  | 4   | 7   | -3 | 9  |
| 3  | 9   | 2   | 7  | 49 |
| 4  | 1   | 10  | -9 | 81 |
| 5  | 8   | 3   | 5  | 25 |
| 6  | 4   | 6   | -2 | 4  |
| 7  | 10  | 1   | 9  | 81 |
| 8  | 2   | 8   | -6 | 36 |
| 9  | 6.5 | 4.5 | 2  | 4  |
| 10 | 5   | 5   | 0  | 0  |


Сумма квадратов разностей: $\sum{d_i^2} = 293$

Шаг 3: Расчет коэффициента корреляции Спирмена

$$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} = 1 - \frac{6 \cdot 293}{10 \cdot (100-1)} = 1 - \frac{1758}{990} \approx 1 - 1.775 \approx -0.775 $$

*(Значение получено условно, при реальных расчетах использовать точные данные)*

Шаг 4: Оценка статистической значимости

Степени свободы $n−2=8$, расчет t-статистики:

$$ t = r \sqrt{\frac{n-2}{1-r^2}} \approx -0.775 \cdot \sqrt{\frac{8}{1-0.775^2}} \approx -0.775 \cdot \sqrt{\frac{8}{0.399}} \approx -0.775 \cdot 4.47 \approx -3.46    $$

Значение абсолютного $t$ превышает критическое при уровне 0.05 (около 2.306), значит связь статистически значима.

**Итоговые выводы**:
Обнаружена отрицательная сильная корреляция между годом рождения и возрастом (что ожидаемо). В реальной практике, анализ должен учитывать целевую переменную — например, понимание взаимосвязи между годом рождения и текущим возрастом или семейным статусом, что может быть полезно для демографических исследований или социального анализа.

Этот пример показывает, как применять коэффициент Спирмена для выявления статистически значимых монотонных зависимостей между переменными.

---

Исследование взаимосвязи между годом рождения, возрастом студента и месяцем опроса показывает, что коэффициент корреляции между годом рождения и возрастом в выборках существенно зависит от месяца, в котором проводился опрос.

Согласно источникам, при различных месяцах опроса значение коэффициента корреляции может варьироваться, что связано с особенностями составления выборок (например, дата опроса влияет на точность определения возраста по году рождения из-за разницы в месяцах рождения и месяце опроса).​

Это означает, что при проведении статистического анализа для таких данных рекомендуется учитывать месяц опроса как дополнительный фактор, чтобы повысить точность и корректность интерпретации корреляционных связей. Можно сегментировать данные по месяцам и отдельно исследовать корреляцию внутри каждого сегмента, затем сравнить результаты.

Таким образом, при анализе связи года рождения и возраста с учётом месяца опроса важно:

- Проводить корреляционный анализ в разбивке по месяцам.

- Учитывать систематические сдвиги, связанные с датой опроса (например, студенты, опрошенные в начале года, могут иметь иной расчет возраста по сравнению с опрошенными ближе к концу года).

- Использовать корректирующие методики по данному фактору или дополнительно учитывать месяц как фактор в многофакторном анализе.

В итоге, месяц опроса является существенным фактором, влияющим на оценку статистических взаимосвязей между годом рождения и возрастом, и его следует учитывать для повышения точности и достоверности результатов исследований на студенческих данных.​
Если сейчас необходим конкретный расчет по вашим данным с детализацией по месяцам, то нужен исходный объем и распределение данных по месяцам, чтобы выполнить точный корреляционный анализ.

Сгенерированы типичные данные для анализа зависимости между годом рождения студента, его возрастом и месяцем, в котором проводился опрос (10 студентов):

| Студент | Год рождения | Возраст (2025 - год рождения) | Месяц опроса |
| ------- | ------------ | ----------------------------- | ------------ |
| 1       | 2000         | 25                            | Январь       |
| 2       | 1998         | 27                            | Январь       |
| 3       | 2002         | 23                            | Февраль      |
| 4       | 1995         | 30                            | Февраль      |
| 5       | 2001         | 24                            | Март         |
| 6       | 1997         | 28                            | Март         |
| 7       | 2003         | 22                            | Апрель       |
| 8       | 1996         | 29                            | Апрель       |
| 9       | 2000         | 25                            | Май          |
| 10      | 1999         | 26                            | Май          |

Это отражает разбивку по месяцам опроса с разным распределением годов рождения и возраста, что дает основу для анализа влияния месяца опроса на корреляцию.

Дальше можно по каждому месяцу отдельно провести расчет коэффициента корреляции между годом рождения и возрастом, выявить различия и сделать выводы об учете месяца опроса в анализе.

Если нужно, могу вычислить коэффициенты корреляции отдельно по месяцам на этих данных с интерпретацией результатов.

### Дополнительные источники
1. Бююль А., Цеффель П. SPSS: искусство обработки информации. – М., 2005. Глава 15. Корреляции
2. Наследов А. IBM SPSS Statistics 20 и AMOS: профессиональный статистический анализ данных. СПб., 2013. Глава 9. Корреляции
3. Сибирев В.А. «Введение в анализ социальных данных» (С. 58-81)
4. [А.Г. Дьяконов. Методы решения задач классификации с категориальными признаками](https://cs.msu.ru/sites/cmc/files/docs/dyakonov.pdf).
5. [Medium: categorical data encoding techniques](https://medium.com/aiskunks/categorical-data-encoding-techniques-d6296697a40f).
6. [Pargent F. et al. Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features //Computational Statistics. – 2022. – Т. 37. – №. 5. – С. 2671-2692](https://link.springer.com/article/10.1007/s00180-022-01207-6).
7. [Документация scikit-learn: preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html).
8. [Документация feature-engine: categorical encoding](https://feature-engine.trainindata.com/en/latest/user_guide/encoding/index.html).

### Источники информации
[^pandas]: [Руководство по кодированию категориальных значений в Python](https://dfedorov.spb.ru/pandas/%D0%A0%D1%83%D0%BA%D0%BE%D0%B2%D0%BE%D0%B4%D1%81%D1%82%D0%B2%D0%BE%20%D0%BF%D0%BE%20%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8E%20%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D0%B9%20%D0%B2%20Python.html)
[^Categorical-preprocessing]: [Обработка категориальных признаков](https://deepmachinelearning.ru/docs/Machine-learning/Data-preprocessing/Categorical-preprocessing)
[^obrabotka-katieghorialnykh-priznakov]: [Кодирование категориальных признаков](https://nerdit.ru/obrabotka-katieghorialnykh-priznakov/)
[^agregatsiia-dannykh]: [Агрегация данных](https://appmaster.io/ru/glossary/agregatsiia-dannykh)
