<link href="../styles.css" rel="stylesheet" />

## 06. Непараметрическая корреляция, агрегация и кодирование признаков

- [06. Непараметрическая корреляция, агрегация и кодирование признаков](#06-непараметрическая-корреляция-агрегация-и-кодирование-признаков)
  - [Кодирование данных](#кодирование-данных)
    - [Основные методы кодирования](#основные-методы-кодирования)
      - [Сопоставление и замена признаков (feature mapping and replacement)](#сопоставление-и-замена-признаков-feature-mapping-and-replacement)
      - [Дихотомизация для бинарных признаков](#дихотомизация-для-бинарных-признаков)
      - [Порядковое (ординальное) кодирование для порядковых признаков](#порядковое-ординальное-кодирование-для-порядковых-признаков)
      - [Прямое кодирование (кодирование метками) для категориальных признаков](#прямое-кодирование-кодирование-метками-для-категориальных-признаков)
      - [Частотное кодирование для категориальных признаков](#частотное-кодирование-для-категориальных-признаков)
      - [Кодирование средним (таргет-кодирование)](#кодирование-средним-таргет-кодирование)
      - [Унитарное кодирование для номинальных признаков](#унитарное-кодирование-для-номинальных-признаков)
    - [Обработка категорий с большим числом уникальных значений](#обработка-категорий-с-большим-числом-уникальных-значений)
    - [Кодирование циклических переменных](#кодирование-циклических-переменных)
    - [Выбор метода кодировки](#выбор-метода-кодировки)
  - [Агрегация данных](#агрегация-данных)
  - [Ранговая корреляция](#ранговая-корреляция)
    - [Коэффициент ранговой корреляции Спирмена (неметрические шкалы)](#коэффициент-ранговой-корреляции-спирмена-неметрические-шкалы)
      - [Расчет коэффициента Спирмена](#расчет-коэффициента-спирмена)
      - [Интерпретация коэффициента](#интерпретация-коэффициента)
      - [Пример расчета](#пример-расчета)
    - [Коэффициент ранговой корреляции Кендалла](#коэффициент-ранговой-корреляции-кендалла)
      - [Диапазон и интерпретация](#диапазон-и-интерпретация)
      - [Особенности](#особенности)
    - [Коэффициент ранговой корреляции Гудмена-Краскела](#коэффициент-ранговой-корреляции-гудмена-краскела)
      - [Интерпретация](#интерпретация)
      - [Особенности](#особенности-1)
  - [Практическая работа. Ранговая и бисериальная корреляция для нементрических шкал](#практическая-работа-ранговая-и-бисериальная-корреляция-для-нементрических-шкал)
  - [Дополнительные источники](#дополнительные-источники)
  - [Источники информации](#источники-информации)


### Кодирование данных
Помимо количественных признаков часто наборы данных содержат категориальные переменные. Эти переменные обычно хранятся в виде текстовых значений, которые представляют различные характеристики. Некоторые примеры включают цвет ("Красный", "Желтый", "Синий"), размер ("Маленький", "Средний", "Большой") или географические обозначения ("Штат" или "Страна"). Другими словами, категориальные признаки — это признаки, которые описываются метками или строковыми значениями, такими как цвет, тип или категория объекта.

<dfn title="категориальный признак">Категориальные признаки</dfn> (categorical features) — это признаки, принимающие одно из $K$ дискретных значений, такие как профессия человека или город, в котором он родился. Такие признаки очень часто встречаются на практике. Частным случаем категориальных признаков являются <dfn title="бинарный признак">бинарные признаки</dfn> (binary features), принимающие всего два значения, такие как семейное положение человека или индикатор, были ли у человека просрочки по кредитам.[^Categorical-preprocessing]

Многие алгоритмы машинного обучения поддерживают категориальные значения без дополнительных манипуляций, но есть множество алгоритмов, которые этого не делают. Чаще всего модель машинного обучения ожидает на входе вектор, состоящий только из вещественных признаков. Следовательно, перед аналитиком стоит задача выяснить, как преобразовать эти текстовые атрибуты в числовые значения для дальнейшей обработки.[^pandas] Правильная обработка таких признаков критически важна для успеха модели.[^obrabotka-katieghorialnykh-priznakov]

Категориальные признаки могут быть преобразованы в числовые признаки, которые можно применять в моделях машинного обучения. <dfn title="кодирование категориальных данных">Кодирование категориальных данных</dfn> — это процесс преобразования качественных признаков в числовую форму для дальнейшего анализа или использования в алгоритмах машинного обучения, которые обычно требуют числовых входов.

**Почему это важно**

- Многие статистические методы и модели машинного обучения работают только с числовыми данными.

- Категориальные переменные без кодирования невозможно напрямую включить в такие модели.

- Кодирование позволяет сохранить информативность категорий, при этом облегчая математическую обработку.

Если бинарный признак мы можем представить в вещественном виде, закодировав категории цифрами 0 и 1, то в случае признака, описывающего несколько категорий, возможны различные варианты кодировок, которые мы рассмотрим далее.

#### Основные методы кодирования
*[OHC]: One-Hot Coding
*[OHE]: One-Hot Encoding

Существует несколько методов преобразования категориальных признаков.

##### Сопоставление и замена признаков (feature mapping and replacement)

Категориальный признак может быть связан с числовым признаком, таким как стоимость товара или количество проданных единиц. В таком случае категориальный признак может быть преобразован в числовой признак, чтобы стать частью общего набора признаков для модели машинного обучения.

Данный метод применим в том случае, если есть два столбца данных, значения которых представляют собой слова, используемые для представления чисел. В частности, количество цилиндров в двигателе (`num_cylinders`) и количество дверей в машине (`num_doors`). В отдельных случаях можно напрямую заменять текстовые значения их числовыми эквивалентами. Например, если данные `num_doors` включают только 2 или 4 двери. Количество цилиндров включает всего 7 значений, которые легко переводятся в действительные числа.

Хотя данный подход может работать только в определенных случаях, это очень полезная демонстрация того, как преобразовать текстовые значения в числовые, когда есть "легкая" интерпретация данных человеком. Представленная концепция также полезна для более общей очистки данных.

##### Дихотомизация для бинарных признаков
<dfn title="дихотомизация">Дихотомизация</dfn> (dichotomous coding) — это процесс преобразования непрерывной или категориальной переменной в бинарную, то есть в две категории (обычно 0 и 1). В статистике и машинном обучении дихотомизация позволяет представить сложные или многозначные данные в упрощённом виде для дальнейшего анализа или построения моделей. Суть метода заключается в том, что при двух категориях (например, пол: м/ж) каждой присваивается 0 или 1, что удобно для большинства алгоритмов.

**Основные моменты дихотомизации**:
- Переменная разбивается на две группы по какому-то критерию (например, значение выше или ниже порога).

- Каждой группе присваивается бинарный код (0 или 1).

- Применяется, когда нужно упростить данные, сделать их совместимыми с бинарными алгоритмами или выделить конкретные категории (например, "болен / здоров", "мужчина / женщина").

Дихотомизация помогает работать с качественными или количественными данными, если требуется категоризация на две части, что часто встречается в задачах классификации и в анализе бинарных признаков. Применяется, когда нужно упростить данные, сделать их совместимыми с бинарными алгоритмами или выделить конкретные категории (например, "болен / здоров", "мужчина / женщина"). Таким образом, дихотомизация — это важный инструмент подготовки данных, позволяющий переводить разнообразные типы данных в удобную для анализа бинарную форму.

##### Порядковое (ординальное) кодирование для порядковых признаков
<dfn title="порядковое кодирование">Порядковое кодирование</dfn> — это метод преобразования категориального признака, для которого существует естественный порядок, в числовой вид, сохраняя этот порядок. Каждой категории присваивается целое число, отражающее её позицию в этом порядке.

В **порядковом кодировании** (ordinal encoding) категория заменяется её номером. Этот метод хорошо подходит для признаков с порядком значений, таких, например, как уровень образования. Каждой категории присваивается числовой ранг согласно их естественному порядку (например, уровень облачности: ясно = 0, малая = 1, средняя = 2, высокая = 3, пасмурно = 4). Это сохраняет информацию о порядке, что важно для корреляционного анализа, учитывающего ранги. Так, в отличие от one-hot encoding, которое создаёт отдельные бинарные признаки для каждой категории и не учитывает порядок, порядковое кодирование компактно и отражает информационный смысл порядка категорий.

Порядковое кодирование широко используется для признаков с понятной и важной последовательностью значений, например, уровень образования, степень удовлетворённости, рейтинги и т.д. Таким образом, порядковое кодирование позволяет преобразовывать упорядоченные категориальные данные в числовую форму, сохраняя их естественную иерархию для последующего анализа и моделирования.

##### Прямое кодирование (кодирование метками) для категориальных признаков
<dfn title="кодирование метки">Кодирование метки</dfn> или <dfn title="прямое кодирование">прямое кодирование</dfn> (label encoding) — это простое преобразование каждого значения категориальных признаков в числовые значения. При этом каждой уникальной категории присваивается число, т.е. каждое значение категориального признака заменяется на соответствующее целое число.

_Пример_: "Синий" -> 1, "Красный" -> 2, "Зеленый" -> 3.

Рассмотрим кодировку признака "профессия". Пусть для простоты она принимает всего 4 возможных значения: программист, художник, дизайнер и системный администратор. В порядковом кодировании мы заменяем профессии их номерами:

<table><thead><tr><th>значение</th><th>номер</th></tr></thead><tbody><tr><td>программист</td><td>0</td></tr><tr><td>художник</td><td>1</td></tr><tr><td>дизайнер</td><td>2</td></tr><tr><td>системный администратор</td><td>3</td></tr></tbody></table>

```py
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
encoded = le.fit_transform(["кошка", "собака", "кошка", "хомяк"])
print(encoded) # [0 1 0 2]
```

**Особенности прямого кодирования**:

- Простое и компактное преобразование категорий в числа.

- Работает хорошо для признаков с упорядоченными категориями (порядковые признаки).

- Может ввести ошибочную интерпретацию порядка для номинальных категорий, так как модели могут воспринимать числовые коды как имеющие числовую величину и порядок.

- Требует осторожности при применении к номинальным данным, чтобы избежать ложных предположений.

Этот метод может вводить искусственную иерархию между категориями, что может быть проблематично для некоторых моделей, так как модель может принять числовые отношения за реальную зависимость (например, что "красный" больше чем "синий"). Проблема здесь в том, что многие алгоритмы будут интерпретировать эти числа как упорядоченность категорий.[^obrabotka-katieghorialnykh-priznakov]

Поэтому данный вид кодирования _не рекомендуется применять на практике_, поскольку метод машинного обучения впоследствии будет считать, что движение в направлении 0,1,2,3 будет соответствовать возрастанию какой-то реально существующей характеристики, которой в действительности нет, поскольку _нумерация была произвольной_. Также в нашем примере метод на основе близости численных значений будет считать, что программист ближе по смыслу к художнику, чем к системному администратору, что в действительности не так.[^Categorical-preprocessing]

Этот метод часто используется как базовый и этап подготовки данных, особенно если количество категорий невелико или признак порядковый. Таким образом, прямое кодирование — это простой способ представить категориальные данные числовыми значениями, при этом важно учитывать природу данных и возможные ограничения модели

##### Частотное кодирование для категориальных признаков
<dfn title="частотное кодирование">Частотное кодирование</dfn> (frequency encoding) — это метод преобразования категориальных переменных в числовые значения, при котором каждой категории присваивается число, равное частоте её встречаемости в наборе данных. То есть категорию заменяют на то, насколько часто она встречается среди всех наблюдений.

При **частотном кодировании** значение каждой категории заменяется на частоту встречаемости этой категории. Пусть, например, у нас 7 человек, среди которых два программиста, три системных администратора, один дизайнер и художник. Для этого случая частотное кодирование будет выглядеть так:

<table><thead><tr><th>значение</th><th>кодировка</th></tr></thead><tbody><tr><td>программист</td><td>2/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>дизайнер</td><td>1/7</td></tr><tr><td>художник</td><td>1/7</td></tr><tr><td>системный администратор</td><td>3/7</td></tr><tr><td>программист</td><td>2/7</td></tr></tbody></table>

Обратим внимание, что кодирование неоднозначно для дизайнера и художника, которые встретились одинаковое число раз.

> Полезность кодировки определяется тем, насколько частота встречаемости категорий связана с целевой переменной.[^Categorical-preprocessing]

**Преимущества частотного кодирования**:

- Простота реализации.

- Сохраняет информацию о распределении категорий.

- Позволяет эффективно кодировать признаки с большим числом уникальных категорий.

**Недостатки**:

- Может потерять информацию о порядке или содержании категорий.

- При использовании в некоторых моделях может внести смещение, если частота сама коррелирует с целевой переменной.

Частотное кодирование часто применяется в задачах с высококардинальными категориальными признаками, когда one-hot кодирование было бы слишком ресурсоёмким. Таким образом, частотное кодирование представляет каждую категорию через долю её встречаемости в данных, что упрощает работу с категориальными признаками в числовом формате.

##### Кодирование средним (таргет-кодирование)
<dfn title="кодирование средним">Кодирование средним</dfn> (mean encoding, target encoding) — это метод кодирования категориальных признаков, при котором каждой категории присваивается числовое значение, равное среднему значению целевой переменной для этой категории. Кодирование средним — компактный и максимально информативный способ кодирования категориального признака путём замены каждой категории на среднее прогнозируемого отклика _при условии этой категории_.

**Суть кодирования средним**:
- Для каждой категории вычисляется среднее значение отклика (цели) в обучающей выборке.

- Категория заменяется этим средним значением.

Такой подход позволяет компактно представить категориальный признак числами с учётом информации о связи с целевой переменной.

Приведём пример для регрессии, когда по профессии необходимо предсказать зарплату:

<table><thead><tr><th>признак (профессия)</th><th>отклик</th><th>кодирование признака</th></tr></thead><tbody><tr><td>программист</td><td>300</td><td>350</td></tr><tr><td>системный администратор</td><td>250</td><td>200</td></tr><tr><td>системный администратор</td><td>200</td><td>200</td></tr><tr><td>дизайнер</td><td>220</td><td>200</td></tr><tr><td>художник</td><td>150</td><td>150</td></tr><tr><td>дизайнер</td><td>180</td><td>200</td></tr><tr><td>программист</td><td>400</td><td>350</td></tr><tr><td>системный администратор</td><td>150</td><td>200</td></tr></tbody></table>

В данной таблице:

- признак (профессия) — это категориальный признак, который отражает профессию каждого объекта или человека.

- отклик — это целевая переменная (target), числовое значение, которое показывает реакцию, результат или показатель, связанный с профессией (например, количество продаж, выручку, доход и т.д.).

- кодирование признака — это числовое представление категориального признака профессии, полученное методом кодирования средним (mean encoding).

А ниже показан пример кодирования средним для классификации, когда по профессии предсказываем, вернёт человек кредит или нет:

<table><thead><tr><th>признак (профессия)</th><th>отклик</th><th>кодирование признака</th></tr></thead><tbody><tr><td>программист</td><td>1</td><td>1</td></tr><tr><td>системный администратор</td><td>1</td><td>2/3</td></tr><tr><td>системный администратор</td><td>0</td><td>2/3</td></tr><tr><td>дизайнер</td><td>1</td><td>1/2</td></tr><tr><td>художник</td><td>0</td><td>0</td></tr><tr><td>дизайнер</td><td>0</td><td>1/2</td></tr><tr><td>программист</td><td>1</td><td>1</td></tr><tr><td>системный администратор</td><td>1</td><td>2/3</td></tr></tbody></table>

Как видим, для регрессии и бинарной классификации один столбец исходного признака заменяется на один столбец условных средних. В случае многоклассовой классификации каждая категория будет заменяться на _вектор условных частот каждого из классов_ при условии категории.

Представленный способ кодирования максимально информативен для решения итоговой задачи предсказания отклика по кодировке, поскольку кодировка в явном виде агрегирует информацию об отклике.

!!! warning Переобучение

    Кодирование признака агрегацией по отклику _приводит к переобучению_, поскольку мы через признак явно передаём информацию об ожидаемом ответе, пусть и в усреднённом виде. Для категорий, которые встретились единожды ("художник" в примере) мы перенесли отклик в признак в явном виде! Получается, мы решаем нечестную задачу, поскольку сообщаем модели информацию об ожидаемом отклике, которую она не должна знать.

    Чтобы избежать переобучения и сделать прогнозы честными, можно выделить отдельную обучающую выборку на кодирование средним только по ней, а потом перенести вычисленное соответствие категорий средним откликам в основную обучающую выборку, по которой уже будем настраивать модель.

    Более эффективный способ с точки зрения переиспользования данных — для каждого объекта подставлять вместо категории условное среднее отклика по всем объектам _кроме рассматриваемого_ (**leave one out encoding**).[^Categorical-preprocessing]

!!! tip Варианты метода

    Вместо каждой категории можно подставлять условное среднее по другому вещественному или бинарному признаку. Такое кодирование не приводит к подглядыванию в неизвестный отклик, поэтому для него не нужна отдельная выборка для кодировки.

    Также вместо среднего значения при условии каждой категории можно подставлять условную медиану, максимум, минимум или стандартное отклонение - в зависимости от задачи.

**Преимущества**:
- Позволяет использовать информацию о целевой переменной в кодировке.

- Уменьшает размерность данных по сравнению с one-hot encoding.

- Может улучшать качество модели за счёт сохранения релевантной статистики.

**Недостатки**:
- Возможность переобучения модели, если кодирование применяется без дополнительных техник (например, сглаживания или кросс-валидации).

- Требует аккуратного применения в задачах машинного обучения.

Таким образом, кодирование средним представляет категориальные признаки числами, отражающими средний уровень целевой переменной, что помогает учитывать влияние категорий на результат и строить более информативные модели

##### Унитарное кодирование для номинальных признаков
Кодирование меток имеет тот недостаток, что числовые значения могут быть "неверно интерпретированы" алгоритмами. Например, значение 0 очевидно меньше значения 4, но действительно ли это соответствует набору данных в реальной жизни? Имеет ли универсал в 4 раза больший вес, чем у кабриолета?

Общий альтернативный подход называется **унитарным кодированием** (One-hot encoding, dummy encoding). <dfn title="унитарное кодирование">Унитарное кодирование</dfn> — это метод преобразования категориального признака в числовой формат, при котором каждая уникальная категория превращается в отдельный бинарный признак (столбец). В полученной матрице для каждой записи один из столбцов принимает значение 1 (указывая на принадлежность к данной категории), а все остальные — 0.

Основная стратегия состоит в том, чтобы преобразовать значение каждой категории в новый столбец и присвоить столбцу значение 1 или 0 (Истина / Ложь). Это дает преимущество в том, что значение не взвешивается неправильно, но имеет обратную сторону добавления дополнительных столбцов в набор данных.[^pandas]

Категории без внутреннего порядка преобразуются в несколько бинарных признаков — по одному на каждую категорию. То есть для каждой категории создается бинарный признак (dummy variable), при этом каждое значение категориального признака заменяется на столбец бинарных значений, где 1 указывает на присутствие значения признака, а 0 — на его отсутствие. Например, если есть типы облаков: кучевые, слоистые, перистые, создаётся три бинарных столбца, где "1" указывает на наличие этой категории. Этот метод подходит для признаков без порядка значений, таких как цвет или тип объекта.

_Пример_: Вместо столбца "Цвет" (синий, красный, зеленый) создаются столбцы "Синий", "Красный", "Зеленый".

Вначале все категории нумеруются произвольным образом. Каждый категориальный признак, принимающий значение i-й категории среди $K$ возможных, кодируется $K$-мерным вектором из нулей, где на одной только i-й позиции стоит единица.

Пример соответствия категорий кодировкам:

<table><thead><tr><th>направление</th><th>кодировка</th></tr></thead><tbody><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>юг</td><td>[0,0,1,0]</td></tr><tr><td>восток</td><td>[0,1,0,0]</td></tr><tr><td>запад</td><td>[1,0,0,0]</td></tr></tbody></table>

Пример применения кодировки к данным:

<table><thead><tr><th>направление</th><th>кодировка</th></tr></thead><tbody><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>север</td><td>[0,0,0,1]</td></tr><tr><td>запад</td><td>[1,0,0,0]</td></tr><tr><td>восток</td><td>[0,1,0,0]</td></tr><tr><td>север</td><td>[0,0,0,1]</td></tr></tbody></table>

Метод однозначно кодирует категорию и, в отличие от предыдущих методов, производит сопоставление одному категориальному признаку сразу набор бинарных признаков (по числу категорий). Все категории, независимо от порядка кодирования, получаются равнозначными: попарное расстояние между кодировками любой пары категорий получается одним и тем же.

```py
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder()
encoded = ohe.fit_transform([["кошка"], ["собака"], ["кошка"], ["хомяк"]]).toarray()
print(encoded)
# [[1. 0. 0.]
#  [0. 0. 1.]
#  [1. 0. 0.]
#  [0. 1. 0.]]
```

Теперь нет ложной упорядоченности, но возросла размерность данных.

**Особенности унитарного кодирования**:

- Позволяет избежать введения искусственного порядка, поскольку каждая категория представлена независимо.

- При увеличении числа уникальных категорий увеличивается размерность данных (создается столько новых признаков, сколько категорий).

- Широко используется в задаках машинного обучения для обработки номинальных (без внутреннего порядка) категориальных признаков.

Таким образом, унитарное (one-hot) кодирование — это удобный и распространенный способ представления категориальных данных в числовом виде, сохраняющий категорийную природу признаков без предположений о порядке.

One-hot кодирование — самый популярный способ представления категориальных признаков, однако у него есть недостаток, что при слишком большом числе категорий он приводит к сильному разрастанию числа признаков. Например, если категория — это город, то, поскольку городов очень много, число признаков значительно увеличивается, что приводит к сильному увеличению параметров модели машинного обучения, ухудшая её настройку. Одним из способов борьбы с этим является объединение различных родственных категорий в одну. Например, вместо указания города можно указывать область, в которой этот город находится. Если же не хочется терять детализации, то можно использовать усиленную [регуляризацию](https://deepmachinelearning.ru/docs/Machine-learning/Base-concepts/Regularization) модели.

#### Обработка категорий с большим числом уникальных значений
Иногда категориальный признак имеет очень много уникальных значений (например, список городов). Применение OHE приведет к "проклятию размерности". Есть несколько способов справиться с этим:

1. **Группировка редких категорий**. Категории с частотой ниже порога объединяются в одну группу "Другое":

    ```py
    def group_rare(df, col, threshold=0.05):
        s = df[col].value_counts(normalize=True)
        rare = s[s < threshold].index
        df[col] = df[col].replace(rare, "Другое")
        return df

    df = group_rare(df, "City", 0.01)
    ```

2. **Применение техник понижения размерности после OHE**, например, метод главных компонент (PCA).

3. **Использование числовых представлений категорий**, например, частоты (probability encoding) или таргет-кодирования (target encoding).

!!! tip Эмбеддинги

    Представление определённой дискретной сущности (например, категории в категориальном признаке) вектором вещественных чисел называется <dfn title="эмбеддинг">эмбеддингом</dfn> (embedding). One-hot кодирование приводит к слишком длинному вектору, если число категорий велико. Вместе с этим понятно, что если использовать не только значения 0/1, а весь спектр вещественных чисел, то можно даже большое число категорий однозначно закодировать компактным вектором эмбеддинга. Эмбеддинги можно сэмплировать случайно, при этом желательно обеспечивать одинаковое попарное расстояние между эмбеддингами разных категорий. Или генерировать эмбеддинги так, чтобы расстояние между эмбеддингами оказывалось более близким для более близких категорий по смыслу (например, работа программиста более близка к работе системного администратора, а работа художника - к работе дизайнера, поэтому и соответствующие эмбеддинги должны быть ближе). Существуют продвинутые методы автоматической генерации эмбеддингов, о которых можно прочитать, например, в [статье](https://cs.msu.ru/sites/cmc/files/docs/dyakonov.pdf).

Правильная обработка категориальных признаков — важный этап построения модели машинного обучения. One-Hot кодирование — наиболее универсальный подход. Но для признаков с большим числом категорий приходится применять дополнительные техники, чтобы избежать "проклятия размерности".[^obrabotka-katieghorialnykh-priznakov]

#### Кодирование циклических переменных
<dfn title="циклическое кодирование">Циклическое кодирование</dfn> (cyclic encoding) — это метод преобразования категориальных признаков, которые имеют естественный циклический порядок, в числовые признаки с сохранением такой цикличности. Часто используется для признаков, представляющих циклы времени или циклические явления, например, часы суток, дни недели, месяцы года.

**Циклическое кодирование** применяется для кодирования категориальных переменных, принимающих циклические значения, такие как час в сутках и день месяца. В этих случаях существует естественный порядок на значениях. Например, час в сутках принимает значения 0,1,2,3,...22,23. За счёт вещественного представления часа в сутках удаётся передать модели, что соседние часы близки, а дальние — далеки, что сделает зависимость от часа дня более плавной. При этом необходимо учесть, что, в силу цикличности, час 23 близок к нулевому часу.[^Categorical-preprocessing]

Моделировать такие виды близости можно с помощью **циклического кодирования**, при котором признак $u∈[0,max(u))$ кодируется парой вещественных значений:

$$ u \longrightarrow \left[ \sin{\left(\frac{2\pi \cdot u}{\max{(u)}}\right)}; \cos{\left(\frac{2\pi \cdot u}{\max{(u)}}\right)} \right] $$

Поскольку $sin()$ и $cos()$ — непрерывные функции, то такое представление для близких значений $u$ и $u′$ будет выдавать близкие кодировки, а дополнительно удастся сообщить модели, что 23 часа близко к часу ночи, а 31 число близко к первому! Эффект достигается за счёт свойств периодичности синуса и косинуса:

![Cyclical feature encoding](../img/cyclical-feature-encoding-f2987f8341923aa0852a54cc83bb90c4.jpg)

**Суть метода**:

- Изначально каждой категории присваивается число по порядку (например, месяцам — 1, 2, ..., 12).

- Затем из этого числового значения создаются два новых признака с помощью функций синуса и косинуса:

$$ x_1 = \sin{\left(\frac{2\pi \cdot i}{N}\right)}, x_2 = \cos{\left(\frac{2\pi \cdot i}{N}\right)} $$

где $i$ — порядковый номер категории, $N$ — общее число категорий.

Такое представление сохраняет информацию о цикличности: например, декабрь (12) и январь (1) оказываются близкими в пространстве признаков, что не учитывается при обычном порядковом или one-hot кодировании.

**Преимущества циклического кодирования**:

- Сохраняет циклическую структуру данных.

- Позволяет моделям воспринимать правильные «расстояния» между крайними категориями.

- Полезен для временных признаков и циклов в данных.

Таким образом, циклическое кодирование помогает корректно представить циклические категориальные признаки в числовом виде, улучшая качество анализа и прогнозирования при работе с такими данными.

#### Выбор метода кодировки
Выбор метода кодирования категориальных данных зависит от типа признака, количества уникальных категорий, а также целей и особенностей модели машинного обучения. Ниже основные рекомендации:

- Для номинальных признаков с небольшим числом уникальных категорий лучше использовать one-hot кодирование (унитарное кодирование), так как оно не вводит искусственного порядка и сохраняет категориальную природу переменной.

- При наличии большого количества категорий one-hot кодирование может привести к сильному росту размерности. В этом случае разумно применять binary encoding или hash encoding, которые уменьшают количество признаков, сохраняя различимость категорий.

- Если категориальные признаки имеют естественный порядок (порядковые признаки), целесообразно использовать порядковое (ординальное) кодирование, которое отражает этот порядок числовыми значениями.

- Для учета связи категорий с целевой переменной применяют кодирование средним (target encoding) или его варианты. Такой метод эффективен, но требует осторожности, чтобы избежать переобучения (необходима кросс-валидация или сглаживание).

- Методы кодирования могут влиять на качество модели, поэтому целесообразно экспериментировать с несколькими подходами и использовать методы валидации для выбора оптимального кодировщика.

- Также учитывают особенности модели: например, деревья принимает категориальные признаки без явного кодирования или хорошо работают с порядковым кодированием, а линейные модели требуют числовых кодов без искажений порядка.

Таким образом, выбор метода кодирования ориентируется на баланс между сохранением информации, размерностью признаков и спецификой модели, чтобы обеспечить максимальную эффективность анализа и прогнозирования.

Конечный вид кодировки подбирается методом проб и ошибок и в конечном счете определяется тем, какой из них будет приводить к более точным прогнозам. Можно кодировать категориальный признак и сразу несколькими способами![^Categorical-preprocessing]

Эти трансформации позволяют анализировать различные типы качественных переменных с помощью статистических методов и алгоритмов машинного обучения, корректно учитывая их природу и отношения между категориями.

Таким образом, кодирование категориальных данных — необходимый этап подготовки данных для успешного анализа и построения корректных моделей

---

Например, имеется набор данных о посещаемости студентами занятиями и информации об итоговой аттестации (файлы *attestation.xlsx*). Например, необходимо выяснить, как аттестационные отметки связаны с посещаемостью студентами занятий. Как мы уже знаем, мерой взаимосвязи между признаками является корреляция. Мы уже научились проводить корреляционный анализ с использованием коэффициента корреляции, позволяющим количественно оценить характер взаимосвязи и степень зависимости двух признаков. Возникает ввопрос: как преобразовать наши данные об аттестации и посещаемости лекций студентами в пригодный для проведения корреляционного анализа и машинной обработки вид?

Как уже говорилось выше, коэффициент корреляции является двумерной описательной статистикой, которая применяется для описания двух простых переменных. Мы в таблице имеем посещаемость как многомерную характеристику каждого из изучаемых объектов (студентов). 



Применение параметрического подхода к качественным признакам: странные дисперсии, средние, отклонения и т.п. коэффициента Пирсона и попытка построить диаграмму рассеяния для пола.

Для исследования связи между ростом (количественная переменная) и полом (дихотомическая категориальная переменная) лучше всего использовать бисериальный коэффициент корреляции. Он предназначен именно для случая, когда одна переменная измеряется в дихотомической шкале (например, пол: мужчина/женщина), а другая — в количественной или интервальной шкале (например, рост).

Если пол кодируется как 0 и 1, бисериальный коэффициент покажет силу и направление связи роста с полом.

Другой вариант — точечный бисериальный коэффициент корреляции, который также применяется для одной бинарной и одной количественной переменной.

Коэффициент Пирсона в данном случае использовать можно, но с условием кодирования пола в числовой формат (например, 0 и 1), тогда он будет эквивалентен бисериальному коэффициенту.

Таким образом, для анализа связи роста и пола оптимален бисериальный (точечный бисериальный) коэффициент корреляции.

### Агрегация данных


### Ранговая корреляция

#### Коэффициент ранговой корреляции Спирмена (неметрические шкалы)
<dfn title="коэффициент ранговой корреляции">Коэффициенты ранговой корреляции</dfn> используются для измерения взаимозависимости между качественными признаками, значения которых могут
быть упорядочены или проранжированы по степени убывания (или возрастания) данного качества у исследуемых социальных объектов.

<dfn title="метод ранговой корреляции Спирмена">Метод ранговой корреляции Спирмена</dfn> позволяет определить тесноту (силу) и направление корреляционной связи между двумя признаками или двумя профилями (иерархиями) признаков.

- Для подсчета ранговой корреляции необходимо располагать двумя рядами значений, которые могут быть проранжированы.

- Возможны два варианта гипотез коэффициента ранговой корреляции Спирмена:

<table>
<tr>

<td>

$H_0$: Корреляция между переменными А и Б не отличается от нуля.

</td>

<td>

$H_0$: Корреляция между иерархиями А и Б не отличается от нуля.

</td>

</tr>

<tr>

<td>

$H_1$: Корреляция между переменными А и Б достоверно отличается от нуля.

</td>

<td>

$H_1$: Корреляция между иерархиями А и Б достоверно отличается от нуля.

</td>

</tr>

</table>


<dfn title="коэффициент ранговой корреляции Спирмена">Коэффициент ранговой корреляции Спирмена</dfn> — это статистический показатель, который используется для оценки силы и направления монотонной зависимости между двумя переменными, измеренными в ранговой (порядковой) шкале. Он является непараметрическим аналогом коэффициента корреляции Пирсона и вычисляется на основании рангов значений переменных, а не их исходных числовых данных.

При использовании коэффициента ранговой корреляции Спирмена обязательно ранжировать оба признака, между которыми исследуется связь. Это его ключевое отличие от обычного коэффициента корреляции Пирсона.

Каждому значению в обоих признаках присваивается ранг — порядковый номер после упорядочивания по возрастанию (либо убыванию). Затем уже вычисляются разности рангов соответствующих наблюдений для подсчёта итогового коэффициента.

Ранжирование делает метод Спирмена непараметрическим, позволяя анализировать не численные значения, а их относительный порядок. Это даёт возможность использовать его для данных, которые не обязательно распределены нормально или имеют порядковую шкалу.

Итак, оба набора данных обязательно переводятся в ранги для корректного вычисления коэффициента Спирмена.

Таким образом, коэффициент Спирмена применяется для анализа зависимостей между переменными, когда данные не соответствуют нормальному распределению или измерены в ранговой шкале, а также в случаях, когда связь между переменными может быть нелинейной, но монотонной.

##### Расчет коэффициента Спирмена
1. Каждому значению признаков по отдельности присваивается ранг (если значения совпадают, им дают средний ранг).

    <dfn title="ранг">Ранг</dfn> — это порядковый номер объекта, присвоенный ему при упорядочивании значений признака по возрастанию или убыванию. Он отражает порядок расположения значения относительно остальных в выборке.

    Принцип присвоения рангов:

    - все значения сортируются в выбранном порядке (обычно по возрастанию);

    - самому минимальному значению присваивается ранг 1, следующему — 2 и так далее;

    - ранги идут по порядку, начиная с 1 и заканчивая числом наблюдений $n$;

    - если значения совпадают (например, несколько одинаковых оценок), им присваивают ранги, равные среднему арифметическому тех рангов, которые они бы получили, если бы были разными (это называется присвоением средних рангов);

    - итоговая сумма всех рангов равна $\frac{n(n+1)}{2}$.

    То есть ранг зависит от количества наблюдений и всегда измеряется в пределах от 1 до числа наблюдений $n$.

    Таким образом, ранги отражают относительное положение данных в упорядоченном ряду, а не абсолютные значения, и всегда соответствуют числовому диапазону от 1 до $n$ с поправками на одинаковые значения, если такие есть.

2. Вычисляют разности рангов для каждой пары наблюдений.

3. Разности возводят в квадрат и суммируют.

4. Коэффициент вычисляется по формуле:

    $$ r_s = 1 - \frac{6 \sum_{i=1}^n{d^2_i}}{n(n^2-1)} $$

    где $d_i$ — разность рангов для $i$-го наблюдения, $\sum_{i=1}^n{d^2_i}$ — сумма квадратов разностей рангов, $n$ — число парных наблюдений.

Если есть повторяющиеся ранги, применяются более общие формулы с учетом поправок.

##### Интерпретация коэффициента
Коэффициент $ρ$ Спирмена интерпретируется аналогично коэффициенту корреляции Пирсона и может принимать значения в таком же диапазоне $(–1;+1)$. 
Значение коэффициента лежит в интервале от -1 до 1. Оценивается $\left|r_s\right|$.

Диапазон | Уровень связи
-- | --
менее 0.3 | слабая связь
[0,3; 0,5] | умеренная
[0,5; 0,7] | заметная
[0,7; 0,9] | высокая
[0,9; 0,99] | весьма высокая

##### Пример расчета
Для исследования связи между посещаемостью лекций и аттестационной оценкой студентов можно применить ранговый корреляционный анализ (коэффициент корреляции Спирмена), так как оценка — порядковая категория (3, 4, 5, н/а).

Исходные данные:

| Студент | Посещаемость (%) | Оценка (число) |
| ------- | ---------------- | -------------- |
| 1       | 90               | 5              |
| 2       | 85               | 4              |
| 3       | 70               | 4              |
| 4       | 60               | 3              |
| 5       | 95               | 5              |
| 6       | 50               | 3              |
| 7       | 80               | 4              |
| 8       | 30               | н/а (0)        |
| 9       | 75               | 4              |
| 10      | 40               | 3              |

Оценка "н/а" кодируется как 0 для удобства расчётов.

Шаги анализа:
1. Пронумеровать оценки (0, 3, 4, 5) — как ранги.

2. Проранжировать посещаемость и оценки по величине.

| Студент | Посещаемость | Ранг посещаемости | Оценка | Ранг оценки |
| ------- | ------------ | ----------------- | ------ | ----------- |
| 5       | 95           | 1                 | 5      | 1.5         |
| 1       | 90           | 2                 | 5      | 1.5         |
| 2       | 85           | 3                 | 4      | 4.5         |
| 7       | 80           | 4                 | 4      | 4.5         |
| 9       | 75           | 5                 | 4      | 4.5         |
| 3       | 70           | 6                 | 4      | 4.5         |
| 4       | 60           | 7                 | 3      | 8.5         |
| 6       | 50           | 8                 | 3      | 8.5         |
| 10      | 40           | 9                 | 3      | 8.5         |
| 8       | 30           | 10                | 0      | 10          |

3. Вычислить ранговую разницу для каждого студента и её квадрат.

    Студент | Ранг пос. | Ранг оценки | $d_i = \text{Ранг пос.} - \text{Ранг оценки}$ | $d_i^2$
    -- | -- | -- | -- | --
    5 | 1 | 1.5 | -0.5 | 0.25
    1 | 2 | 1.5 | 0.5 | 0.25
    2 |	3 |	4.5 | -1.5 | 2.25
    7 |	4 |	4.5 | -0.5 | 0.25
    9 |	5 |	4.5 | 0.5 |	0.25
    3 |	6 |	4.5 | 1.5 |	2.25
    4 |	7 |	8.5 | -1.5 | 2.25
    6 |	8 |	8.5 | -0.5 | 0.25
    10 | 9 | 8.5 | 0.5 | 0.25
    8 |	10 | 10 | 0 | 0

    Сумма $\sum{d_i^2} = 8.5$.

4. Подстановка в формулу коэффициента Спирмена:

    $$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} = 1 - \frac{6 \cdot 8.5}{10 (10^2-1)} = 1 - \frac{51}{990} \approx 1-0.0515 = 0.9485 $$

    где $d_i$ — разница рангов по двум признакам, $n=10$.

    Коэффициент ранговой корреляции Спирмена равен примерно 0.9485, что указывает на очень высокую положительную монотонную связь между посещаемостью лекций и оценкой студентов. Чем выше посещаемость, тем выше аттестационная оценка в общем.

    Таким образом, анализ данных показывает сильную положительную зависимость между посещаемостью и оценками студентов.

5. Оценить статистическую значимость через критерий $t$ с $n−2=8$ степенями свободы.

    Для оценки статистической значимости полученного коэффициента ранговой корреляции Спирмена $r_s = 0.9485$ с размером выборки $n=10$ используется t-критерий Стьюдента с формулой:

    $$ t = r \sqrt{\frac{n-2}{1-r^2}} $$

    Подставим значения:

    $$ t = 0.9485 \sqrt{\frac{10-2}{1-0.9485^2}} \approx 0.9485 \cdot 8.93 = 8.47 $$

    Число степеней свободы равно $n−2=8$.

    Далее нужно сравнить вычисленное значение $t=8.47$ с критическим значением $t$ для 8 степеней свободы при уровне значимости $α=0.05$, которое примерно равно 2.306.

    Так как 8.47 значительно больше 2.306, нулевая гипотеза о том, что корреляция отсутствует, отвергается. Следовательно, полученный коэффициент ранговой корреляции Спирмена статистически значим.

    Это означает, что наблюдаемая высокая корреляция между посещаемостью и оценками не случайна и отражает реальную монотонную связь в данных.

Результаты (примерные):
- Значение коэффициента Спирмена $ρ≈0.85$ — сильная положительная корреляция.

- t-статистика > критического значения при уровне значимости 0.05, что подтверждает достоверность связи.

**Вывод**:
Сильная положительная связь между посещаемостью лекций и оценками студентов. Это указывает, что более посещающие студенты склонны получать более высокие оценки. Такой анализ помогает объективно оценить влияние посещаемости на успехи в обучении.

Этот практический пример демонстрирует применение ранговой корреляции для качественно-количественных и порядковых данных, развивает практические навыки интерпретации и проверки статистической значимости корреляционных связей.

#### Коэффициент ранговой корреляции Кендалла
Коэффициент ранговой корреляции Кендалла (τ) — это мера степени монотонной зависимости между двумя порядковыми переменными. Он оценивает насколько согласованно располагаются пары наблюдений в двух ранжированных наборах данных. Как и коэффициент ранговой корреляции Спирмена, коэффициент Кендалла используется для измерения взаимосвязи между качественными признаками, характеризующими объекты одной и той же природы, ранжированные по одному и тему же критерию. Изменяется от -1 до +1.

**Суть коэффициента Кендалла**
- Рассматриваются все пары наблюдений.

- Число согласованных пар $N^+$ — где порядок значений совпадает в обеих переменных.

- Число несогласованных пар $N^−$ — где порядок различается (то есть инверсия).

- Коэффициент Кендалла вычисляется как разность числа согласованных и несогласованных пар, делённая на общее число пар:

$$ \tau = \frac{N^+ - N^-}{\frac{1}{2} n (n-1)} $$

_Пример_: Оценивается связь между ростом и весом в группе людей, предварительно ранжированных по этим переменным.

При сравнении любых двух человек из этой группы возможны две ситуации:
- однонаправленное изменение переменных («совпадение»), когда и рост, и вес одного больше, чем у другого;
- разнонаправленное изменение («инверсия»), когда рост у второго больше, а вес меньше, чем у первого.

Перебрав все пары испытуемых, можно оценить вероятность совпадений ($P$) и вероятность инверсий ($Q$). Корреляция Кендалла — это разность вероятностей «совпадений» и «инверсий»:

$$ τ = P – Q $$

По значению корреляции Кендалла можно всегда вычислить вероятность «совпадений» и «инверсий»:

$$ P = \frac{1 + τ}{2} $$

$$ Q = \frac{1 - τ}{2} $$

Важным преимуществом корреляции τ-Кендалла является ее отчетливая вероятностная интерпретация.

##### Диапазон и интерпретация
Значение $τ$ лежит в диапазоне от -1 до 1:

- $τ = 1$ означает полное совпадение рангов (идеальная положительная связь);

- $τ = -1$ — полное противопоставление (идеальная отрицательная связь);

- $τ = 0$ — отсутствие связи.

##### Особенности
- Коэффициенты корреляции Спирмена и Кендалла используются как меры взаимозависимости между **рядами рангов**, а не как меры связи между самими переменными.

- Коэффициенты Спирмена и Кендалла обладают примерно одинаковыми свойствами, но t-Кендалла в случае многих рангов, а также при введении дополнительных объектов в ходе исследования имеет определенные вычислительные преимущества.

- Коэффициент Кендалла чувствителен к небольшим изменениями порядка в данных.

- Более устойчив к связанным рангам и выбросам по сравнению с коэффициентом Спирмена.

- Широко используется при анализе порядковых данных и в непараметрической статистике.

Таким образом, коэффициент Кендалла — важный инструмент для рангового корреляционного анализа, отражающий степень согласованности рангов двух признаков и позволяющий оценить их монотонную зависимость.

#### Коэффициент ранговой корреляции Гудмена-Краскела
*[PRE]: Proportional Reduction in Error

Альтернативой мерам ассоциации, построенным на ХИ-квадрат статистике, являются коэффициенты, основанные на идее Л. Гудмана и Е. Краскала о «пропорциональной редукции ошибок» (Proportional Reduction in Error Measures — PRE).

В отличие от предыдущих показателей коэффициент PRE предполагает четкое разграничение на зависимые ($Y$) и независимые ($X$) переменные. Например, в качестве независимой переменной может выступает строковая переменная «уровень дохода», а в качестве зависимой — столбцовая переменная «степень удовлетворенности».

В статистическом распределении двух переменных содержится определенная информация об их зависимости. Если переменная $X$ влияет на переменную $Y$, то, зная распределение независимой переменной, можно сделать вывод о характере распределения зависимой переменной. Естественно, что эта оценка не всегда правильна. Существует вероятность ошибки.

- В случае **полной зависимости** двух переменных друг от друга на основе информации о значении независимой переменной для каждой единицы наблюдения можно совершенно точно "предсказать значение" зависимой.
- При **полной независимости** переменных это сделать не удается.

Таким образом, по тому, как увеличивается точность прогноза значения зависимой переменной с учетом дополнительной информации о независимой переменной, определяют степень их зависимости.

Подобные показатели можно формировать для **любых типов шкал**.

Коэффициент ранговой корреляции Гудмена-Краскела (Goodman-Kruskal's gamma, $γ$) — это мера ассоциации между двумя порядковыми признаками, основанная на сравнении количества конкордантных (согласованных) и дискородантных (несогласованных) пар наблюдений.

**Принцип работы**
- Рассматриваются все пары наблюдений.

- Конкордантные пары — пары, где порядок значений совпадает по обоим признакам.

- Дискордантные пары — пары, где порядок отличен.

Коэффициент Гудмена-Краскела вычисляется по формуле:

$$ \gamma = \frac{N_c - N_d}{N_c + N_d} $$

где $N_c$ — число конкордантных пар, $N_d$ — число дискордантных пар.

##### Интерпретация
Значения $γ$ лежат в диапазоне от -1 (идеально обратная зависимость) до +1 (идеально прямая зависимость).

##### Особенности
- В отличие от коэффициента Кендалла, коэффициент Гудмена-Краскела не учитывает "связанные" пары (где пары равны по одному из признаков), что делает его более отзывчивым к сильной корреляции.

- Коэффициент используется для анализа ассоциаций между порядковыми переменными, особенно когда важен баланс между согласованностью и несогласованностью рангов.

- Полезен при исследовании взаимосвязей в социальных науках, психологии, маркетинговых исследованиях.

- Подходит для небольших выборок и упорядоченных категориальных данных.

Таким образом, коэффициент Гудмена-Краскела — это показатель зависимости порядка двух переменных, отражающий, насколько часто они изменяются согласованно или наоборот, с учётом только несвязанных пар

### Практическая работа. Ранговая и бисериальная корреляция для нементрических шкал
Обработать исходные данные в соответствии со стандартами кодирования для приведения их .

Процедура приведения исходных данных (например, пол — м/ж или уровень облачности) в числовой вид для анализа называется кодированием категориальных признаков или преобразованием качественных переменных. В зависимости от типа данных и задачи используются разные методы:

Для бинарных признаков (например, м/ж) применяется дихотомизация — присвоение значений 0 и 1 каждой категории.​

Для порядковых признаков (например, уровень облачности) — ординальное кодирование, при котором каждой категории присваивается ранг (например, ясно = 0, малая = 1, средняя = 2 и т.д.).​

Для номинальных признаков (без естественного порядка) — one-hot encoding (однократное кодирование), при котором каждая категория превращается в отдельный бинарный столбец.​

Такие преобразования позволяют использовать категориальные данные в алгоритмах машинного обучения и статистических моделях, требующих числовых входов.

Уровень облачности (ясно, малая, средняя, высокая, пасмурно) является порядковым признаком. Это означает, что категории облачности можно упорядочить по степени покрытия неба облаками: от полного отсутствия облаков (ясно) до полного покрытия (пасмурно). Такой порядок отражает количественную шкалу, где каждая категория соответствует определённому диапазону баллов по десятибалльной шкале (например, ясно — 0–2 балла, пасмурно — 8–10 баллов).

Выбрать наиболее подходящий коэффициент корреляции (в зависимости от типа данных — бинарные или порядковые).

---

Для исследования связи между температурой воздуха и каким-либо другим признаком (например, посещаемостью или успеваемостью) можно применить коэффициент ранговой корреляции Спирмена, так как позволяет анализировать непараметрические данные и выявлять монотонные зависимости.

Пример лабораторной работы: Анализ корреляции температуры воздуха и посещаемости студентов

Цель:
- Определить наличие и силу связи между значениями температуры воздуха в день лекции и посещаемостью студентов.

Пример данных:
| День | Температура (°C) | Посещаемость (%) |
| ---- | ---------------- | ---------------- |
| 1    | 15               | 85               |
| 2    | 20               | 90               |
| 3    | 10               | 70               |
| 4    | 25               | 95               |
| 5    | 18               | 80               |
| 6    | 12               | 65               |
| 7    | 22               | 88               |
| 8    | 8                | 60               |
| 9    | 17               | 78               |
| 10   | 14               | 73               |

Методы:

1. Присвоить ранги каждому набору данных (температуре и посещаемости).

2. Рассчитать разницу рангов для каждой пары наблюдений и её квадрат.

3. Вычислить коэффициент корреляции Спирмена по формуле:

    $$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} $$

4. Проверить статистическую значимость с помощью t-теста.

Ожидаемые результаты:

- Коэффициент корреляции покажет, насколько температура влияет на посещаемость (например, выявится положительная или отрицательная монотонная связь).

- Анализ позволит сделать выводы о влиянии погодных условий на поведение студентов.

Такой подход расширяет практические навыки по статистическому анализу в реальных условиях, помогает оценить влияние внешних факторов на поведение исследуемой выборки и применить непараметрические методы корреляции при работе с разными типами данных.

Проведем расчет коэффициента ранговой корреляции Спирмена для заданных данных температуры воздуха и посещаемости (по примеру из предыдущего ответа):

| День | Температура (°C) | Посещаемость (%) |
| ---- | ---------------- | ---------------- |
| 1    | 15               | 85               |
| 2    | 20               | 90               |
| 3    | 10               | 70               |
| 4    | 25               | 95               |
| 5    | 18               | 80               |
| 6    | 12               | 65               |
| 7    | 22               | 88               |
| 8    | 8                | 60               |
| 9    | 17               | 78               |
| 10   | 14               | 73               |

Шаг 1: Присвоение рангов

Ранги температуры по возрастанию:

| Темп. | 8 | 10 | 12 | 14 | 15 | 17 | 18 | 20 | 22 | 25 |
| ----- | - | -- | -- | -- | -- | -- | -- | -- | -- | -- |
| Ранг  | 1 | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 |

Ранги посещаемости по возрастанию:

| Посещаемость | 60 | 65 | 70 | 73 | 78 | 80 | 85 | 88 | 90 | 95 |
| ------------ | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |
| Ранг         | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 |

Шаг 2: Расчет разностей рангов $d_i$ и их квадратов

День | Ранг темп. | Ранг посещ.	| $d_i$ | $d_i^2$
-- | -- | -- | -- | --
| 1  | 5  | 7  | -2 | 4 |
| 2  | 8  | 9  | -1 | 1 |
| 3  | 2  | 3  | -1 | 1 |
| 4  | 10 | 10 | 0  | 0 |
| 5  | 7  | 6  | 1  | 1 |
| 6  | 3  | 2  | 1  | 1 |
| 7  | 9  | 8  | 1  | 1 |
| 8  | 1  | 1  | 0  | 0 |
| 9  | 6  | 5  | 1  | 1 |
| 10 | 4  | 4  | 0  | 0 |

Сумма квадратов разностей: $\sum{d_i^2} = 10$$

Шаг 3: Расчет коэффициента Спирмена

$$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} = 1 - \frac{6 \cdot 10}{10 \cdot (100-1)} = 1 - \frac{60}{990} = 1 - 0.0606=0.9394 $$

Шаг 4: Статистическая значимость

Степени свободы $n−2=8$, расчет t-статистики:

$$ t = r \sqrt{\frac{n-2}{1-r^2}} = 0.9394 \cdot \sqrt{\frac{8}{1-0.8824}} = 0.9394 \cdot \sqrt{\frac{8}{0.1176}} = 0.9394 \cdot 8.238 = 7.74 $$

Критическое значение $t_{0.05,8} ≈ 2.306$.

Так как $7.74 > 2.306$, связь статистически значима при уровне 0.05.

**Вывод**:
Коэффициент ранговой корреляции Спирмена $ρ≈0.94$ свидетельствует о очень сильной положительной монотонной связи между температурой воздуха и посещаемостью студентов. Высокая температура соответствует большей посещаемости. Статистическая значимость проверки подтверждает, что данная связь не случайна.

Таким образом, погодные условия (температура) существенно влияют на поведение студентов с точки зрения посещаемости лекций. Этот пример демонстрирует применение ранговой корреляции для количественных и порядковых данных с интерпретацией результатов и проверкой значимости.​

---

На основании найденных источников и теоретических знаний, проведем расчет и анализ корреляции между годом рождения и возрастом студента.

Исходные данные (примерные):

| Студент | Год рождения | Возраст (на текущий год) |
| ------- | ------------ | ------------------------ |
| 1       | 2000         | 25                       |
| 2       | 1998         | 27                       |
| 3       | 2002         | 23                       |
| 4       | 1995         | 30                       |
| 5       | 2001         | 24                       |
| 6       | 1997         | 28                       |
| 7       | 2003         | 22                       |
| 8       | 1996         | 29                       |
| 9       | 2000         | 25                       |
| 10      | 1999         | 26                       |

*Примечание*: Возраст рассчитываем как текущий год (2025) минус год рождения.

Шаг 1: Присвоение рангов

Ранги по году рождения — по убыванию (чем меньше год, тем старше студент):

| Год рождения | Ранг (по убыванию) |
| ------------ | ------------------ |
| 1995         | 1                  |
| 1996         | 2                  |
| 1997         | 3                  |
| 1998         | 4                  |
| 1999         | 5                  |
| 2000         | 6.5 (два студента) |
| 2001         | 8                  |
| 2002         | 9                  |
| 2003         | 10                 |

Ранги по возрасту — по возрастанию (чем больше возраст, тем выше ранг):

| Возраст | Ранг (по возрастанию) |
| ------- | --------------------- |
| 22      | 1                     |
| 23      | 2                     |
| 24      | 3                     |
| 25      | 4.5 (два студента)    |
| 26      | 6                     |
| 27      | 7                     |
| 28      | 8                     |
| 29      | 9                     |
| 30      | 10                    |

Шаг 2: Расчет разностей рангов и их квадраты

Пример для каждого студента:

День | Ранг по году | Ранг по возрасту	| $d_i$ | $d_i^2$
-- | -- | -- | -- | --
| 1  | 6.5 | 4.5 | 2  | 4  |
| 2  | 4   | 7   | -3 | 9  |
| 3  | 9   | 2   | 7  | 49 |
| 4  | 1   | 10  | -9 | 81 |
| 5  | 8   | 3   | 5  | 25 |
| 6  | 4   | 6   | -2 | 4  |
| 7  | 10  | 1   | 9  | 81 |
| 8  | 2   | 8   | -6 | 36 |
| 9  | 6.5 | 4.5 | 2  | 4  |
| 10 | 5   | 5   | 0  | 0  |


Сумма квадратов разностей: $\sum{d_i^2} = 293$

Шаг 3: Расчет коэффициента корреляции Спирмена

$$ \rho = 1 - \frac{6 \sum d_i^2}{n (n^2-1)} = 1 - \frac{6 \cdot 293}{10 \cdot (100-1)} = 1 - \frac{1758}{990} \approx 1 - 1.775 \approx -0.775 $$

*(Значение получено условно, при реальных расчетах использовать точные данные)*

Шаг 4: Оценка статистической значимости

Степени свободы $n−2=8$, расчет t-статистики:

$$ t = r \sqrt{\frac{n-2}{1-r^2}} \approx -0.775 \cdot \sqrt{\frac{8}{1-0.775^2}} \approx -0.775 \cdot \sqrt{\frac{8}{0.399}} \approx -0.775 \cdot 4.47 \approx -3.46    $$

Значение абсолютного $t$ превышает критическое при уровне 0.05 (около 2.306), значит связь статистически значима.

**Итоговые выводы**:
Обнаружена отрицательная сильная корреляция между годом рождения и возрастом (что ожидаемо). В реальной практике, анализ должен учитывать целевую переменную — например, понимание взаимосвязи между годом рождения и текущим возрастом или семейным статусом, что может быть полезно для демографических исследований или социального анализа.

Этот пример показывает, как применять коэффициент Спирмена для выявления статистически значимых монотонных зависимостей между переменными.

---

Исследование взаимосвязи между годом рождения, возрастом студента и месяцем опроса показывает, что коэффициент корреляции между годом рождения и возрастом в выборках существенно зависит от месяца, в котором проводился опрос.

Согласно источникам, при различных месяцах опроса значение коэффициента корреляции может варьироваться, что связано с особенностями составления выборок (например, дата опроса влияет на точность определения возраста по году рождения из-за разницы в месяцах рождения и месяце опроса).​

Это означает, что при проведении статистического анализа для таких данных рекомендуется учитывать месяц опроса как дополнительный фактор, чтобы повысить точность и корректность интерпретации корреляционных связей. Можно сегментировать данные по месяцам и отдельно исследовать корреляцию внутри каждого сегмента, затем сравнить результаты.

Таким образом, при анализе связи года рождения и возраста с учётом месяца опроса важно:

- Проводить корреляционный анализ в разбивке по месяцам.

- Учитывать систематические сдвиги, связанные с датой опроса (например, студенты, опрошенные в начале года, могут иметь иной расчет возраста по сравнению с опрошенными ближе к концу года).

- Использовать корректирующие методики по данному фактору или дополнительно учитывать месяц как фактор в многофакторном анализе.

В итоге, месяц опроса является существенным фактором, влияющим на оценку статистических взаимосвязей между годом рождения и возрастом, и его следует учитывать для повышения точности и достоверности результатов исследований на студенческих данных.​
Если сейчас необходим конкретный расчет по вашим данным с детализацией по месяцам, то нужен исходный объем и распределение данных по месяцам, чтобы выполнить точный корреляционный анализ.

Сгенерированы типичные данные для анализа зависимости между годом рождения студента, его возрастом и месяцем, в котором проводился опрос (10 студентов):

| Студент | Год рождения | Возраст (2025 - год рождения) | Месяц опроса |
| ------- | ------------ | ----------------------------- | ------------ |
| 1       | 2000         | 25                            | Январь       |
| 2       | 1998         | 27                            | Январь       |
| 3       | 2002         | 23                            | Февраль      |
| 4       | 1995         | 30                            | Февраль      |
| 5       | 2001         | 24                            | Март         |
| 6       | 1997         | 28                            | Март         |
| 7       | 2003         | 22                            | Апрель       |
| 8       | 1996         | 29                            | Апрель       |
| 9       | 2000         | 25                            | Май          |
| 10      | 1999         | 26                            | Май          |

Это отражает разбивку по месяцам опроса с разным распределением годов рождения и возраста, что дает основу для анализа влияния месяца опроса на корреляцию.

Дальше можно по каждому месяцу отдельно провести расчет коэффициента корреляции между годом рождения и возрастом, выявить различия и сделать выводы об учете месяца опроса в анализе.

Если нужно, могу вычислить коэффициенты корреляции отдельно по месяцам на этих данных с интерпретацией результатов.

### Дополнительные источники
1. Бююль А., Цеффель П. SPSS: искусство обработки информации. – М., 2005. Глава 15. Корреляции
2. Наследов А. IBM SPSS Statistics 20 и AMOS: профессиональный статистический анализ данных. СПб., 2013. Глава 9. Корреляции
3. Сибирев В.А. «Введение в анализ социальных данных» (С. 58-81)
4. [А.Г. Дьяконов. Методы решения задач классификации с категориальными признаками](https://cs.msu.ru/sites/cmc/files/docs/dyakonov.pdf).
5. [Medium: categorical data encoding techniques](https://medium.com/aiskunks/categorical-data-encoding-techniques-d6296697a40f).
6. [Pargent F. et al. Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features //Computational Statistics. – 2022. – Т. 37. – №. 5. – С. 2671-2692](https://link.springer.com/article/10.1007/s00180-022-01207-6).
7. [Документация scikit-learn: preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html).
8. [Документация feature-engine: categorical encoding](https://feature-engine.trainindata.com/en/latest/user_guide/encoding/index.html).

### Источники информации
[^pandas]: [Руководство по кодированию категориальных значений в Python](https://dfedorov.spb.ru/pandas/%D0%A0%D1%83%D0%BA%D0%BE%D0%B2%D0%BE%D0%B4%D1%81%D1%82%D0%B2%D0%BE%20%D0%BF%D0%BE%20%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8E%20%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D0%B9%20%D0%B2%20Python.html)
[^Categorical-preprocessing]: [Обработка категориальных признаков](https://deepmachinelearning.ru/docs/Machine-learning/Data-preprocessing/Categorical-preprocessing)
[^obrabotka-katieghorialnykh-priznakov]: [Кодирование категориальных признаков](https://nerdit.ru/obrabotka-katieghorialnykh-priznakov/)
